{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Training_Classification_PT_Bert_FT_More_Grad_Acc_2_2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"8b6b8ec698774e06a1d39a512bbc98a4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_589f96b1756f4e72ba022b4d23931f04","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c2cdb41dd9ef4882b10489d46cc010bb","IPY_MODEL_d8cb5c9c3875446693e58f05a930729a","IPY_MODEL_86bc9f4185484dc3a13daefeda3cee4a"]}},"589f96b1756f4e72ba022b4d23931f04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c2cdb41dd9ef4882b10489d46cc010bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f5283c6b09f144b0b55202a32786ab8f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3b4820a76a8a4c49b3b8214c853a02de"}},"d8cb5c9c3875446693e58f05a930729a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9c9f7132899c488ca00ad9d144b5f767","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_94cf9194172248709f3311a7713939de"}},"86bc9f4185484dc3a13daefeda3cee4a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e46fac48ac774a8b9d4df0c3e610280f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 226k/226k [00:00&lt;00:00, 895kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_14aea7e9a33a4ee9b2967b31c1446176"}},"f5283c6b09f144b0b55202a32786ab8f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3b4820a76a8a4c49b3b8214c853a02de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9c9f7132899c488ca00ad9d144b5f767":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"94cf9194172248709f3311a7713939de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e46fac48ac774a8b9d4df0c3e610280f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"14aea7e9a33a4ee9b2967b31c1446176":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"13dd23403570440bbf414f3ab4637207":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d1233d27d4a04558b1d7332658f13516","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e0fd2661b1e74be68e350d6c1191b48c","IPY_MODEL_802d1e1e5d3a4bf1bebda90d76f5a9ef","IPY_MODEL_7a1e75cc3fb246e38224b5a7e2dd60a5"]}},"d1233d27d4a04558b1d7332658f13516":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e0fd2661b1e74be68e350d6c1191b48c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b40f7f6ff0a64d419c9b54cb009aae2e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c7be70b0bbf9443c8398bc2e42a9a5e0"}},"802d1e1e5d3a4bf1bebda90d76f5a9ef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f6795a7b9ffa4be7a442f2ddb1c4b146","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_16a902921e284854a1b49a643a715191"}},"7a1e75cc3fb246e38224b5a7e2dd60a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e255d6e4e16640e18e6872540c574031","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 455k/455k [00:00&lt;00:00, 1.61MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4e04e31ef085472a8d7886c80b6e1092"}},"b40f7f6ff0a64d419c9b54cb009aae2e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c7be70b0bbf9443c8398bc2e42a9a5e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f6795a7b9ffa4be7a442f2ddb1c4b146":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"16a902921e284854a1b49a643a715191":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e255d6e4e16640e18e6872540c574031":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4e04e31ef085472a8d7886c80b6e1092":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"312fbb873f604218b303a717682c8b9c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6cc034c4a3ad4882904f153e6f4ffaa6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_54124b06eaa842fab6dfff3ddd59e207","IPY_MODEL_61f25177de8642df8d5a06f9dfafb037","IPY_MODEL_b0e747dffd434ad2ae2f95bcba91c512"]}},"6cc034c4a3ad4882904f153e6f4ffaa6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"54124b06eaa842fab6dfff3ddd59e207":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_775a008d2b474df0a7028ba54b9a0d8b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4fea7e7dd74d49d0882bbde3d910f058"}},"61f25177de8642df8d5a06f9dfafb037":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2248adf3a5b44caf84bf4d353de31cb5","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bc96930161694ad9822e9671692c77de"}},"b0e747dffd434ad2ae2f95bcba91c512":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ec0986982e604d68bc2203a919e99c84","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:00&lt;00:00, 458B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f3befa7bd3c54eaea1f834cc99e00277"}},"775a008d2b474df0a7028ba54b9a0d8b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4fea7e7dd74d49d0882bbde3d910f058":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2248adf3a5b44caf84bf4d353de31cb5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bc96930161694ad9822e9671692c77de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ec0986982e604d68bc2203a919e99c84":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f3befa7bd3c54eaea1f834cc99e00277":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d5b01adc62244065a6282fe35fd486af":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1d03be04ffb24e5eadb4a92de8fda9e2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_290625d918364fe2b6f83998179ed704","IPY_MODEL_d49ab921dd64494881cac367e04242d2","IPY_MODEL_520dfb6a2cb24ecd8368c43e80aaa7ff"]}},"1d03be04ffb24e5eadb4a92de8fda9e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"290625d918364fe2b6f83998179ed704":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3bbd018cc1394be9ae955bdc92d76094","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bc81485e69e04e31a7c17a9dea64815a"}},"d49ab921dd64494881cac367e04242d2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d513680188ff4a23b12c5bea71bcfd33","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":570,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":570,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_98b4dd2cc3f948f5ad60d5fa7ea76d23"}},"520dfb6a2cb24ecd8368c43e80aaa7ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_de4df67b01dd42a187eacbda8b23e448","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 570/570 [00:00&lt;00:00, 15.9kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_24b4edbe1b334837b00fa3deb7908647"}},"3bbd018cc1394be9ae955bdc92d76094":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bc81485e69e04e31a7c17a9dea64815a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d513680188ff4a23b12c5bea71bcfd33":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"98b4dd2cc3f948f5ad60d5fa7ea76d23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"de4df67b01dd42a187eacbda8b23e448":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"24b4edbe1b334837b00fa3deb7908647":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f49d23ac8d7044699b8a6f073a415f79":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8b3040a7490a471ab8c37dbb5d620ebc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_df844a0420eb4e9f8af621051f1c0b37","IPY_MODEL_909bfe6d1fb04f3a9c29ce7f14a6945e","IPY_MODEL_3f6d8b122f1f4096add1cad3a78bcda3"]}},"8b3040a7490a471ab8c37dbb5d620ebc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"df844a0420eb4e9f8af621051f1c0b37":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3e60f2b4fa2c498ebefdcecb9d77c037","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: ","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_80cd636efc2e4407b8703a5fbfc94b33"}},"909bfe6d1fb04f3a9c29ce7f14a6945e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_63b243a803164fa184c9cca0ef34980a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1248,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1248,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_604cd29b6d094286a6056d200b6a9b60"}},"3f6d8b122f1f4096add1cad3a78bcda3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_61cac9103c1145b6ac0116c1b8aad997","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2.64k/? [00:00&lt;00:00, 74.6kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_02abd2e482bc42fd99dd5a202b052912"}},"3e60f2b4fa2c498ebefdcecb9d77c037":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"80cd636efc2e4407b8703a5fbfc94b33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"63b243a803164fa184c9cca0ef34980a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"604cd29b6d094286a6056d200b6a9b60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"61cac9103c1145b6ac0116c1b8aad997":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"02abd2e482bc42fd99dd5a202b052912":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2b3818e33f9d41a1a801b25716ae6d43":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7968e59ba0554b03b0d78b9d81466c42","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4c2064e4f30c4b0ea9ae3ed1ea3221c8","IPY_MODEL_4218066aa45549ee8de7ebfe49cfbc1d","IPY_MODEL_164a1f1074a44f63b5b8ffffa9e553d6"]}},"7968e59ba0554b03b0d78b9d81466c42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4c2064e4f30c4b0ea9ae3ed1ea3221c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6b29833292c04e38ba2bb9262aa39c22","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Skipping the first batches: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6965dc6e51574a7a9f99b249ffb57c38"}},"4218066aa45549ee8de7ebfe49cfbc1d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_18a213b806644289be60aa42ca6fc3f3","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1600,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1600,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6a6b398a9c154b739285680cec09f191"}},"164a1f1074a44f63b5b8ffffa9e553d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5c1fdbe247354cd28672a30074d87fd2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1600/1600 [00:07&lt;00:00, 584.77it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_01823f26b78a4979a2f7675a06f0d1ab"}},"6b29833292c04e38ba2bb9262aa39c22":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6965dc6e51574a7a9f99b249ffb57c38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"18a213b806644289be60aa42ca6fc3f3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6a6b398a9c154b739285680cec09f191":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5c1fdbe247354cd28672a30074d87fd2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"01823f26b78a4979a2f7675a06f0d1ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5b68fb8a43014f0fb078d20bc45eb4b7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7847bb441c8b463a80c8bc6631f34952","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_21246d2a24c94b3f8ce46173a537700d","IPY_MODEL_8ffcfbc95b9743d1ba185c143894f9e4","IPY_MODEL_07682d2610174a8d80fe21e67281bc86"]}},"7847bb441c8b463a80c8bc6631f34952":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"21246d2a24c94b3f8ce46173a537700d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a0f1f100f4544c3e8493e6d72739594d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Skipping the first batches: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d8ae5cd9a37b472bab8f157bb43fb51e"}},"8ffcfbc95b9743d1ba185c143894f9e4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9796207fc0ff4ae5923211b47c7ef429","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1920,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1920,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_53db968e776b4072bac0df7ffc41c114"}},"07682d2610174a8d80fe21e67281bc86":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b756936f333244a6a78a113ab104dc4e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1920/1920 [00:08&lt;00:00, 581.33it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5b8585d58fad492c822d0cf9aa52c1e3"}},"a0f1f100f4544c3e8493e6d72739594d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d8ae5cd9a37b472bab8f157bb43fb51e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9796207fc0ff4ae5923211b47c7ef429":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"53db968e776b4072bac0df7ffc41c114":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b756936f333244a6a78a113ab104dc4e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5b8585d58fad492c822d0cf9aa52c1e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"da7d10b015e343aa8432ebcfaf1156ec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_57ff156cc217458ca6474447ce109c39","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d667e961aeb34e81992b156322d9293b","IPY_MODEL_5bc50d99240b453b97f5619f21cbc1b7","IPY_MODEL_223feddf885d41b496cd3b8ec8e4c4cb"]}},"57ff156cc217458ca6474447ce109c39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d667e961aeb34e81992b156322d9293b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3c4db238cf3b443f9b504d2a44e29507","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Skipping the first batches: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6702b199003c47cf9816fe821820cca7"}},"5bc50d99240b453b97f5619f21cbc1b7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4e1a1f5b876147a6a3a321ff9c4177b0","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1120,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1120,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2fa8404da68f447aa8618e253d697652"}},"223feddf885d41b496cd3b8ec8e4c4cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_64e1bcf1014d495aa09f3c21ae90f3ac","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1120/1120 [00:08&lt;00:00, 560.12it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c8fe97bdbcb54b178a9b63d3414236cd"}},"3c4db238cf3b443f9b504d2a44e29507":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6702b199003c47cf9816fe821820cca7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4e1a1f5b876147a6a3a321ff9c4177b0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2fa8404da68f447aa8618e253d697652":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"64e1bcf1014d495aa09f3c21ae90f3ac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c8fe97bdbcb54b178a9b63d3414236cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3fd406cb781c4531bfeae59f1b2f8460":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0ed49ed0fabc433892cb6e66256b110a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9f2417e77b5c40529814b17863ed7abc","IPY_MODEL_0c34082f5e4440f8a83b57148659ef8e"]}},"0ed49ed0fabc433892cb6e66256b110a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9f2417e77b5c40529814b17863ed7abc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_057582f7457a420d8756a3ba6d057634","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":498,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":498,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dd767d8c985a4576a49fac5b8d9be619"}},"0c34082f5e4440f8a83b57148659ef8e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_08929d7f50684c7c8ada1dfd288038e9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 498/498 [00:02&lt;00:00, 240B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_38ec365837fa4ff0a2be6c8cba2ab4d2"}},"057582f7457a420d8756a3ba6d057634":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"dd767d8c985a4576a49fac5b8d9be619":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"08929d7f50684c7c8ada1dfd288038e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"38ec365837fa4ff0a2be6c8cba2ab4d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7d0bb7a8222c4cdd93ebe7343c255476":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7270e156c2ff4542bd03b3a45226bb57","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_27d0397128774943a646b8e58302a4c0","IPY_MODEL_8d6ab9f9e9f64ec29c325fafb95f606b"]}},"7270e156c2ff4542bd03b3a45226bb57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"27d0397128774943a646b8e58302a4c0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5019419281ac4713bb661ff4d40a7517","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":498627950,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":498627950,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0aaa5b3202324f09a008ba9d56dd9a25"}},"8d6ab9f9e9f64ec29c325fafb95f606b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5b6f621fe077499e8f3d16861ad6d3b8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 499M/499M [00:14&lt;00:00, 33.9MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_486c7fddcdb6442f8196ee95d637ab75"}},"5019419281ac4713bb661ff4d40a7517":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0aaa5b3202324f09a008ba9d56dd9a25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5b6f621fe077499e8f3d16861ad6d3b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"486c7fddcdb6442f8196ee95d637ab75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7e43d9250d9c4fe98cf2194b98c78718":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1a94aa7269f04ec0a6225998be67fe19","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ee9becdbc1304049894383e58d3494af","IPY_MODEL_b74e72c12b5b4616a8442c4cb6c43d66"]}},"1a94aa7269f04ec0a6225998be67fe19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ee9becdbc1304049894383e58d3494af":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4eac87fde4cd41069b79a176f4f0ef2c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":898822,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898822,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_05b4472fa511434d976e4fdfe07f0b0e"}},"b74e72c12b5b4616a8442c4cb6c43d66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6d57a22c25154c0bbe08e30c14b14058","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 899k/899k [00:01&lt;00:00, 890kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_257914342d4d46b18d18ce634df1491e"}},"4eac87fde4cd41069b79a176f4f0ef2c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"05b4472fa511434d976e4fdfe07f0b0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6d57a22c25154c0bbe08e30c14b14058":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"257914342d4d46b18d18ce634df1491e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a68e0782e4a5468db873a756625b19de":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_de2be8b05cce43bfaa77683c05d88601","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a5d2b9fc93804566a996519a9effd1b4","IPY_MODEL_da2b4c1886aa436bb65d7bf84ec83591"]}},"de2be8b05cce43bfaa77683c05d88601":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a5d2b9fc93804566a996519a9effd1b4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5dcbe6b0e6ff4a809bbe5169c26ccc66","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0c8efdfc214a4555b45553902871ca21"}},"da2b4c1886aa436bb65d7bf84ec83591":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_70a386e1270d4cec81a6f8094949f78a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:00&lt;00:00, 746kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_97e7fd5fe96240029d5c945237f2698f"}},"5dcbe6b0e6ff4a809bbe5169c26ccc66":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0c8efdfc214a4555b45553902871ca21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"70a386e1270d4cec81a6f8094949f78a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"97e7fd5fe96240029d5c945237f2698f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9203100138a345008a2f9a8fbf0d2b64":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e1fd4543d8954cf9a39a44e87ff88d51","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0619c1520fef496cbe7c7ff7849f5a3e","IPY_MODEL_cf4a578094e34e49b2aa06645c967a45"]}},"e1fd4543d8954cf9a39a44e87ff88d51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0619c1520fef496cbe7c7ff7849f5a3e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_efc714bbf70346978fc96984d874c14e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":150,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":150,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4043d03dae6340f69a78ca3de9769269"}},"cf4a578094e34e49b2aa06645c967a45":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4f16ea15084949d9ba31135f95e46883","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 150/150 [00:00&lt;00:00, 333B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_63fccdf13da943d5b6465aac5de450c9"}},"efc714bbf70346978fc96984d874c14e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4043d03dae6340f69a78ca3de9769269":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4f16ea15084949d9ba31135f95e46883":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"63fccdf13da943d5b6465aac5de450c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5363e51c14074513a213eee6a32be738":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cc3f26fa8f3f408da359dd9fb8951240","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_42d306f457d342cd9145fa9ac8849bb3","IPY_MODEL_593bba70198e43ff84d417e394fa37ec"]}},"cc3f26fa8f3f408da359dd9fb8951240":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"42d306f457d342cd9145fa9ac8849bb3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4ee0adef37534792857a6d87798d17cb","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":25,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":25,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8eddc5a2839c4b359b7415194dfa7f0f"}},"593bba70198e43ff84d417e394fa37ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_221f4aaf860c4a6fbafd774a348bb227","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 25.0/25.0 [00:00&lt;00:00, 272B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d10fc488334e4677842ef6c6230a8d5a"}},"4ee0adef37534792857a6d87798d17cb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8eddc5a2839c4b359b7415194dfa7f0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"221f4aaf860c4a6fbafd774a348bb227":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d10fc488334e4677842ef6c6230a8d5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"MpxvQ14HFYM1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638871745368,"user_tz":480,"elapsed":23133,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"89bc4bc5-ed56-4f32-c6b0-033cba4f1526"},"source":["from google.colab import drive\n","drive._mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","metadata":{"id":"jGuiOxBdFh3k"},"source":["#!pip install -q keras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"utYxkMR9F0wq","executionInfo":{"status":"ok","timestamp":1638871749427,"user_tz":480,"elapsed":4075,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}}},"source":["!pip install -q pydrive"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"OIJwvszjF4AZ","executionInfo":{"status":"ok","timestamp":1638871762329,"user_tz":480,"elapsed":12911,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}}},"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"WxE-L4LS3v5I"},"source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name() \n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y8N8IE0Z30_Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638871768781,"user_tz":480,"elapsed":5989,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"aa47ae29-1461-4eeb-e8e0-4532195bdf63"},"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla K80\n"]}]},{"cell_type":"code","metadata":{"id":"yAUVCCQ96jsT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638656991710,"user_tz":480,"elapsed":24105,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"a9ca1f5c-65a7-4e6b-b9f4-5a87627380ec"},"source":["!nvidia-smi\n","\n","from tensorflow.python.client import device_lib\n","device_lib.list_local_devices()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Dec  4 22:29:28 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   73C    P8    32W / 149W |      3MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]},{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 14819889134611883572\n"," xla_global_id: -1, name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 10843127808\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 4864828189585404777\n"," physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n"," xla_global_id: 416903419]"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"6-PaQ17P36m8","colab":{"base_uri":"https://localhost:8080/","height":922},"executionInfo":{"status":"ok","timestamp":1638871796500,"user_tz":480,"elapsed":27726,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"d1f3356a-6344-4364-9cad-8b6e59858cb0"},"source":["#!pip install transformers\n","!pip install git+https://github.com/huggingface/transformers"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/huggingface/transformers\n","  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-4ymo8yd5\n","  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-4ymo8yd5\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (4.8.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (1.19.5)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (4.62.3)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 32.8 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 529 kB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (3.4.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 39.5 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.13.0.dev0) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.13.0.dev0) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.13.0.dev0) (3.6.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (2021.10.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (1.15.0)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.13.0.dev0-py3-none-any.whl size=3276845 sha256=f18e6596dc4139cc32af7d77c9c1f0dba8894b5d05a68513e4723353310295c7\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-2bi0hoao/wheels/35/2e/a7/d819e3310040329f0f47e57c9e3e7a7338aa5e74c49acfe522\n","Successfully built transformers\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.13.0.dev0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["yaml"]}}},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"hYNfHEVCUTJM","executionInfo":{"status":"ok","timestamp":1638871796503,"user_tz":480,"elapsed":18,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}}},"source":["project_path='/content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b7Re8ir-aRg4","executionInfo":{"status":"ok","timestamp":1623930507463,"user_tz":-360,"elapsed":407,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"06154810530490924203"}},"outputId":"5f8c4590-62d5-41ce-b064-66903de9f725"},"source":["#cd '/content/drive/My Drive/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SmZ_NAJRUc7v"},"source":["#cd $project_path"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XutRrfaDUh-p"},"source":["#ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jEvmy_hdVu99","executionInfo":{"status":"ok","timestamp":1638871796504,"user_tz":480,"elapsed":17,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}}},"source":["import numpy as np\n","import pandas as pd"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"eak_teqZUmjI","executionInfo":{"status":"ok","timestamp":1638871796505,"user_tz":480,"elapsed":17,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}}},"source":["def tensorify(lst):\n","    \"\"\"\n","    List must be nested list of tensors (with no varying lengths within a dimension).\n","    Nested list of nested lengths [D1, D2, ... DN] -> tensor([D1, D2, ..., DN)\n","\n","    :return: nested list D\n","    \"\"\"\n","    # base case, if the current list is not nested anymore, make it into tensor\n","    if type(lst[0]) != list:\n","        if type(lst) == torch.Tensor:\n","            return lst\n","        elif type(lst[0]) == torch.Tensor:\n","            return torch.stack(lst, dim=0)\n","        else:  # if the elements of lst are floats or something like that\n","            return torch.tensor(lst)\n","    current_dimension_i = len(lst)\n","    for d_i in range(current_dimension_i):\n","        tensor = tensorify(lst[d_i])\n","        lst[d_i] = tensor\n","    # end of loop lst[d_i] = tensor([D_i, ... D_0])\n","    tensor_lst = torch.stack(lst, dim=0)\n","    return tensor_lst"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"KzLahl8DjRbo","executionInfo":{"status":"ok","timestamp":1638871796505,"user_tz":480,"elapsed":17,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}}},"source":["import torch\n","\n","class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","        self.temp = None\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"EZ98pV7F4ctw","executionInfo":{"status":"ok","timestamp":1638871799751,"user_tz":480,"elapsed":3262,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}}},"source":["######## Shuffling Training Dataset for Plausibility Classification ######################\n","#########################################################################\n","\n","import pickle\n","\n","with open(project_path+'Pickles/Plausibility_Classification_PT_Bert_FT_1/pickle_shuffled_train_clarification_single_filler_dataset_1_1.pickle', 'rb') as f:\n","  shuffled_train_dataset = pickle.load(f)\n","  #pickle.dump((test_df['labels'],predictions),f)\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"T5gyjQ3FjUJd"},"source":["import pickle\n","\n","with open(project_path+'Pickles/Plausibility_Classification_PT_Bert_FT_1/pickle_train_clarification_single_filler_dataset_1_1.pickle', 'rb') as f:\n","  train_dataset = pickle.load(f)\n","  #pickle.dump((test_df['labels'],predictions),f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EeWHCErDz2kz"},"source":["import pickle\n","\n","with open(project_path+'Pickles/Plausibility_Classification_PT_Bert_FT_1/pickle_valid_clarification_single_filler_dataset_1_1.pickle', 'rb') as f:\n","  val_dataset = pickle.load(f)\n","  #pickle.dump((test_df['labels'],predictions),f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ja9xsfbkOUbD"},"source":["'''\n","import pickle\n","\n","with open(project_path+'Pickles/pickle_valid_puzzle_shuffled_1000_dataset_1.pickle', 'rb') as f:\n","  shuffled_val_dataset = pickle.load(f)\n","  #pickle.dump((test_df['labels'],predictions),f)\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QVXCtnSBjW5P"},"source":["import pickle\n","\n","with open(project_path+'Pickles/Plausibility_Classification_PT_Bert_FT_1/pickle_valid_small_clarification_single_filler_dataset_1_1.pickle', 'rb') as f:\n","  val_small_dataset = pickle.load(f)\n","  #pickle.dump((test_df['labels'],predictions),f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KEX_2Di5jZFM","executionInfo":{"status":"ok","timestamp":1638871800333,"user_tz":480,"elapsed":605,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}}},"source":["\n","import pickle\n","\n","with open(project_path+'Pickles/Plausibility_Classification_PT_Bert_FT_1/pickle_test_clarification_single_filler_dataset_1_1.pickle', 'rb') as f:\n","  test_dataset = pickle.load(f)\n","  #pickle.dump((test_df['labels'],predictions),f)\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"XTNsqVdCBlzb","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["8b6b8ec698774e06a1d39a512bbc98a4","589f96b1756f4e72ba022b4d23931f04","c2cdb41dd9ef4882b10489d46cc010bb","d8cb5c9c3875446693e58f05a930729a","86bc9f4185484dc3a13daefeda3cee4a","f5283c6b09f144b0b55202a32786ab8f","3b4820a76a8a4c49b3b8214c853a02de","9c9f7132899c488ca00ad9d144b5f767","94cf9194172248709f3311a7713939de","e46fac48ac774a8b9d4df0c3e610280f","14aea7e9a33a4ee9b2967b31c1446176","13dd23403570440bbf414f3ab4637207","d1233d27d4a04558b1d7332658f13516","e0fd2661b1e74be68e350d6c1191b48c","802d1e1e5d3a4bf1bebda90d76f5a9ef","7a1e75cc3fb246e38224b5a7e2dd60a5","b40f7f6ff0a64d419c9b54cb009aae2e","c7be70b0bbf9443c8398bc2e42a9a5e0","f6795a7b9ffa4be7a442f2ddb1c4b146","16a902921e284854a1b49a643a715191","e255d6e4e16640e18e6872540c574031","4e04e31ef085472a8d7886c80b6e1092","312fbb873f604218b303a717682c8b9c","6cc034c4a3ad4882904f153e6f4ffaa6","54124b06eaa842fab6dfff3ddd59e207","61f25177de8642df8d5a06f9dfafb037","b0e747dffd434ad2ae2f95bcba91c512","775a008d2b474df0a7028ba54b9a0d8b","4fea7e7dd74d49d0882bbde3d910f058","2248adf3a5b44caf84bf4d353de31cb5","bc96930161694ad9822e9671692c77de","ec0986982e604d68bc2203a919e99c84","f3befa7bd3c54eaea1f834cc99e00277","d5b01adc62244065a6282fe35fd486af","1d03be04ffb24e5eadb4a92de8fda9e2","290625d918364fe2b6f83998179ed704","d49ab921dd64494881cac367e04242d2","520dfb6a2cb24ecd8368c43e80aaa7ff","3bbd018cc1394be9ae955bdc92d76094","bc81485e69e04e31a7c17a9dea64815a","d513680188ff4a23b12c5bea71bcfd33","98b4dd2cc3f948f5ad60d5fa7ea76d23","de4df67b01dd42a187eacbda8b23e448","24b4edbe1b334837b00fa3deb7908647"]},"executionInfo":{"status":"ok","timestamp":1638871805549,"user_tz":480,"elapsed":5230,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"aa50336e-98c0-472e-b3b2-44dbcf26380f"},"source":["from transformers import AutoTokenizer,BertTokenizerFast\n","\n","tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\",max_length=512) #, skip_special_tokens=True)\n","\n","#special_tokens_dict = {'additional_special_tokens': ['[SEP]','[FILLER]','[\\FILLER]']}\n","#num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8b6b8ec698774e06a1d39a512bbc98a4","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"13dd23403570440bbf414f3ab4637207","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"312fbb873f604218b303a717682c8b9c","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d5b01adc62244065a6282fe35fd486af","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aETyN_olnOGA","executionInfo":{"status":"ok","timestamp":1638856926430,"user_tz":480,"elapsed":11,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06154810530490924203"}},"outputId":"ab68e186-aba3-4526-fc91-1e24f8d39a21"},"source":["'''\n","decoder_tokenizer.cls_token = decoder_tokenizer.bos_token\n","decoder_tokenizer.sep_token = decoder_tokenizer.eos_token\n","decoder_tokenizer.pad_token = decoder_tokenizer.eos_token\n","encoder_tokenizer.pad_token = decoder_tokenizer.eos_token\n","'''\n","\n","print(tokenizer.cls_token,tokenizer.sep_token,tokenizer.bos_token,tokenizer.eos_token,tokenizer.pad_token,tokenizer.sep_token_id,tokenizer.pad_token_id)\n","print(tokenizer.special_tokens_map)\n","print(tokenizer.vocab_size)\n","#print(decoder_tokenizer.cls_token,decoder_tokenizer.sep_token,decoder_tokenizer.bos_token,decoder_tokenizer.eos_token,decoder_tokenizer.pad_token,decoder_tokenizer.sep_token_id,decoder_tokenizer.pad_token_id)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using bos_token, but it is not set yet.\n","Using eos_token, but it is not set yet.\n"]},{"output_type":"stream","name":"stdout","text":["[CLS] [SEP] None None [PAD] 102 0\n","{'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}\n","30522\n"]}]},{"cell_type":"code","metadata":{"id":"STcaFc6xJMOR"},"source":["'''\n","from transformers import AutoModelForSequenceClassification\n","\n","roberta_new = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\",num_labels=3)\n","\n","\n","print(roberta_new.get_input_embeddings())\n","\n","roberta_new.resize_token_embeddings(len(tokenizer))\n","\n","print(roberta_new.get_input_embeddings())\n","\n","roberta_new.save_pretrained(project_path+'Saved_Models/PLAUSIBILITY_CLASSIFICATION_ROBERTA_1/')\n","'''\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6HsV4dm8j9qT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638871814539,"user_tz":480,"elapsed":9000,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"86783dee-d509-4615-e980-b39ec05f77c1"},"source":["from transformers import AutoModelForSequenceClassification\n","model = AutoModelForSequenceClassification.from_pretrained(project_path+'Saved_Models/Training_1/Plausibility_Classification_Bert_1/Final_Bert_Not_Scratch',num_labels=3) #########"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_1/Final_Bert_Not_Scratch were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_1/Final_Bert_Not_Scratch and are newly initialized: ['classifier.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pMamweLLLhWz","executionInfo":{"status":"ok","timestamp":1638856934145,"user_tz":480,"elapsed":8,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06154810530490924203"}},"outputId":"8f2a7fe2-c6b7-43cb-87bc-d87aa12a2890"},"source":["#model.config.decoder.add_cross_attention=True\n","#print(model.config.decoder)\n","print(model.get_input_embeddings())\n","print(model.config.pad_token_id)\n","#model.save_pretrained(project_path+'Saved_Models/BertGPT_2_decoder_cross_attention')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Embedding(30522, 768, padding_idx=0)\n","0\n"]}]},{"cell_type":"code","metadata":{"id":"cWzHwcz6BEeo"},"source":["#led_tokenizer = AutoTokenizer.from_pretrained(\"allenai/led-base-16384\")\n","#led_model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/led-base-16384\", gradient_checkpointing=True, use_cache=False,)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":800},"id":"MmYQNbcc44J4","executionInfo":{"status":"ok","timestamp":1638871825087,"user_tz":480,"elapsed":10559,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"e3c33186-901c-4933-bc7c-7bb3075ac5b4"},"source":["!pip install datasets==1.2.1\n","!pip install rouge_score"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets==1.2.1\n","  Downloading datasets-1.2.1-py3-none-any.whl (159 kB)\n","\u001b[K     |████████████████████████████████| 159 kB 5.1 MB/s \n","\u001b[?25hCollecting tqdm<4.50.0,>=4.27\n","  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n","\u001b[K     |████████████████████████████████| 69 kB 7.2 MB/s \n","\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (0.70.12.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (4.8.2)\n","Collecting xxhash\n","  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n","\u001b[K     |████████████████████████████████| 243 kB 42.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (1.19.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (1.1.5)\n","Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (3.0.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (0.3.4)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (2.23.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.2.1) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.2.1) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.2.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.2.1) (2021.10.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==1.2.1) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==1.2.1) (3.10.0.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.2.1) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.2.1) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.2.1) (1.15.0)\n","Installing collected packages: xxhash, tqdm, datasets\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.62.3\n","    Uninstalling tqdm-4.62.3:\n","      Successfully uninstalled tqdm-4.62.3\n","Successfully installed datasets-1.2.1 tqdm-4.49.0 xxhash-2.0.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tqdm"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting rouge_score\n","  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge_score) (3.2.5)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.15.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.19.5)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge_score) (0.12.0)\n","Installing collected packages: rouge-score\n","Successfully installed rouge-score-0.0.4\n"]}]},{"cell_type":"code","metadata":{"id":"f7M0Ok_QAaHI","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["f49d23ac8d7044699b8a6f073a415f79","8b3040a7490a471ab8c37dbb5d620ebc","df844a0420eb4e9f8af621051f1c0b37","909bfe6d1fb04f3a9c29ce7f14a6945e","3f6d8b122f1f4096add1cad3a78bcda3","3e60f2b4fa2c498ebefdcecb9d77c037","80cd636efc2e4407b8703a5fbfc94b33","63b243a803164fa184c9cca0ef34980a","604cd29b6d094286a6056d200b6a9b60","61cac9103c1145b6ac0116c1b8aad997","02abd2e482bc42fd99dd5a202b052912"]},"executionInfo":{"status":"ok","timestamp":1638871826496,"user_tz":480,"elapsed":1415,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"2062b76a-464e-41a0-a805-801751f6b8b7"},"source":["#from transformers import logging ################\n","#logging.set_verbosity_info() #####################\n","\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","\n","from datasets import load_dataset, load_metric\n","from transformers import (\n","    Trainer,\n","    TrainingArguments,\n","    AutoTokenizer,\n",")\n","\n","#tokenizer = tokenizer\n","\n","# load rouge\n","metric = load_metric(\"accuracy\")\n","\n","# compute Rouge score during validation\n","def compute_metrics(pred):\n","    logits, labels = pred\n","    predictions = np.argmax(logits, axis=-1)\n","\n","    accuracy = metric.compute(predictions=predictions, references=labels)['accuracy']\n","\n","    micro_f1 = f1_score(labels, predictions, average='micro')\n","    macro_f1 = f1_score(labels, predictions, average='macro')\n","    weighted_f1 = f1_score(labels, predictions, average='weighted')\n","\n","\n","\n","    return {\n","        \"Accuracy\": accuracy,\n","        \"micro_F1\": round(micro_f1, 4),\n","        \"macro_F1\": round(macro_f1, 4),\n","        \"weighted_F1\": round(weighted_f1, 4),\n","    }\n"],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f49d23ac8d7044699b8a6f073a415f79","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.25k [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":974},"id":"9RKQPr9zbjFE","executionInfo":{"status":"ok","timestamp":1638871839993,"user_tz":480,"elapsed":13509,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"8a4f5779-f745-4a7d-a53c-23903908b1b1"},"source":["!pip install wandb\n","\n","import wandb\n","wandb.login()\n","\n","%env WANDB_PROJECT=Plausibility_Clarification_PT_Bert_FT_Training_2_2"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wandb\n","  Downloading wandb-0.12.7-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 5.3 MB/s \n","\u001b[?25hCollecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n","\u001b[K     |████████████████████████████████| 180 kB 52.4 MB/s \n","\u001b[?25hCollecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.5.0-py2.py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 48.8 MB/s \n","\u001b[?25hCollecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Collecting yaspin>=1.0.0\n","  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting configparser>=3.8.1\n","  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting subprocess32>=3.5.3\n","  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 5.4 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n","Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n","Building wheels for collected packages: subprocess32, pathtools\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=712c8a9f7fff94b315dd7d71bed0d4fec7c96354aebb08e7d086039ce473c61f\n","  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=bbccdcd507f6cb9aa8fb063d255a5202c4360f7c6fc49f9e6b2a62f3ecb19f5d\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built subprocess32 pathtools\n","Installing collected packages: smmap, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n","Successfully installed GitPython-3.1.24 configparser-5.2.0 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.0 shortuuid-1.0.8 smmap-5.0.0 subprocess32-3.5.4 wandb-0.12.7 yaspin-2.1.0\n"]},{"output_type":"display_data","data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"stream","name":"stdout","text":["env: WANDB_PROJECT=Plausibility_Clarification_PT_Bert_FT_Training_2_2\n"]}]},{"cell_type":"code","metadata":{"id":"z3u4_AvV5ysj","executionInfo":{"status":"ok","timestamp":1638871839995,"user_tz":480,"elapsed":12,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}}},"source":["batch_size = 8 ####################\n","\n","\n","\n","training_args = TrainingArguments(\n","    evaluation_strategy=\"steps\",\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    #fp16=True,\n","    #fp16_backend=\"apex\",\n","    output_dir=project_path+'Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/',\n","    logging_dir = project_path+'Saved_Logs/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/',\n","    num_train_epochs = 20,  ##########################################################\n","    logging_steps=10, #250,\n","    eval_steps=50,  # 200, #5000,\n","    save_steps=50, #200, #500,\n","    warmup_steps=1, #1500,\n","    #save_total_limit=2,\n","    gradient_accumulation_steps=32, ############################################################\n","    load_best_model_at_end = False,\n","    #resume_from_checkpoint = project_path+'Saved_Models/Training_1/checkpoint-1500',\n","    report_to=\"wandb\",  # enable logging to W&B\n","    run_name=\"plausibility-classification-PT-Bert-FT-run-2-2\",  # name of the W&B run (optional)\n",")\n","\n","\n","# BEST TO ME by Accuracy (project_path+'Saved_Logs/Training_1/Plausibility_Classification_Roberta_1/checkpoint-150')\n","# BEST TO ME by Validation Loss "],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2b3818e33f9d41a1a801b25716ae6d43","7968e59ba0554b03b0d78b9d81466c42","4c2064e4f30c4b0ea9ae3ed1ea3221c8","4218066aa45549ee8de7ebfe49cfbc1d","164a1f1074a44f63b5b8ffffa9e553d6","6b29833292c04e38ba2bb9262aa39c22","6965dc6e51574a7a9f99b249ffb57c38","18a213b806644289be60aa42ca6fc3f3","6a6b398a9c154b739285680cec09f191","5c1fdbe247354cd28672a30074d87fd2","01823f26b78a4979a2f7675a06f0d1ab"]},"id":"NyBM4sbOXzeA","outputId":"60f15da9-0d95-442b-d331-699135076e39"},"source":["# instantiate trainer BATCH SIZE = 8 ############\n","trainer = Trainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    #data_collator=data_collator,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    train_dataset= shuffled_train_dataset,  #train_dataset,  ########################################\n","    eval_dataset=test_dataset,  # val_dataset, \n",")\n","\n","# start training\n","#trainer.train()\n","trainer.train(project_path+'Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-400')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Loading model from /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-400).\n","***** Running training *****\n","  Num examples = 17960\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 256\n","  Gradient Accumulation steps = 32\n","  Total optimization steps = 1400\n","  Continuing training from checkpoint, will skip to saved global_step\n","  Continuing training from epoch 5\n","  Continuing training from global step 400\n","  Will skip the first 5 epochs then the first 1600 batches in the first epoch. If this takes a lot of time, you can add the `--ignore_data_skip` flag to your launch command, but you will resume the training on data already seen by your model.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b3818e33f9d41a1a801b25716ae6d43","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1600 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtawkat\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_PT_Bert_FT_Training_2_2/runs/36j88gun\" target=\"_blank\">plausibility-classification-PT-Bert-FT-run-2-2</a></strong> to <a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_PT_Bert_FT_Training_2_2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='611' max='1400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 611/1400 3:36:37 < 13:37:47, 0.02 it/s, Epoch 8.71/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Micro F1</th>\n","      <th>Macro F1</th>\n","      <th>Weighted F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>450</td>\n","      <td>0.526800</td>\n","      <td>1.572097</td>\n","      <td>0.433200</td>\n","      <td>0.433200</td>\n","      <td>0.419500</td>\n","      <td>0.452800</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.421400</td>\n","      <td>1.540317</td>\n","      <td>0.464400</td>\n","      <td>0.464400</td>\n","      <td>0.439600</td>\n","      <td>0.481000</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.436700</td>\n","      <td>1.541960</td>\n","      <td>0.468800</td>\n","      <td>0.468800</td>\n","      <td>0.435900</td>\n","      <td>0.477600</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.366500</td>\n","      <td>1.804356</td>\n","      <td>0.457200</td>\n","      <td>0.457200</td>\n","      <td>0.425500</td>\n","      <td>0.463100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-450\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-450/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-450/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-450/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-450/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-500\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-500/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-550\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-550/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-550/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-550/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-550/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-600\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-600/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-600/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-600/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-600/special_tokens_map.json\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["5b68fb8a43014f0fb078d20bc45eb4b7","7847bb441c8b463a80c8bc6631f34952","21246d2a24c94b3f8ce46173a537700d","8ffcfbc95b9743d1ba185c143894f9e4","07682d2610174a8d80fe21e67281bc86","a0f1f100f4544c3e8493e6d72739594d","d8ae5cd9a37b472bab8f157bb43fb51e","9796207fc0ff4ae5923211b47c7ef429","53db968e776b4072bac0df7ffc41c114","b756936f333244a6a78a113ab104dc4e","5b8585d58fad492c822d0cf9aa52c1e3"]},"id":"KFwapc5OfAIG","outputId":"09de30ff-1586-4f98-859f-87e34e0a75bf"},"source":["# instantiate trainer BATCH SIZE = 8 ############\n","trainer = Trainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    #data_collator=data_collator,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    train_dataset= shuffled_train_dataset,  #train_dataset,  ########################################\n","    eval_dataset=test_dataset,  # val_dataset, \n",")\n","\n","# start training\n","#trainer.train()\n","trainer.train(project_path+'Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-200')"],"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Loading model from /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-200).\n","***** Running training *****\n","  Num examples = 17960\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 256\n","  Gradient Accumulation steps = 32\n","  Total optimization steps = 1400\n","  Continuing training from checkpoint, will skip to saved global_step\n","  Continuing training from epoch 2\n","  Continuing training from global step 200\n","  Will skip the first 2 epochs then the first 1920 batches in the first epoch. If this takes a lot of time, you can add the `--ignore_data_skip` flag to your launch command, but you will resume the training on data already seen by your model.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5b68fb8a43014f0fb078d20bc45eb4b7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1920 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtawkat\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_PT_Bert_FT_Training_2_2/runs/2m7j3ljl\" target=\"_blank\">plausibility-classification-PT-Bert-FT-run-2-2</a></strong> to <a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_PT_Bert_FT_Training_2_2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='204' max='1400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 204/1400 01:24 < 14:07:08, 0.02 it/s, Epoch 2.90/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='425' max='1400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 425/1400 2:50:31 < 12:25:33, 0.02 it/s, Epoch 6.06/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Micro F1</th>\n","      <th>Macro F1</th>\n","      <th>Weighted F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>250</td>\n","      <td>0.789000</td>\n","      <td>1.177341</td>\n","      <td>0.445200</td>\n","      <td>0.445200</td>\n","      <td>0.425200</td>\n","      <td>0.463500</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.646100</td>\n","      <td>1.367650</td>\n","      <td>0.498400</td>\n","      <td>0.498400</td>\n","      <td>0.451400</td>\n","      <td>0.494800</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.681600</td>\n","      <td>1.245178</td>\n","      <td>0.467200</td>\n","      <td>0.467200</td>\n","      <td>0.446500</td>\n","      <td>0.485700</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.558900</td>\n","      <td>1.410590</td>\n","      <td>0.472800</td>\n","      <td>0.472800</td>\n","      <td>0.436100</td>\n","      <td>0.477600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-250\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-250/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-250/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-250/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-250/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-300\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-300/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-300/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-300/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-300/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-350\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-350/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-350/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-350/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-350/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-400\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-400/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-400/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-400/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-400/special_tokens_map.json\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":933},"id":"NNhbo3gLBvw0","outputId":"d88daee5-d232-46d4-b328-fed4d34ad125"},"source":["# instantiate trainer BATCH SIZE = 8 ############\n","trainer = Trainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    #data_collator=data_collator,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    train_dataset= shuffled_train_dataset,  #train_dataset,  ########################################\n","    eval_dataset=test_dataset,  # val_dataset, \n",")\n","\n","# start training\n","trainer.train()\n","#trainer.train(project_path+'Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_2/checkpoint-950')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running training *****\n","  Num examples = 17960\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 256\n","  Gradient Accumulation steps = 32\n","  Total optimization steps = 1400\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"]},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_PT_Bert_FT_Training_2_2/runs/299w9xkl\" target=\"_blank\">plausibility-classification-PT-Bert-FT-run-2-2</a></strong> to <a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_PT_Bert_FT_Training_2_2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='244' max='1400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 244/1400 3:20:03 < 15:55:41, 0.02 it/s, Epoch 3.47/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Micro F1</th>\n","      <th>Macro F1</th>\n","      <th>Weighted F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>1.084400</td>\n","      <td>1.134654</td>\n","      <td>0.279200</td>\n","      <td>0.279200</td>\n","      <td>0.245500</td>\n","      <td>0.246000</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.062100</td>\n","      <td>1.089177</td>\n","      <td>0.452400</td>\n","      <td>0.452400</td>\n","      <td>0.344700</td>\n","      <td>0.401400</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.950700</td>\n","      <td>1.149360</td>\n","      <td>0.512800</td>\n","      <td>0.512800</td>\n","      <td>0.403900</td>\n","      <td>0.474400</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.917400</td>\n","      <td>1.107851</td>\n","      <td>0.452400</td>\n","      <td>0.452400</td>\n","      <td>0.420200</td>\n","      <td>0.462800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-50\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-50/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-50/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-50/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-50/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-100\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-100/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-100/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-100/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-100/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-150\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-150/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-150/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-150/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-150/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-200\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-200/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-200/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-200/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_More_Grad_Acc_2_2/checkpoint-200/special_tokens_map.json\n"]}]},{"cell_type":"code","metadata":{"id":"q6Jw1xvqFXKs","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["da7d10b015e343aa8432ebcfaf1156ec","57ff156cc217458ca6474447ce109c39","d667e961aeb34e81992b156322d9293b","5bc50d99240b453b97f5619f21cbc1b7","223feddf885d41b496cd3b8ec8e4c4cb","3c4db238cf3b443f9b504d2a44e29507","6702b199003c47cf9816fe821820cca7","4e1a1f5b876147a6a3a321ff9c4177b0","2fa8404da68f447aa8618e253d697652","64e1bcf1014d495aa09f3c21ae90f3ac","c8fe97bdbcb54b178a9b63d3414236cd"]},"executionInfo":{"status":"error","timestamp":1638603438604,"user_tz":480,"elapsed":1896906,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06154810530490924203"}},"outputId":"9988cb3f-166e-4d98-c662-29661f54fbe7"},"source":["# instantiate trainer BATCH SIZE = 8 ############\n","trainer = Trainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    #data_collator=data_collator,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    train_dataset= shuffled_train_dataset,  #train_dataset,  ########################################\n","    eval_dataset=test_dataset,  # val_dataset, \n",")\n","\n","# start training\n","#trainer.train()\n","trainer.train(project_path+'Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-700')"],"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Loading model from /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-700).\n","***** Running training *****\n","  Num examples = 17960\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 8\n","  Total optimization steps = 5600\n","  Continuing training from checkpoint, will skip to saved global_step\n","  Continuing training from epoch 2\n","  Continuing training from global step 700\n","  Will skip the first 2 epochs then the first 1120 batches in the first epoch. If this takes a lot of time, you can add the `--ignore_data_skip` flag to your launch command, but you will resume the training on data already seen by your model.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da7d10b015e343aa8432ebcfaf1156ec","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1120 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtawkat\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_RoBerta_Training_1/runs/30ocn50o\" target=\"_blank\">plausibility-classification-RoBerta-run-1</a></strong> to <a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_RoBerta_Training_1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='891' max='5600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 891/5600 45:27 < 18:52:27, 0.07 it/s, Epoch 3.18/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Micro F1</th>\n","      <th>Macro F1</th>\n","      <th>Weighted F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>750</td>\n","      <td>1.075700</td>\n","      <td>1.117875</td>\n","      <td>0.357200</td>\n","      <td>0.357200</td>\n","      <td>0.349200</td>\n","      <td>0.377100</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>1.032600</td>\n","      <td>1.170667</td>\n","      <td>0.281200</td>\n","      <td>0.281200</td>\n","      <td>0.281800</td>\n","      <td>0.282500</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>1.011100</td>\n","      <td>1.122727</td>\n","      <td>0.436000</td>\n","      <td>0.436000</td>\n","      <td>0.363500</td>\n","      <td>0.419100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-750\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-750/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-750/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-750/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-750/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-800\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-800/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-800/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-800/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-800/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-850\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-850/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-850/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-850/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-850/special_tokens_map.json\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1001' max='5600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1001/5600 1:12:38 < 18:37:23, 0.07 it/s, Epoch 3.57/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Micro F1</th>\n","      <th>Macro F1</th>\n","      <th>Weighted F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>750</td>\n","      <td>1.075700</td>\n","      <td>1.117875</td>\n","      <td>0.357200</td>\n","      <td>0.357200</td>\n","      <td>0.349200</td>\n","      <td>0.377100</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>1.032600</td>\n","      <td>1.170667</td>\n","      <td>0.281200</td>\n","      <td>0.281200</td>\n","      <td>0.281800</td>\n","      <td>0.282500</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>1.011100</td>\n","      <td>1.122727</td>\n","      <td>0.436000</td>\n","      <td>0.436000</td>\n","      <td>0.363500</td>\n","      <td>0.419100</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.955600</td>\n","      <td>1.234073</td>\n","      <td>0.320000</td>\n","      <td>0.320000</td>\n","      <td>0.320900</td>\n","      <td>0.330200</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.940900</td>\n","      <td>1.189740</td>\n","      <td>0.371600</td>\n","      <td>0.371600</td>\n","      <td>0.361800</td>\n","      <td>0.391500</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.983600</td>\n","      <td>1.288924</td>\n","      <td>0.282000</td>\n","      <td>0.282000</td>\n","      <td>0.265600</td>\n","      <td>0.266000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-900\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-900/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-900/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-900/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-900/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-950\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-950/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-950/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-950/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-950/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-1000\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-1000/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-1000/special_tokens_map.json\n"]},{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-bcda2b4c7839>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#trainer.train()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-700'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1388\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1509\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1510\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   1624\u001b[0m         \u001b[0;31m# Save the Trainer state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1626\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAINER_STATE_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m         \u001b[0;31m# Save RNG state in non-distributed training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36msave_to_json\u001b[0;34m(self, json_path)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;34m\"\"\"Save the content of this instance in JSON format inside :obj:`json_path`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mjson_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error: '/content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-1000/trainer_state.json'"]}]},{"cell_type":"code","metadata":{"id":"KmmTpD9BjNXM","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"b0bb78f2-8424-49d7-e64f-cac5bf6000a6"},"source":["# instantiate trainer BATCH SIZE = 8 ############\n","trainer = Trainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    #data_collator=data_collator,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    train_dataset= shuffled_train_dataset,  #train_dataset,  ########################################\n","    eval_dataset=test_dataset,  # val_dataset, \n",")\n","\n","# start training\n","trainer.train()\n","#trainer.train(project_path+'Saved_Logs/Training_1/Plausibility_Classification_Roberta_1/checkpoint-850')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running training *****\n","  Num examples = 17960\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 8\n","  Total optimization steps = 5600\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtawkat\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_RoBerta_Training_1/runs/b6gw0hku\" target=\"_blank\">plausibility-classification-RoBerta-run-1</a></strong> to <a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_RoBerta_Training_1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='711' max='5600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 711/5600 2:57:06 < 20:21:12, 0.07 it/s, Epoch 2.53/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Micro F1</th>\n","      <th>Macro F1</th>\n","      <th>Weighted F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>1.108000</td>\n","      <td>1.125301</td>\n","      <td>0.333200</td>\n","      <td>0.333200</td>\n","      <td>0.281900</td>\n","      <td>0.290100</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.097300</td>\n","      <td>1.162198</td>\n","      <td>0.178000</td>\n","      <td>0.178000</td>\n","      <td>0.106300</td>\n","      <td>0.060700</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>1.105100</td>\n","      <td>1.140031</td>\n","      <td>0.220400</td>\n","      <td>0.220400</td>\n","      <td>0.176500</td>\n","      <td>0.154600</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.091600</td>\n","      <td>1.099588</td>\n","      <td>0.437600</td>\n","      <td>0.437600</td>\n","      <td>0.234400</td>\n","      <td>0.295300</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>1.088200</td>\n","      <td>1.091331</td>\n","      <td>0.422000</td>\n","      <td>0.422000</td>\n","      <td>0.234600</td>\n","      <td>0.285200</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.089900</td>\n","      <td>1.208503</td>\n","      <td>0.228800</td>\n","      <td>0.228800</td>\n","      <td>0.191900</td>\n","      <td>0.178200</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>1.098400</td>\n","      <td>1.130554</td>\n","      <td>0.276800</td>\n","      <td>0.276800</td>\n","      <td>0.267800</td>\n","      <td>0.267700</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.086200</td>\n","      <td>1.120622</td>\n","      <td>0.399600</td>\n","      <td>0.399600</td>\n","      <td>0.332200</td>\n","      <td>0.372700</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>1.093800</td>\n","      <td>1.138465</td>\n","      <td>0.327600</td>\n","      <td>0.327600</td>\n","      <td>0.308000</td>\n","      <td>0.326100</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>1.069800</td>\n","      <td>1.185204</td>\n","      <td>0.233600</td>\n","      <td>0.233600</td>\n","      <td>0.221300</td>\n","      <td>0.206500</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>1.070700</td>\n","      <td>1.165409</td>\n","      <td>0.406400</td>\n","      <td>0.406400</td>\n","      <td>0.290400</td>\n","      <td>0.323400</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>1.013800</td>\n","      <td>1.248552</td>\n","      <td>0.287600</td>\n","      <td>0.287600</td>\n","      <td>0.260500</td>\n","      <td>0.266400</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>1.031400</td>\n","      <td>1.207353</td>\n","      <td>0.230400</td>\n","      <td>0.230400</td>\n","      <td>0.206800</td>\n","      <td>0.187000</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>1.056400</td>\n","      <td>1.077277</td>\n","      <td>0.417600</td>\n","      <td>0.417600</td>\n","      <td>0.338600</td>\n","      <td>0.387800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-50\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-50/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-50/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-50/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-50/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-100\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-100/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-100/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-100/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-100/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-150\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-150/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-150/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-150/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-150/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-200\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-200/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-200/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-200/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-200/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-250\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-250/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-250/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-250/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-250/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-300\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-300/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-300/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-300/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-300/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-350\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-350/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-350/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-350/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-350/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-400\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-400/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-400/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-400/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-400/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-450\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-450/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-450/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-450/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-450/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-500\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-500/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-550\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-550/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-550/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-550/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-550/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-600\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-600/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-600/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-600/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-600/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-650\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-650/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-650/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-650/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-650/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-700\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-700/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-700/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-700/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-700/special_tokens_map.json\n"]}]},{"cell_type":"markdown","metadata":{"id":"FMkR5GX8qEIB"},"source":["# **Testing**"]},{"cell_type":"code","metadata":{"id":"lSJ7XnOTwP2g"},"source":["class_names = [\"IMPLAUSIBLE\", \"NEUTRAL\", \"PLAUSIBLE\"]\n","\n","LABEL_DICT = {}\n","LABEL_DICT[class_names[0]] = 0\n","LABEL_DICT[class_names[1]] = 1\n","LABEL_DICT[class_names[2]] = 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"to0VNWg5GMti","executionInfo":{"status":"ok","timestamp":1625751778126,"user_tz":-360,"elapsed":429,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"a2ccccfd-25e1-4629-c1be-44f3fcd424c2"},"source":["print(tokenizer.batch_decode(train_dataset[499:500]['input_ids']))\n","\n","labels_ids = train_dataset[499:500]['labels']#[test_dataset[499:500]['labels'] == -100] = tokenizer.pad_token_id\n","labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n","#print(labels_ids)\n","output = tokenizer.batch_decode(labels_ids, skip_special_tokens=False)\n","print(output[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[\"solve: def sat(x: List[int], a: int=-165, r: int=1, l: int=42): assert type(x) is list and all(type(a) is int for a in x), 'x must be of type List[int]' return x[0] == a and len(x) == l and all([x[i] * r == x[i + 1] for i in range(len(x) - 1)])</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\"]\n","sol(a=-165, r=1, l=42): return [a * r ** i for i in range(l)]</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AUCrq4edW5j3","executionInfo":{"status":"ok","timestamp":1625751805282,"user_tz":-360,"elapsed":452,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"a2743cbd-eb9a-4148-af60-5bbae0b62f74"},"source":["print(tokenizer.special_tokens_map)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': \"['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']\"}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BinEuSh8YNuf"},"source":["accuracy = Accuracy(actual_str,output_str)\n","sommth_bleu_score = round(_bleu(actual_str, output_str),2)\n","\n","print(accuracy)\n","print(sommth_bleu_score)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gkSfUBOkDlId"},"source":["from transformers import AutoModelForSequenceClassification\n","model = AutoModelForSequenceClassification.from_pretrained(project_path+'Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-850',num_labels=3)\n","model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mq4qCzaGCn_V"},"source":["start = 200\n","end = 210\n","model.eval()\n","outputs = model(input_ids=test_dataset[start:end]['input_ids'].to(device),attention_mask=test_dataset[start:end]['attention_mask'].to(device))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-dG9P0chEGMJ","executionInfo":{"status":"ok","timestamp":1636787048297,"user_tz":480,"elapsed":621,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12040636431562290492"}},"outputId":"e43eb3a5-481b-4fac-b44f-f708c5ccff4c"},"source":["print(np.argmax(outputs.logits.detach().cpu().numpy(),axis=1))\n","print(test_dataset[start:end]['labels'])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2 2 2 2 2 2 2 2 2 2]\n","tensor([0, 0, 1, 2, 1, 0, 1, 0, 0, 2])\n"]}]},{"cell_type":"code","metadata":{"id":"JTPCopoGZzTd"},"source":["total_output_str=[]\n","batch_size = 100\n","\n","curr = 0\n","for i in range(0,len(test_dataset),batch_size):\n","  end = min(i+batch_size,len(test_dataset))\n","  code_tokens = ed.generate(input_ids=test_dataset[i:end]['input_ids'].to(device),attention_mask=test_dataset[i:end]['attention_mask'].to(device))\n","  \n","  codes = decoder_tokenizer.batch_decode(code_tokens,skip_special_tokens=True)\n","\n","  for c in codes:\n","    total_output_str.append(c)\n","  print(i)\n","  if(end == len(test_dataset)):\n","    break\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RwXy5K__TnQ1","executionInfo":{"status":"ok","timestamp":1624463170470,"user_tz":-360,"elapsed":12,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"b288768f-b9c7-4541-8ad5-17bf675fd7cd"},"source":["print(len(total_output_str))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["6545\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XnxauUisXJ14"},"source":["class Example(object):\n","    \"\"\"A single training/test example.\"\"\"\n","    def __init__(self,\n","                 idx,\n","                 source,\n","                 target,\n","                 ):\n","        self.idx = idx\n","        self.source = source\n","        self.target = target"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r1haZjJ8Xe8E"},"source":["import pickle\n","with open(project_path+'Pickles/pickle_test_buggy_fixed_1.pickle', 'rb') as f:\n","  test_examples = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K5vm5E9gXgfR","executionInfo":{"status":"ok","timestamp":1624463170958,"user_tz":-360,"elapsed":15,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"296d3f96-a55a-463f-b3fe-41be9de8f284"},"source":["total_actual_str=[]\n","\n","for te in test_examples:\n","  total_actual_str.append(te.target)\n","\n","print(len(total_actual_str))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["6545\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bFQg6nPQnmKh"},"source":["import pickle\n","with open(project_path+'Pickles/pickle_pred_test_buggy_fixed_13000_1.pickle', 'wb') as f:\n","  pickle.dump((total_actual_str,total_output_str),f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D6m6Eu4uoEUl"},"source":["import pickle\n","with open(project_path+'Pickles/pickle_pred_test_buggy_fixed_13000_1.pickle', 'rb') as f:\n","  total_actual_str,total_output_str = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bDwUATPdX0JK","executionInfo":{"status":"ok","timestamp":1624464471028,"user_tz":-360,"elapsed":414,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"a8eca143-6574-43a2-db93-e0e02885563d"},"source":["print(total_actual_str[100])\n","print(total_output_str[100])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["public void METHOD_1 ( ) { TYPE_1 query = new TYPE_1 ( ) ; TYPE_2 VAR_1 = TYPE_3 . METHOD_2 ( VAR_2 class ) ; TYPE_3 . METHOD_3 ( VAR_1 . getId ( ) ) . METHOD_4 ( 1 ) ; TYPE_3 . METHOD_5 ( VAR_1 ) ; java.lang.Long count = VAR_3 . METHOD_6 ( VAR_1 , query ) ; TYPE_4 . assertEquals ( INT_2 , count . METHOD_7 ( ) ) ; }\n","public void METHOD_1 ( ) { TYPE_1 query = new TYPE_1 ( ) ; TYPE_2 VAR_1 = TYPE_3. METHOD_2 ( VAR_2 class ) ; TYPE_3. METHOD_3 ( VAR_1. getId ( ) ). METHOD_4 ( INT_1 ) ; TYPE_3. METHOD_5 ( VAR_1 ) ; java.lang.Long count = VAR_3. METHOD_6 ( VAR_1, query ) ; TYPE_4. assertEquals ( INT_2, count. METHOD_7 ( ) ) ; }\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KUFMXJPrxaqs","executionInfo":{"status":"ok","timestamp":1624464289031,"user_tz":-360,"elapsed":3404,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"5283b33f-8801-4c03-92a2-3489af3fa4de"},"source":["accuracy = Accuracy(total_actual_str,total_output_str)\n","sommth_bleu_score = round(_bleu(total_actual_str, total_output_str),2)\n","\n","print(accuracy)\n","print(sommth_bleu_score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[['public', 'java.lang.String', 'METHOD_1', '(', ')', '{', 'if', '(', '(', 'METHOD_2', '(', ')', ')', '&&', '(', 'METHOD_3', '(', 'VAR_1', '.', 'METHOD_4', '(', ')', ')', ')', ')', '{', 'return', 'VAR_1', '.', 'METHOD_4', '(', ')', ';', '}', 'else', 'if', '(', 'METHOD_3', '(', 'VAR_3', '.', 'METHOD_5', '(', ')', '.', 'METHOD_6', '(', ')', ')', ')', '{', 'return', 'VAR_3', '.', 'METHOD_5', '(', ')', '.', 'METHOD_6', '(', ')', ';', '}', 'else', '{', 'return', 'VAR_4', '.', 'METHOD_4', '(', ')', ';', '}', '}'], ['private', 'void', 'METHOD_1', '(', 'TYPE_1', 'index', ',', 'java.util.Collection', '<', 'TYPE_2', '>', 'VAR_1', ')', '{', 'TYPE_1', 'VAR_2', '=', 'index', '.', 'METHOD_2', '(', 'VAR_3', ')', ';', 'for', '(', 'TYPE_3', '<', 'TYPE_2', '>', 'VAR_4', ':', 'this', '.', 'VAR_1', '.', 'values', '(', ')', ')', '{', 'VAR_4', '.', 'METHOD_3', '(', 'VAR_2', ',', 'null', ')', ';', '}', 'METHOD_4', '(', 'index', ',', 'VAR_1', ')', ';', '}'], ['public', 'void', 'remove', '(', 'int', 'id', ')', '{', 'try', '{', 'java.lang.String', 'query', '=', 'STRING_1', ';', 'TYPE_1', 'VAR_1', '=', 'METHOD_1', '(', ')', ';', 'TYPE_2', 'VAR_2', '=', 'VAR_1', '.', 'METHOD_2', '(', 'query', ')', ';', 'VAR_2', '.', 'METHOD_3', '(', '1', ',', 'id', ')', ';', 'VAR_2', '.', 'METHOD_4', '(', ')', ';', '}', 'catch', '(', 'TYPE_3', 'VAR_3', ')', '{', 'java.lang.System.out.println', '(', 'STRING_2', ')', ';', '}', '}'], ['private', 'java.util.List', '<', 'TYPE_1', '>', 'METHOD_1', '(', ')', '{', 'java.util.List', '<', 'TYPE_1', '>', 'VAR_2', '=', 'new', 'java.util.ArrayList', '<', '>', '(', ')', ';', 'for', '(', 'int', 'i', '=', '0', ';', 'i', '<', '(', 'VAR_3', '.', 'size', '(', ')', ')', ';', 'i', '++', ')', '{', 'TYPE_1', 'VAR_1', '=', 'new', 'TYPE_1', '(', ')', ';', 'VAR_1', '.', 'METHOD_2', '(', 'VAR_3', '.', 'get', '(', 'i', ')', '.', 'METHOD_3', '(', ')', ')', ';', 'VAR_2', '.', 'add', '(', 'VAR_1', ')', ';', '}', 'return', 'VAR_2', ';', '}'], ['private', 'void', 'METHOD_1', '(', 'java.util.List', '<', 'TYPE_1', '>', 'parameters', ',', 'TYPE_2', 'VAR_1', ')', '{', 'while', '(', 'VAR_1', '.', 'METHOD_2', '(', ')', ')', '{', 'TYPE_3', 'VAR_2', '=', 'METHOD_3', '(', 'VAR_1', ')', ';', 'if', '(', 'VAR_2', '==', 'null', ')', '{', 'break', ';', '}', 'if', '(', 'VAR_2', '.', 'METHOD_4', '(', ')', ')', '{', 'METHOD_6', '(', 'parameters', ',', 'METHOD_7', '(', 'VAR_2', ')', ')', ';', '}', 'VAR_1', '=', '(', '(', 'TYPE_2', ')', '(', 'VAR_2', '.', 'METHOD_8', '(', ')', ')', ')', ';', '}', '}']]\n","[['public', 'java.lang.String', 'METHOD_1', '(', ')', '{', 'if', '(', '(', 'METHOD_2', '(', ')', ')', '&&', '(', 'METHOD_3', '(', 'VAR_1.', 'METHOD_4', '(', ')', ')', ')', ')', '{', 'return', 'VAR_2.', 'METHOD_4', '(', ')', ';', '}', 'else', 'if', '(', 'METHOD_3', '(', 'VAR_3.', 'METHOD_5', '(', ').', 'METHOD_6', '(', ')', ')', ')', '{', 'return', 'VAR_3.', 'METHOD_5', '(', ').', 'METHOD_6', '(', ')', ';', '}', 'else', '{', 'return', 'VAR_4.', 'METHOD_4', '(', ')', ';', '}', '}'], ['private', 'void', 'METHOD_1', '(', 'TYPE_1', 'index,', 'java.util.Collection', '<', 'TYPE_2', '>', 'VAR_1', ')', '{', 'TYPE_1', 'VAR_2', '=', 'index.', 'METHOD_2', '(', 'VAR_3', ')', ';', 'for', '(', 'TYPE_3', '<', 'TYPE_2', '>', 'VAR_4', ':', 'this.', 'VAR_1.', 'values', '(', ')', ')', '{', 'VAR_4.', 'METHOD_3', '(', 'VAR_2,', 'null', ')', ';', '}', 'METHOD_4', '(', 'VAR_2,', 'VAR_1', ')', ';', '}'], ['public', 'void', 'remove', '(', 'int', 'id', ')', '{', 'try', '{', 'java.lang.String', 'query', '=', 'STRING_1', ';', 'TYPE_1', 'VAR_1', '=', 'METHOD_1', '(', ')', ';', 'TYPE_2', 'VAR_2', '=', 'VAR_1.', 'METHOD_2', '(', 'query', ')', ';', 'VAR_2.', 'METHOD_3', '(', '1,', 'id', ')', ';', 'VAR_2.', 'METHOD_4', '(', ')', ';', '}', 'catch', '(', 'TYPE_3', 'VAR_3', ')', '{', 'VAR_3.', 'METHOD_5', '(', ')', ';', 'java.lang.System.out.println', '(', 'STRING_2', ')', ';', '}', '}'], ['private', 'java.util.List', '<', 'TYPE_1', '>', 'METHOD_1', '(', ')', '{', 'TYPE_1', 'VAR_1', '=', 'new', 'TYPE_1', '(', ')', ';', 'java.util.List', '<', 'TYPE_1', '>', 'VAR_2', '=', 'new', 'java.util.ArrayList', '<', '>', '(', ')', ';', 'for', '(', 'int', 'i', '=', '0', ';', 'i', '<', '(', 'VAR_3.', 'size', '(', ')', ')', ';', 'i', '++', ')', '{', 'VAR_1.', 'METHOD_2', '(', 'VAR_3.', 'get', '(', 'i', ').', 'METHOD_3', '(', ')', ')', ';', 'VAR_2.', 'add', '(', 'VAR_1', ')', ';', '}', 'return', 'VAR_2', ';', '}'], ['private', 'void', 'METHOD_1', '(', 'java.util.List', '<', 'TYPE_1', '>', 'parameters,', 'TYPE_2', 'VAR_1', ')', '{', 'while', '(', 'VAR_1.', 'METHOD_2', '(', ')', ')', '{', 'TYPE_3', 'VAR_2', '=', 'METHOD_3', '(', 'VAR_1', ')', ';', 'if', '(', 'VAR_2', '==', 'null', ')', '{', 'break', ';', '}', 'if', '(', 'TYPE_4.', 'METHOD_4', '(', 'VAR_2.', 'METHOD_5', '(', ')', ')', ')', '{', 'METHOD_6', '(', 'parameters,', 'METHOD_7', '(', 'VAR_2', ')', ')', ';', '}', 'VAR_1', '=', '(', '(', 'TYPE_2', ')', '(', 'VAR_2.', 'METHOD_8', '(', ')', ')', ')', ';', '}', '}']]\n","0.17\n","61.45\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IGGJYnLmxV7E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624464281813,"user_tz":-360,"elapsed":3807,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"647a87ea-6783-4c93-aa76-bf5a73740eea"},"source":["accuracy = Accuracy(total_actual_str,total_actual_str)\n","sommth_bleu_score = round(_bleu(total_actual_str, total_actual_str),2)\n","\n","print(accuracy)\n","print(sommth_bleu_score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[['public', 'java.lang.String', 'METHOD_1', '(', ')', '{', 'if', '(', '(', 'METHOD_2', '(', ')', ')', '&&', '(', 'METHOD_3', '(', 'VAR_1', '.', 'METHOD_4', '(', ')', ')', ')', ')', '{', 'return', 'VAR_1', '.', 'METHOD_4', '(', ')', ';', '}', 'else', 'if', '(', 'METHOD_3', '(', 'VAR_3', '.', 'METHOD_5', '(', ')', '.', 'METHOD_6', '(', ')', ')', ')', '{', 'return', 'VAR_3', '.', 'METHOD_5', '(', ')', '.', 'METHOD_6', '(', ')', ';', '}', 'else', '{', 'return', 'VAR_4', '.', 'METHOD_4', '(', ')', ';', '}', '}'], ['private', 'void', 'METHOD_1', '(', 'TYPE_1', 'index', ',', 'java.util.Collection', '<', 'TYPE_2', '>', 'VAR_1', ')', '{', 'TYPE_1', 'VAR_2', '=', 'index', '.', 'METHOD_2', '(', 'VAR_3', ')', ';', 'for', '(', 'TYPE_3', '<', 'TYPE_2', '>', 'VAR_4', ':', 'this', '.', 'VAR_1', '.', 'values', '(', ')', ')', '{', 'VAR_4', '.', 'METHOD_3', '(', 'VAR_2', ',', 'null', ')', ';', '}', 'METHOD_4', '(', 'index', ',', 'VAR_1', ')', ';', '}'], ['public', 'void', 'remove', '(', 'int', 'id', ')', '{', 'try', '{', 'java.lang.String', 'query', '=', 'STRING_1', ';', 'TYPE_1', 'VAR_1', '=', 'METHOD_1', '(', ')', ';', 'TYPE_2', 'VAR_2', '=', 'VAR_1', '.', 'METHOD_2', '(', 'query', ')', ';', 'VAR_2', '.', 'METHOD_3', '(', '1', ',', 'id', ')', ';', 'VAR_2', '.', 'METHOD_4', '(', ')', ';', '}', 'catch', '(', 'TYPE_3', 'VAR_3', ')', '{', 'java.lang.System.out.println', '(', 'STRING_2', ')', ';', '}', '}'], ['private', 'java.util.List', '<', 'TYPE_1', '>', 'METHOD_1', '(', ')', '{', 'java.util.List', '<', 'TYPE_1', '>', 'VAR_2', '=', 'new', 'java.util.ArrayList', '<', '>', '(', ')', ';', 'for', '(', 'int', 'i', '=', '0', ';', 'i', '<', '(', 'VAR_3', '.', 'size', '(', ')', ')', ';', 'i', '++', ')', '{', 'TYPE_1', 'VAR_1', '=', 'new', 'TYPE_1', '(', ')', ';', 'VAR_1', '.', 'METHOD_2', '(', 'VAR_3', '.', 'get', '(', 'i', ')', '.', 'METHOD_3', '(', ')', ')', ';', 'VAR_2', '.', 'add', '(', 'VAR_1', ')', ';', '}', 'return', 'VAR_2', ';', '}'], ['private', 'void', 'METHOD_1', '(', 'java.util.List', '<', 'TYPE_1', '>', 'parameters', ',', 'TYPE_2', 'VAR_1', ')', '{', 'while', '(', 'VAR_1', '.', 'METHOD_2', '(', ')', ')', '{', 'TYPE_3', 'VAR_2', '=', 'METHOD_3', '(', 'VAR_1', ')', ';', 'if', '(', 'VAR_2', '==', 'null', ')', '{', 'break', ';', '}', 'if', '(', 'VAR_2', '.', 'METHOD_4', '(', ')', ')', '{', 'METHOD_6', '(', 'parameters', ',', 'METHOD_7', '(', 'VAR_2', ')', ')', ';', '}', 'VAR_1', '=', '(', '(', 'TYPE_2', ')', '(', 'VAR_2', '.', 'METHOD_8', '(', ')', ')', ')', ';', '}', '}']]\n","[['public', 'java.lang.String', 'METHOD_1', '(', ')', '{', 'if', '(', '(', 'METHOD_2', '(', ')', ')', '&&', '(', 'METHOD_3', '(', 'VAR_1', '.', 'METHOD_4', '(', ')', ')', ')', ')', '{', 'return', 'VAR_1', '.', 'METHOD_4', '(', ')', ';', '}', 'else', 'if', '(', 'METHOD_3', '(', 'VAR_3', '.', 'METHOD_5', '(', ')', '.', 'METHOD_6', '(', ')', ')', ')', '{', 'return', 'VAR_3', '.', 'METHOD_5', '(', ')', '.', 'METHOD_6', '(', ')', ';', '}', 'else', '{', 'return', 'VAR_4', '.', 'METHOD_4', '(', ')', ';', '}', '}'], ['private', 'void', 'METHOD_1', '(', 'TYPE_1', 'index', ',', 'java.util.Collection', '<', 'TYPE_2', '>', 'VAR_1', ')', '{', 'TYPE_1', 'VAR_2', '=', 'index', '.', 'METHOD_2', '(', 'VAR_3', ')', ';', 'for', '(', 'TYPE_3', '<', 'TYPE_2', '>', 'VAR_4', ':', 'this', '.', 'VAR_1', '.', 'values', '(', ')', ')', '{', 'VAR_4', '.', 'METHOD_3', '(', 'VAR_2', ',', 'null', ')', ';', '}', 'METHOD_4', '(', 'index', ',', 'VAR_1', ')', ';', '}'], ['public', 'void', 'remove', '(', 'int', 'id', ')', '{', 'try', '{', 'java.lang.String', 'query', '=', 'STRING_1', ';', 'TYPE_1', 'VAR_1', '=', 'METHOD_1', '(', ')', ';', 'TYPE_2', 'VAR_2', '=', 'VAR_1', '.', 'METHOD_2', '(', 'query', ')', ';', 'VAR_2', '.', 'METHOD_3', '(', '1', ',', 'id', ')', ';', 'VAR_2', '.', 'METHOD_4', '(', ')', ';', '}', 'catch', '(', 'TYPE_3', 'VAR_3', ')', '{', 'java.lang.System.out.println', '(', 'STRING_2', ')', ';', '}', '}'], ['private', 'java.util.List', '<', 'TYPE_1', '>', 'METHOD_1', '(', ')', '{', 'java.util.List', '<', 'TYPE_1', '>', 'VAR_2', '=', 'new', 'java.util.ArrayList', '<', '>', '(', ')', ';', 'for', '(', 'int', 'i', '=', '0', ';', 'i', '<', '(', 'VAR_3', '.', 'size', '(', ')', ')', ';', 'i', '++', ')', '{', 'TYPE_1', 'VAR_1', '=', 'new', 'TYPE_1', '(', ')', ';', 'VAR_1', '.', 'METHOD_2', '(', 'VAR_3', '.', 'get', '(', 'i', ')', '.', 'METHOD_3', '(', ')', ')', ';', 'VAR_2', '.', 'add', '(', 'VAR_1', ')', ';', '}', 'return', 'VAR_2', ';', '}'], ['private', 'void', 'METHOD_1', '(', 'java.util.List', '<', 'TYPE_1', '>', 'parameters', ',', 'TYPE_2', 'VAR_1', ')', '{', 'while', '(', 'VAR_1', '.', 'METHOD_2', '(', ')', ')', '{', 'TYPE_3', 'VAR_2', '=', 'METHOD_3', '(', 'VAR_1', ')', ';', 'if', '(', 'VAR_2', '==', 'null', ')', '{', 'break', ';', '}', 'if', '(', 'VAR_2', '.', 'METHOD_4', '(', ')', ')', '{', 'METHOD_6', '(', 'parameters', ',', 'METHOD_7', '(', 'VAR_2', ')', ')', ';', '}', 'VAR_1', '=', '(', '(', 'TYPE_2', ')', '(', 'VAR_2', '.', 'METHOD_8', '(', ')', ')', ')', ';', '}', '}']]\n","100.0\n","100.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"djtFAyfe2ncv","executionInfo":{"status":"ok","timestamp":1624032134883,"user_tz":-360,"elapsed":535,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"06154810530490924203"}},"outputId":"47eec9a3-21e7-4b9f-ba14-d44bba4ccdac"},"source":["print(ed.config.encoder.max_length)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["20\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ht2OMlcq5fF","executionInfo":{"status":"ok","timestamp":1623752484246,"user_tz":-360,"elapsed":420,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"06154810530490924203"}},"outputId":"edb45d68-7745-4517-f91b-ba8c78620aa5"},"source":["import torch\n","output_ids_padding = torch.where(train_labels[0]== -100,led_tokenizer.pad_token_id,train_labels[0])\n","print(led_tokenizer.decode(output_ids_padding))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<s>[problem_tags]greedy, math, sortings[problem_difficulty]1100[req_time]218 ms[req_memory]400 KB[code_text]#include<bits/stdc++.h>\r\r\n","using namespace std;\r\r\n","\r\r\n","int main()\r\r\n","{\r\r\n","\tint t; cin>>t; while(t-->0){\r\r\n","\t\tint n; cin>>n; int a[n]; for(int i=0;i<n;i++) cin>>a[i];\r\r\n","\t\tint p=n-1; sort(a,a+n);\r\r\n","\t\tfor(int i=0;i<p;i++){\r\r\n","\t\t\tif(a[i+1]-a[i] < a[p]){\r\r\n","\t\t\t\tp--; i--;\r\r\n","\t\t\t}\r\r\n","\t\t}\r\r\n","\t\tcout << p+1 << endl;\r\r\n","\t}\r\r\n","}</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tSp5J6ltjHP6"},"source":["import torch\n","\n","from datasets import load_dataset, load_metric\n","from transformers import LEDTokenizer, LEDForConditionalGeneration\n","\n","# load pubmed\n","pubmed_test = load_dataset(\"scientific_papers\", \"pubmed\", ignore_verifications=True, split=\"test\")\n","\n","# load tokenizer\n","tokenizer = LEDTokenizer.from_pretrained(\"patrickvonplaten/led-large-16384-pubmed\")\n","model = LEDForConditionalGeneration.from_pretrained(\"patrickvonplaten/led-large-16384-pubmed\").to(\"cuda\").half()\n","\n","\n","def generate_answer(batch):\n","  inputs_dict = tokenizer(batch[\"article\"], padding=\"max_length\", max_length=8192, return_tensors=\"pt\", truncation=True)\n","  input_ids = inputs_dict.input_ids.to(\"cuda\")\n","  attention_mask = inputs_dict.attention_mask.to(\"cuda\")\n","  global_attention_mask = torch.zeros_like(attention_mask)\n","  # put global attention on <s> token\n","  global_attention_mask[:, 0] = 1\n","\n","  predicted_abstract_ids = model.generate(input_ids, attention_mask=attention_mask, global_attention_mask=global_attention_mask)\n","  batch[\"predicted_abstract\"] = tokenizer.batch_decode(predicted_abstract_ids, skip_special_tokens=True)\n","  return batch\n","\n","\n","result = pubmed_test.map(generate_answer, batched=True, batch_size=4)\n","\n","# load rouge\n","rouge = load_metric(\"rouge\")\n","\n","print(\"Result:\", rouge.compute(predictions=result[\"predicted_abstract\"], references=result[\"abstract\"], rouge_types=[\"rouge2\"])[\"rouge2\"].mid)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UkDe4LKiJcPI"},"source":["for i in range(len(train_labels)):\n","  for x in train_labels[i]:\n","    if(x>50277 or x<0):\n","      print(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t-JsofAhQU-B"},"source":["for x in train_labels[0]:\n","  if(x!=1):\n","    #print(x)\n","    #s = led_tokenizer.convert_ids_to_tokens(torch.tensor([x]))\n","    #x = led_model.get_decoder().embed_tokens(train_labels[0])[0]\n","    #print(s)\n","    m = led_model.get_decoder()\n","    ss = m(tensorify([[x]]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zJxUK4pJb6nw","executionInfo":{"status":"ok","timestamp":1622920670945,"user_tz":-360,"elapsed":575,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"74e9e588-8025-48f7-d830-47c1e9c7a61b"},"source":["arr = torch.zeros_like(train_labels[0])\n","print(len(arr))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["4096\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XxnwUjfMe3Aa"},"source":["print(led_model.config.max_decoder_position_embeddings)\n","dec = led_model.get_decoder()\n","print(led_model.get_decoder().embed_tokens)\n","dec.set_input_embeddings(led_model.get_encoder().embed_tokens)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":340},"id":"-pFi8xqyaGAX","executionInfo":{"status":"error","timestamp":1622923729558,"user_tz":-360,"elapsed":389,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"bff6c710-6fd9-45bf-e400-01763dfbf57f"},"source":["x = edm.get_decoder()\n","ss = x(tensorify([arr[:1024]]))"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-49-2bb4de1c05e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensorify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/reformer/modeling_reformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, position_ids, attention_mask, head_mask, inputs_embeds, num_hashes, past_buckets_states, use_cache, output_hidden_states, output_attentions, return_dict, labels)\u001b[0m\n\u001b[1;32m   2236\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2237\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2238\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2239\u001b[0m         )\n\u001b[1;32m   2240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/reformer/modeling_reformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, num_hashes, past_buckets_states, use_cache, output_hidden_states, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m   2083\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2084\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2085\u001b[0;31m             \u001b[0mstart_idx_pos_encodings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_idx_pos_encodings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2086\u001b[0m         )\n\u001b[1;32m   2087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/reformer/modeling_reformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, position_ids, inputs_embeds, start_idx_pos_encodings)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m# add positional embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/reformer/modeling_reformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, position_ids)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxial_pos_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 raise ValueError(\n\u001b[0;32m--> 156\u001b[0;31m                     \u001b[0;34mf\"If training, make sure that config.axial_pos_shape factors: {self.axial_pos_shape} multiply to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                     \u001b[0;34mf\"sequence length. Got prod({self.axial_pos_shape}) != sequence_length: {sequence_length}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                     \u001b[0;34mf\"You might want to consider padding your sequence length to {reduce(mul, self.axial_pos_shape)} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: If training, make sure that config.axial_pos_shape factors: (128, 512) multiply to sequence length. Got prod((128, 512)) != sequence_length: 1024. You might want to consider padding your sequence length to 65536 or changing config.axial_pos_shape."]}]},{"cell_type":"code","metadata":{"id":"UsKew13SR3sD"},"source":["print(ss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x4u0kzyrFKx5","executionInfo":{"status":"ok","timestamp":1622911805192,"user_tz":-360,"elapsed":405,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"95c67d2e-e857-482f-b1a2-17a62573c430"},"source":["print(len(led_tokenizer))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["50265\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qOlwP_wSFO8u"},"source":["print(led_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j5vDcLYyhSbl"},"source":["model = led_model.get_decoder()\n","#x.from_pretrained(\"allenai/led-base-16384\")\n","model.max_target_positions = 2048"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8kbNwdP1m8fq"},"source":["from transformers import EncoderDecoderModel,AutoModelForCausalLM\n","\n","encoder_model = AutoModelForCausalLM.from_pretrained('allenai/longformer-base-4096')\n","#encoder_model.resize_token_embeddings(len(encoder_tokenizer))\n","\n","encoder_model.save_pretrained(project_path+'Saved_Models/Longformer_Encoder_Init_2')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KoDI4zbRpeX1"},"source":["from transformers import EncoderDecoderModel,AutoModelForSeq2SeqLM, ReformerModel,ReformerForMaskedLM\n","\n","edm = EncoderDecoderModel.from_encoder_decoder_pretrained(project_path+'Saved_Models/asd_E',project_path+'Saved_Models/asd_D')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wMMSQ3nMxWAY","executionInfo":{"status":"ok","timestamp":1623221292691,"user_tz":-360,"elapsed":8787,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"12a3852a-cc35-4926-9005-53906401f8ea"},"source":["print(edm.config.decoder.max_position_embeddings)\n","\n","edm.save_pretrained(project_path+'Saved_Models/asd_ED')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["65536\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IaiojYkjgZMV"},"source":["from transformers import ReformerModel, ReformerConfig\n","# Initializing a Reformer configuration\n","configuration = ReformerConfig.from_pretrained(\"google/reformer-enwik8\", lsh_attn_chunk_length=16386, local_attn_chunk_length=16386)\n","# Initializing a Reformer model\n","enc_model = ReformerModel(configuration)\n","\n","enc_model.save_pretrained(project_path+'Saved_Models/asd_E')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fHywIi9Lgps7"},"source":["from transformers import ReformerForMaskedLM, ReformerConfig\n","# Initializing a Reformer configuration\n","configuration = ReformerConfig.from_pretrained(\"google/reformer-enwik8\", lsh_attn_chunk_length=16386, local_attn_chunk_length=16386)\n","configuration.is_decoder=False\n","# Initializing a Reformer model\n","dec_model = ReformerForMaskedLM(configuration)\n","\n","dec_model.save_pretrained(project_path+'Saved_Models/asd_D')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZGHTUf4ecHdH"},"source":["red = AutoModelForSeq2SeqLM.from_pretrained(project_path+'Saved_Models/asd_ED')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L--c2w-3h6KW","executionInfo":{"status":"ok","timestamp":1623221451026,"user_tz":-360,"elapsed":340,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"55240be5-4d04-43d3-b253-28b0c90f4d3f"},"source":["print(red.config.decoder.is_decoder)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dl3iiv78lHjz","executionInfo":{"status":"ok","timestamp":1623222892873,"user_tz":-360,"elapsed":4739,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"4dc8acd5-71b5-4922-97a2-cbdeccf772a7"},"source":["cnt_1024 = 0\n","cnt_4096 = 0\n","\n","for x in train_labels:\n","  try:\n","    if(x.tolist().index(1)+1<=1023):\n","      cnt_1024=cnt_1024+1\n","    else:\n","      cnt_4096 = cnt_4096+1\n","  except:\n","    cnt_4096 = cnt_4096+1\n","\n","print(cnt_1024)\n","print(cnt_4096)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["16863\n","12389\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"81l9k2RDnro3","executionInfo":{"status":"ok","timestamp":1623222847906,"user_tz":-360,"elapsed":323,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"1655e8db-b97c-47cd-ba01-1aba646dc43e"},"source":["print(len(train_encoding['input_ids']))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["29252\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mGMhJU43lwrD","executionInfo":{"status":"ok","timestamp":1623222574131,"user_tz":-360,"elapsed":349,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"5b5ffb29-b5cc-4f40-df68-fb382ffe792c"},"source":["print(train_encoding['input_ids'][0].tolist().index(1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["626\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238,"referenced_widgets":["3fd406cb781c4531bfeae59f1b2f8460","0ed49ed0fabc433892cb6e66256b110a","9f2417e77b5c40529814b17863ed7abc","0c34082f5e4440f8a83b57148659ef8e","057582f7457a420d8756a3ba6d057634","dd767d8c985a4576a49fac5b8d9be619","08929d7f50684c7c8ada1dfd288038e9","38ec365837fa4ff0a2be6c8cba2ab4d2","7d0bb7a8222c4cdd93ebe7343c255476","7270e156c2ff4542bd03b3a45226bb57","27d0397128774943a646b8e58302a4c0","8d6ab9f9e9f64ec29c325fafb95f606b","5019419281ac4713bb661ff4d40a7517","0aaa5b3202324f09a008ba9d56dd9a25","5b6f621fe077499e8f3d16861ad6d3b8","486c7fddcdb6442f8196ee95d637ab75"]},"id":"kssh2MlxlRC1","executionInfo":{"status":"ok","timestamp":1623827507768,"user_tz":-360,"elapsed":19049,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"06154810530490924203"}},"outputId":"51559d13-ea70-4448-d004-da2dd8c46b9d"},"source":["#python_code = \"def convert(x): return x\"\n","PHP_CODE = \"\"\"\n","public static <mask> set(string $key, $value) {\n","    if (!in_array($key, self::$allowedKeys)) {\n","        throw new \\InvalidArgumentException('Invalid key given');\n","    }\n","    self::$storedValues[$key] = $value;\n","}\n","\"\"\".lstrip()\n","\n","from transformers import pipeline, EncoderDecoderModel\n","\n","#summarizer = pipeline(\"summarization\")\n","\n","ed_model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"microsoft/codebert-base-mlm\",\"microsoft/codebert-base\")\n","'''\n","fill_mask = pipeline(\n","    \"summarization\",\n","    model=model,\n","    tokenizer=\"microsoft/codebert-base-mlm\"\n",")\n","\n","print(fill_mask(PHP_CODE))\n","'''\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at microsoft/codebert-base-mlm were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3fd406cb781c4531bfeae59f1b2f8460","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=498.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d0bb7a8222c4cdd93ebe7343c255476","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=498627950.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of RobertaForCausalLM were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.value.bias', 'lm_head.layer_norm.bias', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'lm_head.bias', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.8.crossattention.self.value.bias', 'lm_head.decoder.weight', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.query.weight', 'lm_head.dense.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'lm_head.dense.weight', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.value.bias', 'lm_head.layer_norm.weight', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nfill_mask = pipeline(\\n    \"summarization\",\\n    model=model,\\n    tokenizer=\"microsoft/codebert-base-mlm\"\\n)\\n\\nprint(fill_mask(PHP_CODE))\\n'"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":553,"referenced_widgets":["7e43d9250d9c4fe98cf2194b98c78718","1a94aa7269f04ec0a6225998be67fe19","ee9becdbc1304049894383e58d3494af","b74e72c12b5b4616a8442c4cb6c43d66","4eac87fde4cd41069b79a176f4f0ef2c","05b4472fa511434d976e4fdfe07f0b0e","6d57a22c25154c0bbe08e30c14b14058","257914342d4d46b18d18ce634df1491e","a68e0782e4a5468db873a756625b19de","de2be8b05cce43bfaa77683c05d88601","a5d2b9fc93804566a996519a9effd1b4","da2b4c1886aa436bb65d7bf84ec83591","5dcbe6b0e6ff4a809bbe5169c26ccc66","0c8efdfc214a4555b45553902871ca21","70a386e1270d4cec81a6f8094949f78a","97e7fd5fe96240029d5c945237f2698f","9203100138a345008a2f9a8fbf0d2b64","e1fd4543d8954cf9a39a44e87ff88d51","0619c1520fef496cbe7c7ff7849f5a3e","cf4a578094e34e49b2aa06645c967a45","efc714bbf70346978fc96984d874c14e","4043d03dae6340f69a78ca3de9769269","4f16ea15084949d9ba31135f95e46883","63fccdf13da943d5b6465aac5de450c9","5363e51c14074513a213eee6a32be738","cc3f26fa8f3f408da359dd9fb8951240","42d306f457d342cd9145fa9ac8849bb3","593bba70198e43ff84d417e394fa37ec","4ee0adef37534792857a6d87798d17cb","8eddc5a2839c4b359b7415194dfa7f0f","221f4aaf860c4a6fbafd774a348bb227","d10fc488334e4677842ef6c6230a8d5a"]},"id":"mOUktUDZpWTS","executionInfo":{"status":"error","timestamp":1623830636311,"user_tz":-360,"elapsed":18035,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"06154810530490924203"}},"outputId":"3c42d94d-2c19-4b6a-f721-9856c404adce"},"source":["summarizer = pipeline(\"text-generation\", model=\"microsoft/codebert-base\", tokenizer=\"microsoft/codebert-base\", framework=\"tf\")\n","summarizer(\"def convert_int_to_str(x):\", min_length=5, max_length=50)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e43d9250d9c4fe98cf2194b98c78718","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898822.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a68e0782e4a5468db873a756625b19de","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9203100138a345008a2f9a8fbf0d2b64","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=150.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5363e51c14074513a213eee6a32be738","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=25.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"error","ename":"PipelineException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mPipelineException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-65f1399abde7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummarizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text-generation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"microsoft/codebert-base\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"microsoft/codebert-base\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msummarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"def convert_int_to_str(x):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"feature_extractor\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtask_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, return_full_text, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_model_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALLOWED_MODELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_full_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_full_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mcheck_model_type\u001b[0;34m(self, supported_models)\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m                 \u001b[0;34mf\"The model '{self.model.__class__.__name__}' is not supported for {self.task}. Supported models are {supported_models}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m             )\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mPipelineException\u001b[0m: The model 'RobertaModel' is not supported for text-generation. Supported models are ['XLNetLMHeadModel', 'TransfoXLLMHeadModel', 'ReformerModelWithLMHead', 'GPT2LMHeadModel', 'GPTNeoForCausalLM', 'OpenAIGPTLMHeadModel', 'CTRLLMHeadModel', 'TFXLNetLMHeadModel', 'TFTransfoXLLMHeadModel', 'TFGPT2LMHeadModel', 'TFOpenAIGPTLMHeadModel', 'TFCTRLLMHeadModel']"]}]}]}