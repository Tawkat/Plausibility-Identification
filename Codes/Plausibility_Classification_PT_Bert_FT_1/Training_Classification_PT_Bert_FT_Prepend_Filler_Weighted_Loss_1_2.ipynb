{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Training_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"7a2235d688304868ac6a62d55b112a13":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a3a95885991d4713b06519755a0ec1fb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d91938074d43477ba314c6cf0661bd6d","IPY_MODEL_ee8221e3b52142e495b666e767dd1c90","IPY_MODEL_730f8e6dd8e6404db51c90b1a3a79639"]}},"a3a95885991d4713b06519755a0ec1fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d91938074d43477ba314c6cf0661bd6d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_566da1d9cfcc4029a3d77b7049c86ed9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_91052efa1c2f4179a4c6c140084ceb92"}},"ee8221e3b52142e495b666e767dd1c90":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0bd5f2256e5c4a8c91ca006be9f68f84","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9e815a1c128240d7b1ff583479ba5408"}},"730f8e6dd8e6404db51c90b1a3a79639":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0daedf560a3e4a30bddda7ccdbc382ab","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 226k/226k [00:00&lt;00:00, 920kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c2463caf9bd14e50a82833c79075617e"}},"566da1d9cfcc4029a3d77b7049c86ed9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"91052efa1c2f4179a4c6c140084ceb92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0bd5f2256e5c4a8c91ca006be9f68f84":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9e815a1c128240d7b1ff583479ba5408":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0daedf560a3e4a30bddda7ccdbc382ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c2463caf9bd14e50a82833c79075617e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"21602ba0638940019325d607b1a37787":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f1305a29923e4e348e78a6e9198c0f2e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2184b416fe954b2dae0c6984c82cfdd5","IPY_MODEL_30fab6f25b74484a9e79c59217924483","IPY_MODEL_f2f5ddeb2165448c99bdbf25e2cc5158"]}},"f1305a29923e4e348e78a6e9198c0f2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2184b416fe954b2dae0c6984c82cfdd5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e056725b25f848e39165ac610cfecbf7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e6dd25678e6f41378c0c99022eb3c23d"}},"30fab6f25b74484a9e79c59217924483":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_17c438ee10bb4427a4dff50e32a3b0f1","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e437dab2a07247ababba81dd58b02794"}},"f2f5ddeb2165448c99bdbf25e2cc5158":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e4f87aee52c342c68c623cab9347c787","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 455k/455k [00:00&lt;00:00, 1.30MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a5566b7ed01044df845d060759a6fd84"}},"e056725b25f848e39165ac610cfecbf7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e6dd25678e6f41378c0c99022eb3c23d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"17c438ee10bb4427a4dff50e32a3b0f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e437dab2a07247ababba81dd58b02794":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e4f87aee52c342c68c623cab9347c787":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a5566b7ed01044df845d060759a6fd84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ef38b83dcf7f48048421bb1cf9b3550b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a6f584b571054754bf19c2bc6a188ca7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9811ef9491d74c46b2a3a2b934ff397b","IPY_MODEL_202dfb9518664294a5d7f72d5fa48054","IPY_MODEL_6fe19d02d1224e47a9af775648ca6fcf"]}},"a6f584b571054754bf19c2bc6a188ca7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9811ef9491d74c46b2a3a2b934ff397b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d24be10a8c8545d1a2576a01ed760010","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_08a16564ea4f4da79227c9c05b3d8517"}},"202dfb9518664294a5d7f72d5fa48054":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1e6cbfd4814349088d5bad5244128569","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_620801fa46d14e038e11e9c7bf978afc"}},"6fe19d02d1224e47a9af775648ca6fcf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_398771d4f37c498db19cf32dde522ccd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:00&lt;00:00, 732B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5fa569389ec34c069f87505d11e3130a"}},"d24be10a8c8545d1a2576a01ed760010":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"08a16564ea4f4da79227c9c05b3d8517":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1e6cbfd4814349088d5bad5244128569":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"620801fa46d14e038e11e9c7bf978afc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"398771d4f37c498db19cf32dde522ccd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5fa569389ec34c069f87505d11e3130a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9f8a463e42ba4808a38f8ec393addc3d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_aa7c8513506249a4b3ae1c7002dc6fe4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c12f3068876a4a6db2c8f9d33d5572e7","IPY_MODEL_8a9b3ec328014fd9959f5c2ce662c1f2","IPY_MODEL_28422731862d424f85e0fb235d8fa360"]}},"aa7c8513506249a4b3ae1c7002dc6fe4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c12f3068876a4a6db2c8f9d33d5572e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ee0cafd8d6884883b47f995c8131a090","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1e9cb30981614845b2d90fe448a491bb"}},"8a9b3ec328014fd9959f5c2ce662c1f2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_81032285f5154f11a3a6b869aea52be9","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":570,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":570,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b40990a6de60416d8b2db8ccdc1e2969"}},"28422731862d424f85e0fb235d8fa360":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_28c7a67d863040feb7290d2c9ace4bd7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 570/570 [00:00&lt;00:00, 14.2kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fcea02b4e09d4578b8f198c51629aa81"}},"ee0cafd8d6884883b47f995c8131a090":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1e9cb30981614845b2d90fe448a491bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"81032285f5154f11a3a6b869aea52be9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b40990a6de60416d8b2db8ccdc1e2969":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"28c7a67d863040feb7290d2c9ace4bd7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fcea02b4e09d4578b8f198c51629aa81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f2eeafd58f884b2d8e028b17dcf89448":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3682cb47bb4f44b0bfc855d76f1bdd0d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_86e0694b95b947b6b16f935e0ad3ef95","IPY_MODEL_1b43e7d5fa1741879cc304f8cef62a7c","IPY_MODEL_2a49714a8a18417d8d819a13bca8b462"]}},"3682cb47bb4f44b0bfc855d76f1bdd0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"86e0694b95b947b6b16f935e0ad3ef95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_684cacca80d34e81b594bacd65a82ada","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d3e59f72a0bd43b3a57a353d665072f8"}},"1b43e7d5fa1741879cc304f8cef62a7c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b097a2dfda774a37bf6211e377c97186","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":435779157,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":435779157,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_09e8ebf5fc4a49b494f1780b6113c33d"}},"2a49714a8a18417d8d819a13bca8b462":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_13e8a798f3fb41bc951a9f6f12e13fc8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 416M/416M [00:16&lt;00:00, 26.4MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6162a81e5c334cc684c3d33cc648b2de"}},"684cacca80d34e81b594bacd65a82ada":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d3e59f72a0bd43b3a57a353d665072f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b097a2dfda774a37bf6211e377c97186":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"09e8ebf5fc4a49b494f1780b6113c33d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"13e8a798f3fb41bc951a9f6f12e13fc8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6162a81e5c334cc684c3d33cc648b2de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3e47eb3d8ec34608be790b81b3e36104":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_569d07493fa04ecf860739a2d1b810a7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e357679ad16f4366bfa4c09ac61b8b88","IPY_MODEL_63de9dd7ee8f4badac14d04d914b1bf7","IPY_MODEL_a56b492a6b31405b98d644a44ce19b10"]}},"569d07493fa04ecf860739a2d1b810a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e357679ad16f4366bfa4c09ac61b8b88":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ef80ae1cb324468494c33b5d58ea72ea","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: ","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_407def282de74fbda6d896a5921e2dea"}},"63de9dd7ee8f4badac14d04d914b1bf7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_45a8c6e0368f4fe2826d81c3e0d1fcd3","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1248,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1248,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_18417122ea5f4d79b4656a37a88d5772"}},"a56b492a6b31405b98d644a44ce19b10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9b448314c5174fcfa30fe6fab6bc67b8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2.64k/? [00:00&lt;00:00, 60.1kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_456b98d3d05848f4b5e79074dfad95c4"}},"ef80ae1cb324468494c33b5d58ea72ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"407def282de74fbda6d896a5921e2dea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"45a8c6e0368f4fe2826d81c3e0d1fcd3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"18417122ea5f4d79b4656a37a88d5772":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9b448314c5174fcfa30fe6fab6bc67b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"456b98d3d05848f4b5e79074dfad95c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3fd406cb781c4531bfeae59f1b2f8460":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0ed49ed0fabc433892cb6e66256b110a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9f2417e77b5c40529814b17863ed7abc","IPY_MODEL_0c34082f5e4440f8a83b57148659ef8e"]}},"0ed49ed0fabc433892cb6e66256b110a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9f2417e77b5c40529814b17863ed7abc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_057582f7457a420d8756a3ba6d057634","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":498,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":498,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dd767d8c985a4576a49fac5b8d9be619"}},"0c34082f5e4440f8a83b57148659ef8e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_08929d7f50684c7c8ada1dfd288038e9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 498/498 [00:02&lt;00:00, 240B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_38ec365837fa4ff0a2be6c8cba2ab4d2"}},"057582f7457a420d8756a3ba6d057634":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"dd767d8c985a4576a49fac5b8d9be619":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"08929d7f50684c7c8ada1dfd288038e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"38ec365837fa4ff0a2be6c8cba2ab4d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7d0bb7a8222c4cdd93ebe7343c255476":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7270e156c2ff4542bd03b3a45226bb57","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_27d0397128774943a646b8e58302a4c0","IPY_MODEL_8d6ab9f9e9f64ec29c325fafb95f606b"]}},"7270e156c2ff4542bd03b3a45226bb57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"27d0397128774943a646b8e58302a4c0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5019419281ac4713bb661ff4d40a7517","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":498627950,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":498627950,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0aaa5b3202324f09a008ba9d56dd9a25"}},"8d6ab9f9e9f64ec29c325fafb95f606b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5b6f621fe077499e8f3d16861ad6d3b8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 499M/499M [00:14&lt;00:00, 33.9MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_486c7fddcdb6442f8196ee95d637ab75"}},"5019419281ac4713bb661ff4d40a7517":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0aaa5b3202324f09a008ba9d56dd9a25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5b6f621fe077499e8f3d16861ad6d3b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"486c7fddcdb6442f8196ee95d637ab75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7e43d9250d9c4fe98cf2194b98c78718":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1a94aa7269f04ec0a6225998be67fe19","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ee9becdbc1304049894383e58d3494af","IPY_MODEL_b74e72c12b5b4616a8442c4cb6c43d66"]}},"1a94aa7269f04ec0a6225998be67fe19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ee9becdbc1304049894383e58d3494af":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4eac87fde4cd41069b79a176f4f0ef2c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":898822,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898822,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_05b4472fa511434d976e4fdfe07f0b0e"}},"b74e72c12b5b4616a8442c4cb6c43d66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6d57a22c25154c0bbe08e30c14b14058","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 899k/899k [00:01&lt;00:00, 890kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_257914342d4d46b18d18ce634df1491e"}},"4eac87fde4cd41069b79a176f4f0ef2c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"05b4472fa511434d976e4fdfe07f0b0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6d57a22c25154c0bbe08e30c14b14058":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"257914342d4d46b18d18ce634df1491e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a68e0782e4a5468db873a756625b19de":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_de2be8b05cce43bfaa77683c05d88601","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a5d2b9fc93804566a996519a9effd1b4","IPY_MODEL_da2b4c1886aa436bb65d7bf84ec83591"]}},"de2be8b05cce43bfaa77683c05d88601":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a5d2b9fc93804566a996519a9effd1b4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5dcbe6b0e6ff4a809bbe5169c26ccc66","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0c8efdfc214a4555b45553902871ca21"}},"da2b4c1886aa436bb65d7bf84ec83591":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_70a386e1270d4cec81a6f8094949f78a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:00&lt;00:00, 746kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_97e7fd5fe96240029d5c945237f2698f"}},"5dcbe6b0e6ff4a809bbe5169c26ccc66":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0c8efdfc214a4555b45553902871ca21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"70a386e1270d4cec81a6f8094949f78a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"97e7fd5fe96240029d5c945237f2698f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9203100138a345008a2f9a8fbf0d2b64":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e1fd4543d8954cf9a39a44e87ff88d51","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0619c1520fef496cbe7c7ff7849f5a3e","IPY_MODEL_cf4a578094e34e49b2aa06645c967a45"]}},"e1fd4543d8954cf9a39a44e87ff88d51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0619c1520fef496cbe7c7ff7849f5a3e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_efc714bbf70346978fc96984d874c14e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":150,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":150,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4043d03dae6340f69a78ca3de9769269"}},"cf4a578094e34e49b2aa06645c967a45":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4f16ea15084949d9ba31135f95e46883","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 150/150 [00:00&lt;00:00, 333B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_63fccdf13da943d5b6465aac5de450c9"}},"efc714bbf70346978fc96984d874c14e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4043d03dae6340f69a78ca3de9769269":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4f16ea15084949d9ba31135f95e46883":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"63fccdf13da943d5b6465aac5de450c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5363e51c14074513a213eee6a32be738":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cc3f26fa8f3f408da359dd9fb8951240","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_42d306f457d342cd9145fa9ac8849bb3","IPY_MODEL_593bba70198e43ff84d417e394fa37ec"]}},"cc3f26fa8f3f408da359dd9fb8951240":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"42d306f457d342cd9145fa9ac8849bb3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4ee0adef37534792857a6d87798d17cb","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":25,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":25,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8eddc5a2839c4b359b7415194dfa7f0f"}},"593bba70198e43ff84d417e394fa37ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_221f4aaf860c4a6fbafd774a348bb227","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 25.0/25.0 [00:00&lt;00:00, 272B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d10fc488334e4677842ef6c6230a8d5a"}},"4ee0adef37534792857a6d87798d17cb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8eddc5a2839c4b359b7415194dfa7f0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"221f4aaf860c4a6fbafd774a348bb227":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d10fc488334e4677842ef6c6230a8d5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"MpxvQ14HFYM1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638750826826,"user_tz":480,"elapsed":22620,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"3e7168b2-8cfa-4a55-cb09-d04e2d1f414c"},"source":["from google.colab import drive\n","drive._mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","metadata":{"id":"jGuiOxBdFh3k"},"source":["#!pip install -q keras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"utYxkMR9F0wq","executionInfo":{"status":"ok","timestamp":1638750830873,"user_tz":480,"elapsed":4057,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}}},"source":["!pip install -q pydrive"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"OIJwvszjF4AZ","executionInfo":{"status":"ok","timestamp":1638750845708,"user_tz":480,"elapsed":14843,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}}},"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"WxE-L4LS3v5I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624902425292,"user_tz":-360,"elapsed":6377,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"e072e213-e04c-42e0-ced5-87181582377d"},"source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Y8N8IE0Z30_Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638750851290,"user_tz":480,"elapsed":5594,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"70904824-ea87-4088-8f87-67ee33e533e6"},"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla K80\n"]}]},{"cell_type":"code","metadata":{"id":"yAUVCCQ96jsT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636926261550,"user_tz":480,"elapsed":6298,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12040636431562290492"}},"outputId":"2b218661-4d59-4ab6-e84b-28bd26c5156c"},"source":["!nvidia-smi\n","\n","from tensorflow.python.client import device_lib\n","device_lib.list_local_devices()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Nov 14 21:44:17 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   46C    P8    29W / 149W |      3MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]},{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 4166222181018048320\n"," xla_global_id: -1, name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 10843127808\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 15994622152920921938\n"," physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n"," xla_global_id: 416903419]"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"6-PaQ17P36m8","colab":{"base_uri":"https://localhost:8080/","height":922},"executionInfo":{"status":"ok","timestamp":1638750880501,"user_tz":480,"elapsed":29018,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"ca3365c5-ff0a-4e61-e587-063dfe5c35fa"},"source":["#!pip install transformers\n","!pip install git+https://github.com/huggingface/transformers"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/huggingface/transformers\n","  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-rfvt68go\n","  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-rfvt68go\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (1.19.5)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (21.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 53.7 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (3.4.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (4.8.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 48.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (4.62.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 467 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.13.0.dev0) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.13.0.dev0) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.13.0.dev0) (3.6.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (1.15.0)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.13.0.dev0-py3-none-any.whl size=3254938 sha256=dc39cf1380b9f753611589363f5bcae32a395fa5c5814cdc0c0c55cb79c917bb\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-hxdql5on/wheels/35/2e/a7/d819e3310040329f0f47e57c9e3e7a7338aa5e74c49acfe522\n","Successfully built transformers\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.13.0.dev0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["yaml"]}}},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"hYNfHEVCUTJM","executionInfo":{"status":"ok","timestamp":1638750881011,"user_tz":480,"elapsed":14,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}}},"source":["project_path='/content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b7Re8ir-aRg4","executionInfo":{"status":"ok","timestamp":1623930507463,"user_tz":-360,"elapsed":407,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"06154810530490924203"}},"outputId":"5f8c4590-62d5-41ce-b064-66903de9f725"},"source":["#cd '/content/drive/My Drive/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SmZ_NAJRUc7v"},"source":["#cd $project_path"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XutRrfaDUh-p"},"source":["#ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jEvmy_hdVu99","executionInfo":{"status":"ok","timestamp":1638750881012,"user_tz":480,"elapsed":11,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}}},"source":["import numpy as np\n","import pandas as pd"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"eak_teqZUmjI","executionInfo":{"status":"ok","timestamp":1638750881013,"user_tz":480,"elapsed":10,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}}},"source":["def tensorify(lst):\n","    \"\"\"\n","    List must be nested list of tensors (with no varying lengths within a dimension).\n","    Nested list of nested lengths [D1, D2, ... DN] -> tensor([D1, D2, ..., DN)\n","\n","    :return: nested list D\n","    \"\"\"\n","    # base case, if the current list is not nested anymore, make it into tensor\n","    if type(lst[0]) != list:\n","        if type(lst) == torch.Tensor:\n","            return lst\n","        elif type(lst[0]) == torch.Tensor:\n","            return torch.stack(lst, dim=0)\n","        else:  # if the elements of lst are floats or something like that\n","            return torch.tensor(lst)\n","    current_dimension_i = len(lst)\n","    for d_i in range(current_dimension_i):\n","        tensor = tensorify(lst[d_i])\n","        lst[d_i] = tensor\n","    # end of loop lst[d_i] = tensor([D_i, ... D_0])\n","    tensor_lst = torch.stack(lst, dim=0)\n","    return tensor_lst"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"KzLahl8DjRbo","executionInfo":{"status":"ok","timestamp":1638750881014,"user_tz":480,"elapsed":10,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}}},"source":["import torch\n","\n","class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","        self.temp = None\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"EZ98pV7F4ctw","executionInfo":{"status":"ok","timestamp":1638750884101,"user_tz":480,"elapsed":3097,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}}},"source":["######## Shuffling Training Dataset for Plausibility Classification ######################\n","#########################################################################\n","\n","import pickle\n","\n","with open(project_path+'Pickles/pickle_shuffled_train_clarification_single_filler_dataset_3.pickle', 'rb') as f:\n","  shuffled_train_dataset = pickle.load(f)\n","  #pickle.dump((test_df['labels'],predictions),f)\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"T5gyjQ3FjUJd","executionInfo":{"status":"ok","timestamp":1638750982332,"user_tz":480,"elapsed":1755,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}}},"source":["import pickle\n","\n","with open(project_path+'Pickles/pickle_train_clarification_single_filler_dataset_3.pickle', 'rb') as f:\n","  train_dataset = pickle.load(f)\n","  #pickle.dump((test_df['labels'],predictions),f)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"EeWHCErDz2kz"},"source":["import pickle\n","\n","with open(project_path+'Pickles/pickle_valid_clarification_single_filler_dataset_3.pickle', 'rb') as f:\n","  val_dataset = pickle.load(f)\n","  #pickle.dump((test_df['labels'],predictions),f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ja9xsfbkOUbD"},"source":["'''\n","import pickle\n","\n","with open(project_path+'Pickles/pickle_valid_puzzle_shuffled_1000_dataset_1.pickle', 'rb') as f:\n","  shuffled_val_dataset = pickle.load(f)\n","  #pickle.dump((test_df['labels'],predictions),f)\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QVXCtnSBjW5P"},"source":["import pickle\n","\n","with open(project_path+'Pickles/pickle_valid_small_clarification_single_filler_dataset_3.pickle', 'rb') as f: \n","  val_small_dataset = pickle.load(f)\n","  #pickle.dump((test_df['labels'],predictions),f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KEX_2Di5jZFM","executionInfo":{"status":"ok","timestamp":1638750884402,"user_tz":480,"elapsed":334,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}}},"source":["\n","import pickle\n","\n","with open(project_path+'Pickles/pickle_test_clarification_single_filler_dataset_3.pickle', 'rb') as f:\n","  test_dataset = pickle.load(f)\n","  #pickle.dump((test_df['labels'],predictions),f)\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"XTNsqVdCBlzb","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["7a2235d688304868ac6a62d55b112a13","a3a95885991d4713b06519755a0ec1fb","d91938074d43477ba314c6cf0661bd6d","ee8221e3b52142e495b666e767dd1c90","730f8e6dd8e6404db51c90b1a3a79639","566da1d9cfcc4029a3d77b7049c86ed9","91052efa1c2f4179a4c6c140084ceb92","0bd5f2256e5c4a8c91ca006be9f68f84","9e815a1c128240d7b1ff583479ba5408","0daedf560a3e4a30bddda7ccdbc382ab","c2463caf9bd14e50a82833c79075617e","21602ba0638940019325d607b1a37787","f1305a29923e4e348e78a6e9198c0f2e","2184b416fe954b2dae0c6984c82cfdd5","30fab6f25b74484a9e79c59217924483","f2f5ddeb2165448c99bdbf25e2cc5158","e056725b25f848e39165ac610cfecbf7","e6dd25678e6f41378c0c99022eb3c23d","17c438ee10bb4427a4dff50e32a3b0f1","e437dab2a07247ababba81dd58b02794","e4f87aee52c342c68c623cab9347c787","a5566b7ed01044df845d060759a6fd84","ef38b83dcf7f48048421bb1cf9b3550b","a6f584b571054754bf19c2bc6a188ca7","9811ef9491d74c46b2a3a2b934ff397b","202dfb9518664294a5d7f72d5fa48054","6fe19d02d1224e47a9af775648ca6fcf","d24be10a8c8545d1a2576a01ed760010","08a16564ea4f4da79227c9c05b3d8517","1e6cbfd4814349088d5bad5244128569","620801fa46d14e038e11e9c7bf978afc","398771d4f37c498db19cf32dde522ccd","5fa569389ec34c069f87505d11e3130a","9f8a463e42ba4808a38f8ec393addc3d","aa7c8513506249a4b3ae1c7002dc6fe4","c12f3068876a4a6db2c8f9d33d5572e7","8a9b3ec328014fd9959f5c2ce662c1f2","28422731862d424f85e0fb235d8fa360","ee0cafd8d6884883b47f995c8131a090","1e9cb30981614845b2d90fe448a491bb","81032285f5154f11a3a6b869aea52be9","b40990a6de60416d8b2db8ccdc1e2969","28c7a67d863040feb7290d2c9ace4bd7","fcea02b4e09d4578b8f198c51629aa81"]},"executionInfo":{"status":"ok","timestamp":1638750889732,"user_tz":480,"elapsed":5336,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"10ec8fd7-f66a-47a7-a004-e251f5d50b92"},"source":["from transformers import AutoTokenizer,BertTokenizerFast\n","\n","tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\",max_length=512) #, skip_special_tokens=True)\n","\n","special_tokens_dict = {'additional_special_tokens': ['[SEP]','[FILLER]','[\\FILLER]']}\n","num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7a2235d688304868ac6a62d55b112a13","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"21602ba0638940019325d607b1a37787","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef38b83dcf7f48048421bb1cf9b3550b","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9f8a463e42ba4808a38f8ec393addc3d","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aETyN_olnOGA","executionInfo":{"status":"ok","timestamp":1638750889853,"user_tz":480,"elapsed":132,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"720eda45-0037-479f-9aef-0996bd13596d"},"source":["'''\n","decoder_tokenizer.cls_token = decoder_tokenizer.bos_token\n","decoder_tokenizer.sep_token = decoder_tokenizer.eos_token\n","decoder_tokenizer.pad_token = decoder_tokenizer.eos_token\n","encoder_tokenizer.pad_token = decoder_tokenizer.eos_token\n","'''\n","\n","print(tokenizer.cls_token,tokenizer.sep_token,tokenizer.bos_token,tokenizer.eos_token,tokenizer.pad_token,tokenizer.sep_token_id,tokenizer.pad_token_id)\n","print(tokenizer.special_tokens_map)\n","#print(decoder_tokenizer.cls_token,decoder_tokenizer.sep_token,decoder_tokenizer.bos_token,decoder_tokenizer.eos_token,decoder_tokenizer.pad_token,decoder_tokenizer.sep_token_id,decoder_tokenizer.pad_token_id)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Using bos_token, but it is not set yet.\n","Using eos_token, but it is not set yet.\n"]},{"output_type":"stream","name":"stdout","text":["[CLS] [SEP] None None [PAD] 102 0\n","{'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]', 'additional_special_tokens': ['[SEP]', '[FILLER]', '[\\\\FILLER]']}\n"]}]},{"cell_type":"code","metadata":{"id":"STcaFc6xJMOR","colab":{"base_uri":"https://localhost:8080/","height":188,"referenced_widgets":["f2eeafd58f884b2d8e028b17dcf89448","3682cb47bb4f44b0bfc855d76f1bdd0d","86e0694b95b947b6b16f935e0ad3ef95","1b43e7d5fa1741879cc304f8cef62a7c","2a49714a8a18417d8d819a13bca8b462","684cacca80d34e81b594bacd65a82ada","d3e59f72a0bd43b3a57a353d665072f8","b097a2dfda774a37bf6211e377c97186","09e8ebf5fc4a49b494f1780b6113c33d","13e8a798f3fb41bc951a9f6f12e13fc8","6162a81e5c334cc684c3d33cc648b2de"]},"executionInfo":{"status":"ok","timestamp":1636611041507,"user_tz":480,"elapsed":21658,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12040636431562290492"}},"outputId":"e35300fb-a712-41d9-f87d-c4cd7c693f7f"},"source":["'''\n","from transformers import AutoModelForSequenceClassification\n","\n","bert_new = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\",num_labels=3)\n","\n","\n","print(bert_new.get_input_embeddings())\n","\n","bert_new.resize_token_embeddings(len(tokenizer))\n","\n","print(bert_new.get_input_embeddings())\n","\n","bert_new.save_pretrained(project_path+'Saved_Models/PLAUSIBILITY_CLASSIFICATION_BERT_1')\n","'''\n","\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f2eeafd58f884b2d8e028b17dcf89448","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Embedding(28996, 768, padding_idx=0)\n","Embedding(28998, 768)\n"]}]},{"cell_type":"code","metadata":{"id":"6HsV4dm8j9qT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638750899726,"user_tz":480,"elapsed":9879,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"a7964d9d-bd85-419a-9778-0759b4b302bf"},"source":["from transformers import AutoModelForSequenceClassification\n","model = AutoModelForSequenceClassification.from_pretrained(project_path+'Saved_Models/Training_1/Plausibility_Classification_Bert_1/Final_Bert',num_labels=3) #########\n","model.resize_token_embeddings(len(tokenizer)) ###############"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_1/Final_Bert were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_1/Final_Bert and are newly initialized: ['classifier.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["Embedding(30524, 768)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pMamweLLLhWz","executionInfo":{"status":"ok","timestamp":1638750899727,"user_tz":480,"elapsed":34,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"7317b89a-5cfe-4604-f3e8-580e90b4d217"},"source":["#model.config.decoder.add_cross_attention=True\n","#print(model.config.decoder)\n","print(model.get_input_embeddings())\n","print(model.config.pad_token_id)\n","#model.save_pretrained(project_path+'Saved_Models/BertGPT_2_decoder_cross_attention')"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Embedding(30524, 768)\n","0\n"]}]},{"cell_type":"code","metadata":{"id":"cWzHwcz6BEeo"},"source":["#led_tokenizer = AutoTokenizer.from_pretrained(\"allenai/led-base-16384\")\n","#led_model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/led-base-16384\", gradient_checkpointing=True, use_cache=False,)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":800},"id":"MmYQNbcc44J4","executionInfo":{"status":"ok","timestamp":1638750907701,"user_tz":480,"elapsed":7989,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"50acf586-a90b-46e4-db05-19622a540a57"},"source":["!pip install datasets==1.2.1\n","!pip install rouge_score"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets==1.2.1\n","  Downloading datasets-1.2.1-py3-none-any.whl (159 kB)\n","\u001b[K     |████████████████████████████████| 159 kB 5.4 MB/s \n","\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (0.3.4)\n","Collecting tqdm<4.50.0,>=4.27\n","  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n","\u001b[K     |████████████████████████████████| 69 kB 6.7 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (3.0.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (1.19.5)\n","Collecting xxhash\n","  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n","\u001b[K     |████████████████████████████████| 243 kB 35.3 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (4.8.2)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (0.70.12.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (1.1.5)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (2.23.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.2.1) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.2.1) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.2.1) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.2.1) (1.24.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==1.2.1) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==1.2.1) (3.10.0.2)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.2.1) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.2.1) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.2.1) (1.15.0)\n","Installing collected packages: xxhash, tqdm, datasets\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.62.3\n","    Uninstalling tqdm-4.62.3:\n","      Successfully uninstalled tqdm-4.62.3\n","Successfully installed datasets-1.2.1 tqdm-4.49.0 xxhash-2.0.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tqdm"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting rouge_score\n","  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge_score) (0.12.0)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.15.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.19.5)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge_score) (3.2.5)\n","Installing collected packages: rouge-score\n","Successfully installed rouge-score-0.0.4\n"]}]},{"cell_type":"code","metadata":{"id":"f7M0Ok_QAaHI","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["3e47eb3d8ec34608be790b81b3e36104","569d07493fa04ecf860739a2d1b810a7","e357679ad16f4366bfa4c09ac61b8b88","63de9dd7ee8f4badac14d04d914b1bf7","a56b492a6b31405b98d644a44ce19b10","ef80ae1cb324468494c33b5d58ea72ea","407def282de74fbda6d896a5921e2dea","45a8c6e0368f4fe2826d81c3e0d1fcd3","18417122ea5f4d79b4656a37a88d5772","9b448314c5174fcfa30fe6fab6bc67b8","456b98d3d05848f4b5e79074dfad95c4"]},"executionInfo":{"status":"ok","timestamp":1638750909129,"user_tz":480,"elapsed":1436,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"669be37a-29a2-4bca-8851-a7724f2665b3"},"source":["#from transformers import logging ################\n","#logging.set_verbosity_info() #####################\n","\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","\n","from datasets import load_dataset, load_metric\n","from transformers import (\n","    Trainer,\n","    TrainingArguments,\n","    AutoTokenizer,\n",")\n","\n","#tokenizer = tokenizer\n","\n","# load rouge\n","metric = load_metric(\"accuracy\")\n","\n","# compute Rouge score during validation\n","def compute_metrics(pred):\n","    logits, labels = pred\n","    predictions = np.argmax(logits, axis=-1)\n","\n","    accuracy = metric.compute(predictions=predictions, references=labels)['accuracy']\n","\n","    micro_f1 = f1_score(labels, predictions, average='micro')\n","    macro_f1 = f1_score(labels, predictions, average='macro')\n","    weighted_f1 = f1_score(labels, predictions, average='weighted')\n","\n","\n","\n","    return {\n","        \"Accuracy\": accuracy,\n","        \"micro_F1\": round(micro_f1, 4),\n","        \"macro_F1\": round(macro_f1, 4),\n","        \"weighted_F1\": round(weighted_f1, 4),\n","    }\n"],"execution_count":17,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3e47eb3d8ec34608be790b81b3e36104","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.25k [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":974},"id":"9RKQPr9zbjFE","executionInfo":{"status":"ok","timestamp":1638750924901,"user_tz":480,"elapsed":15269,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"2c969ae9-b5c5-4ef9-f787-bae01ccd2045"},"source":["!pip install wandb\n","\n","import wandb\n","wandb.login()\n","\n","%env WANDB_PROJECT=Plausibility_Clarification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_Training_1_2"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wandb\n","  Downloading wandb-0.12.7-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Collecting yaspin>=1.0.0\n","  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.5.0-py2.py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 51.7 MB/s \n","\u001b[?25hCollecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n","Collecting subprocess32>=3.5.3\n","  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 6.0 MB/s \n","\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Collecting configparser>=3.8.1\n","  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n","\u001b[K     |████████████████████████████████| 180 kB 51.8 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n","Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n","Building wheels for collected packages: subprocess32, pathtools\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=6e34873f9523e2655e16f20ddb7f744ac8dfaa39793a9f89bf71510e8a4d530d\n","  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=d7abad0942669c585a14709f2bc50a849a1566af1372a139f3c800802bc16873\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built subprocess32 pathtools\n","Installing collected packages: smmap, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n","Successfully installed GitPython-3.1.24 configparser-5.2.0 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.0 shortuuid-1.0.8 smmap-5.0.0 subprocess32-3.5.4 wandb-0.12.7 yaspin-2.1.0\n"]},{"output_type":"display_data","data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"stream","name":"stdout","text":["env: WANDB_PROJECT=Plausibility_Clarification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_Training_1_2\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CIJMsTjAQhMG","executionInfo":{"status":"ok","timestamp":1638750992089,"user_tz":480,"elapsed":1465,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"2b9c7a5a-a68e-4468-ae1a-b0b519f1af3a"},"source":["class_dic = {}\n","for i in range(3):\n","  class_dic[i]=0\n","\n","for i in range(len(train_dataset)):\n","  class_dic[int(train_dataset[i]['labels'])] += 1\n","\n","class_dic"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: 4950, 1: 6441, 2: 6569}"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BOUfARTdW_45","executionInfo":{"status":"ok","timestamp":1638750993114,"user_tz":480,"elapsed":115,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"d5672fcb-b20d-4a1f-8f26-d415642310da"},"source":["print(max(class_dic.values()))"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["6569\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wF6Ix7kZXKYh","executionInfo":{"status":"ok","timestamp":1638750994001,"user_tz":480,"elapsed":147,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"c12bc4b7-1511-4d4d-a59d-a1dcae6b3cc2"},"source":["class_weights = []\n","\n","max_class = max(class_dic.values())\n","\n","for i in range(3):\n","  class_weights.append(max_class/class_dic[i])\n","\n","print(class_weights)\n","class_weights = torch.FloatTensor(class_weights).to(device)\n","print(class_weights)"],"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["[1.327070707070707, 1.0198726905759976, 1.0]\n","tensor([1.3271, 1.0199, 1.0000], device='cuda:0')\n"]}]},{"cell_type":"code","metadata":{"id":"Xcq6r1AHX1y6","executionInfo":{"status":"ok","timestamp":1638750995863,"user_tz":480,"elapsed":121,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}}},"source":["from torch import nn\n","from transformers import Trainer\n","\n","class MultiClassTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        labels = inputs.get(\"labels\")\n","        outputs = model(**inputs)\n","        logits = outputs.get('logits')\n","        loss_fct = nn.CrossEntropyLoss(weight = class_weights)\n","        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n","        return (loss, outputs) if return_outputs else loss"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"z3u4_AvV5ysj","executionInfo":{"status":"ok","timestamp":1638750998415,"user_tz":480,"elapsed":114,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}}},"source":["batch_size = 8 ####################\n","\n","\n","\n","training_args = TrainingArguments(\n","    evaluation_strategy=\"steps\",\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    #fp16=True,\n","    #fp16_backend=\"apex\",\n","    output_dir=project_path+'Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/',\n","    logging_dir = project_path+'Saved_Logs/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/',\n","    num_train_epochs = 20,  ##########################################################\n","    logging_steps=10, #250,\n","    eval_steps=50,  # 200, #5000,\n","    save_steps=50, #200, #500,\n","    warmup_steps=1, #1500,\n","    #save_total_limit=2,\n","    gradient_accumulation_steps=8, ############################################################\n","    load_best_model_at_end = False,\n","    #resume_from_checkpoint = project_path+'Saved_Models/Training_1/checkpoint-1500',\n","    report_to=\"wandb\",  # enable logging to W&B\n","    run_name=\"plausibility-classification-PT-Bert-FT-Prepend-Filler-Weighted-Loss-run-2\",  # name of the W&B run (optional)\n",")\n","\n","\n"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"KAwT_NCXG03r","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"22c3c2e4-be6a-4fe9-b72a-cb3675cee650"},"source":["# instantiate trainer BATCH SIZE = 8 ############\n","trainer = MultiClassTrainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    #data_collator=data_collator,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    train_dataset= train_dataset,  #shuffled_train_dataset,  ########################################\n","    eval_dataset=test_dataset,  # val_dataset, \n",")\n","\n","# start training\n","trainer.train()\n","#trainer.train(project_path+'Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-750')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running training *****\n","  Num examples = 17960\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 8\n","  Total optimization steps = 5600\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtawkat\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_Training_1_2/runs/2tz0ylch\" target=\"_blank\">plausibility-classification-PT-Bert-FT-Prepend-Filler-Weighted-Loss-run-2</a></strong> to <a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_Training_1_2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1201' max='5600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1201/5600 6:16:47 < 23:02:24, 0.05 it/s, Epoch 4.29/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Micro F1</th>\n","      <th>Macro F1</th>\n","      <th>Weighted F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>1.112600</td>\n","      <td>1.087546</td>\n","      <td>0.434800</td>\n","      <td>0.434800</td>\n","      <td>0.202600</td>\n","      <td>0.264500</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.114500</td>\n","      <td>1.040662</td>\n","      <td>0.387200</td>\n","      <td>0.387200</td>\n","      <td>0.186600</td>\n","      <td>0.217100</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>1.109200</td>\n","      <td>1.132152</td>\n","      <td>0.201200</td>\n","      <td>0.201200</td>\n","      <td>0.161100</td>\n","      <td>0.131600</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.095000</td>\n","      <td>1.124118</td>\n","      <td>0.320400</td>\n","      <td>0.320400</td>\n","      <td>0.313100</td>\n","      <td>0.329000</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>1.096000</td>\n","      <td>1.073419</td>\n","      <td>0.442800</td>\n","      <td>0.442800</td>\n","      <td>0.330300</td>\n","      <td>0.396000</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.061600</td>\n","      <td>1.122799</td>\n","      <td>0.421600</td>\n","      <td>0.421600</td>\n","      <td>0.340600</td>\n","      <td>0.394900</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>1.048400</td>\n","      <td>1.128627</td>\n","      <td>0.400800</td>\n","      <td>0.400800</td>\n","      <td>0.363100</td>\n","      <td>0.407200</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.089300</td>\n","      <td>1.116941</td>\n","      <td>0.462800</td>\n","      <td>0.462800</td>\n","      <td>0.278400</td>\n","      <td>0.351800</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>1.086100</td>\n","      <td>1.110502</td>\n","      <td>0.358000</td>\n","      <td>0.358000</td>\n","      <td>0.345500</td>\n","      <td>0.374300</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>1.081500</td>\n","      <td>1.111678</td>\n","      <td>0.347600</td>\n","      <td>0.347600</td>\n","      <td>0.343500</td>\n","      <td>0.368900</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>1.073800</td>\n","      <td>1.123666</td>\n","      <td>0.350400</td>\n","      <td>0.350400</td>\n","      <td>0.348800</td>\n","      <td>0.375000</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.998600</td>\n","      <td>1.171213</td>\n","      <td>0.420800</td>\n","      <td>0.420800</td>\n","      <td>0.365700</td>\n","      <td>0.415300</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>1.003700</td>\n","      <td>1.179558</td>\n","      <td>0.366400</td>\n","      <td>0.366400</td>\n","      <td>0.335500</td>\n","      <td>0.356800</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.980100</td>\n","      <td>1.170337</td>\n","      <td>0.397200</td>\n","      <td>0.397200</td>\n","      <td>0.378900</td>\n","      <td>0.415800</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.996000</td>\n","      <td>1.083705</td>\n","      <td>0.446000</td>\n","      <td>0.446000</td>\n","      <td>0.376700</td>\n","      <td>0.436600</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>1.017900</td>\n","      <td>1.179394</td>\n","      <td>0.348400</td>\n","      <td>0.348400</td>\n","      <td>0.351600</td>\n","      <td>0.371500</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.909300</td>\n","      <td>1.234060</td>\n","      <td>0.430000</td>\n","      <td>0.430000</td>\n","      <td>0.388800</td>\n","      <td>0.436500</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.885500</td>\n","      <td>1.262314</td>\n","      <td>0.396800</td>\n","      <td>0.396800</td>\n","      <td>0.381400</td>\n","      <td>0.416000</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.853100</td>\n","      <td>1.280982</td>\n","      <td>0.385200</td>\n","      <td>0.385200</td>\n","      <td>0.370100</td>\n","      <td>0.402700</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.880500</td>\n","      <td>1.262404</td>\n","      <td>0.427200</td>\n","      <td>0.427200</td>\n","      <td>0.393500</td>\n","      <td>0.437600</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.887200</td>\n","      <td>1.250036</td>\n","      <td>0.429200</td>\n","      <td>0.429200</td>\n","      <td>0.392100</td>\n","      <td>0.436900</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.871700</td>\n","      <td>1.337484</td>\n","      <td>0.394800</td>\n","      <td>0.394800</td>\n","      <td>0.377700</td>\n","      <td>0.413200</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.749100</td>\n","      <td>1.384130</td>\n","      <td>0.406800</td>\n","      <td>0.406800</td>\n","      <td>0.385400</td>\n","      <td>0.424000</td>\n","    </tr>\n","  </tbody>\n","</table><p>\n","    <div>\n","      \n","      <progress value='67' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 67/313 00:44 < 02:47, 1.47 it/s]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-50\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-50/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-50/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-50/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-50/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-100\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-100/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-100/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-100/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-100/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-150\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-150/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-150/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-150/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-150/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-200\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-200/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-200/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-200/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-200/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-250\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-250/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-250/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-250/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-250/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-300\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-300/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-300/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-300/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-300/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-350\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-350/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-350/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-350/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-350/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-400\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-400/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-400/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-400/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-400/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-450\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-450/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-450/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-450/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-450/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-500\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-500/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-550\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-550/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-550/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-550/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-550/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-600\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-600/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-600/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-600/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-600/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-650\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-650/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-650/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-650/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-650/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-700\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-700/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-700/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-700/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-700/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-750\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-750/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-750/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-750/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-750/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-800\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-800/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-800/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-800/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-800/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-850\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-850/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-850/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-850/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-850/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-900\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-900/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-900/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-900/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-900/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-950\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-950/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-950/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-950/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-950/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-1000\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-1000/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-1000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-1050\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-1050/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-1050/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-1050/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-1050/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-1100\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-1100/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-1100/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-1100/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-1100/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-1150\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-1150/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-1150/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-1150/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_PT_Bert_FT_Prepend_Filler_Weighted_Loss_1_2/checkpoint-1150/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"8gNFJiB-grF6","outputId":"44b6de29-b74f-4ce2-c598-e27d7fd3f403"},"source":["# instantiate trainer BATCH SIZE = 8 ############\n","trainer = MultiClassTrainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    #data_collator=data_collator,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    train_dataset= train_dataset,  #shuffled_train_dataset,  ########################################\n","    eval_dataset=test_dataset,  # val_dataset, \n",")\n","\n","# start training\n","trainer.train()\n","#trainer.train(project_path+'Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-900')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running training *****\n","  Num examples = 17960\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 8\n","  Total optimization steps = 5600\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"]},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_Bert_Training_3_2/runs/2y8haluv\" target=\"_blank\">plausibility-classification-Bert-3-2-run-2</a></strong> to <a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_Bert_Training_3_2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='787' max='5600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 787/5600 3:04:35 < 18:51:47, 0.07 it/s, Epoch 2.81/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Micro F1</th>\n","      <th>Macro F1</th>\n","      <th>Weighted F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>1.099400</td>\n","      <td>1.135188</td>\n","      <td>0.348400</td>\n","      <td>0.348400</td>\n","      <td>0.276000</td>\n","      <td>0.301600</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.084200</td>\n","      <td>1.074268</td>\n","      <td>0.420400</td>\n","      <td>0.420400</td>\n","      <td>0.362500</td>\n","      <td>0.418300</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>1.116300</td>\n","      <td>1.067504</td>\n","      <td>0.481200</td>\n","      <td>0.481200</td>\n","      <td>0.316400</td>\n","      <td>0.397200</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.087600</td>\n","      <td>1.108826</td>\n","      <td>0.366000</td>\n","      <td>0.366000</td>\n","      <td>0.358300</td>\n","      <td>0.390500</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>1.084400</td>\n","      <td>1.090485</td>\n","      <td>0.377200</td>\n","      <td>0.377200</td>\n","      <td>0.374000</td>\n","      <td>0.407000</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.008400</td>\n","      <td>1.088289</td>\n","      <td>0.439200</td>\n","      <td>0.439200</td>\n","      <td>0.401100</td>\n","      <td>0.453900</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>1.008800</td>\n","      <td>1.092953</td>\n","      <td>0.470000</td>\n","      <td>0.470000</td>\n","      <td>0.389500</td>\n","      <td>0.456500</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.052900</td>\n","      <td>1.114945</td>\n","      <td>0.407200</td>\n","      <td>0.407200</td>\n","      <td>0.389600</td>\n","      <td>0.428100</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>1.037200</td>\n","      <td>1.046952</td>\n","      <td>0.510800</td>\n","      <td>0.510800</td>\n","      <td>0.387400</td>\n","      <td>0.468600</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>1.058600</td>\n","      <td>1.083083</td>\n","      <td>0.488400</td>\n","      <td>0.488400</td>\n","      <td>0.347500</td>\n","      <td>0.422900</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>1.045000</td>\n","      <td>1.058307</td>\n","      <td>0.494400</td>\n","      <td>0.494400</td>\n","      <td>0.381800</td>\n","      <td>0.457600</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.885900</td>\n","      <td>1.193976</td>\n","      <td>0.484400</td>\n","      <td>0.484400</td>\n","      <td>0.419600</td>\n","      <td>0.477700</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.911000</td>\n","      <td>1.128386</td>\n","      <td>0.392000</td>\n","      <td>0.392000</td>\n","      <td>0.386800</td>\n","      <td>0.421700</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.921000</td>\n","      <td>1.164315</td>\n","      <td>0.425200</td>\n","      <td>0.425200</td>\n","      <td>0.412300</td>\n","      <td>0.450700</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.945000</td>\n","      <td>1.076002</td>\n","      <td>0.481600</td>\n","      <td>0.481600</td>\n","      <td>0.431800</td>\n","      <td>0.487300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-50\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-50/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-50/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-50/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-50/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-100\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-100/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-100/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-100/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-100/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-150\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-150/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-150/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-150/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-150/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-200\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-200/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-200/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-200/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-200/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-250\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-250/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-250/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-250/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-250/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-300\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-300/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-300/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-300/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-300/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-350\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-350/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-350/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-350/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-350/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-400\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-400/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-400/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-400/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-400/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-450\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-450/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-450/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-450/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-450/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-500\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-500/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-550\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-550/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-550/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-550/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-550/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-600\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-600/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-600/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-600/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-600/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-650\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-650/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-650/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-650/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-650/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-700\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-700/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-700/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-700/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-700/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-750\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-750/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-750/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-750/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-750/special_tokens_map.json\n"]}]},{"cell_type":"code","metadata":{"id":"KmmTpD9BjNXM","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"45051793-efff-4d5f-8f19-a42cccde88af"},"source":["# instantiate trainer BATCH SIZE = 8 ############\n","trainer = Trainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    #data_collator=data_collator,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    train_dataset= train_dataset,  #shuffled_train_dataset,  ########################################\n","    eval_dataset=test_dataset,  # val_dataset, \n",")\n","\n","# start training\n","trainer.train()\n","#trainer.train(project_path+'Saved_Logs/Training_1/Plausibility_Classification_Bert_2/checkpoint-900')"],"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 17960\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 8\n","  Total optimization steps = 5600\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtawkat\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_Bert_Training_3/runs/khrsj6wx\" target=\"_blank\">plausibility-classification-Bert-3-run-2</a></strong> to <a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_Bert_Training_3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='101' max='5600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 101/5600 21:01 < 19:27:25, 0.08 it/s, Epoch 0.36/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Micro F1</th>\n","      <th>Macro F1</th>\n","      <th>Weighted F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>1.091200</td>\n","      <td>1.143194</td>\n","      <td>0.417600</td>\n","      <td>0.234000</td>\n","      <td>0.234000</td>\n","      <td>0.277800</td>\n","    </tr>\n","  </tbody>\n","</table><p>\n","    <div>\n","      \n","      <progress value='269' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [269/313 02:20 < 00:23, 1.91 it/s]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-50\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-50/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-50/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-50/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-50/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='950' max='5600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 950/5600 3:45:23 < 18:25:33, 0.07 it/s, Epoch 3.39/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Micro F1</th>\n","      <th>Macro F1</th>\n","      <th>Weighted F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>1.091200</td>\n","      <td>1.143194</td>\n","      <td>0.417600</td>\n","      <td>0.234000</td>\n","      <td>0.234000</td>\n","      <td>0.277800</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.093200</td>\n","      <td>1.098558</td>\n","      <td>0.384800</td>\n","      <td>0.286900</td>\n","      <td>0.286900</td>\n","      <td>0.328600</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>1.113500</td>\n","      <td>1.062129</td>\n","      <td>0.464800</td>\n","      <td>0.279300</td>\n","      <td>0.279300</td>\n","      <td>0.353900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.081100</td>\n","      <td>1.090249</td>\n","      <td>0.436000</td>\n","      <td>0.393000</td>\n","      <td>0.393000</td>\n","      <td>0.446300</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>1.072300</td>\n","      <td>1.093444</td>\n","      <td>0.392400</td>\n","      <td>0.367300</td>\n","      <td>0.367300</td>\n","      <td>0.405600</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.024900</td>\n","      <td>1.125634</td>\n","      <td>0.456400</td>\n","      <td>0.389300</td>\n","      <td>0.389300</td>\n","      <td>0.446000</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>1.017700</td>\n","      <td>1.118906</td>\n","      <td>0.415600</td>\n","      <td>0.373300</td>\n","      <td>0.373300</td>\n","      <td>0.420800</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.054500</td>\n","      <td>1.108778</td>\n","      <td>0.396000</td>\n","      <td>0.362900</td>\n","      <td>0.362900</td>\n","      <td>0.398400</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>1.033900</td>\n","      <td>1.062676</td>\n","      <td>0.448800</td>\n","      <td>0.405500</td>\n","      <td>0.405500</td>\n","      <td>0.457100</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>1.049400</td>\n","      <td>1.060683</td>\n","      <td>0.501600</td>\n","      <td>0.380800</td>\n","      <td>0.380800</td>\n","      <td>0.453200</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>1.051900</td>\n","      <td>1.069072</td>\n","      <td>0.455600</td>\n","      <td>0.384600</td>\n","      <td>0.384600</td>\n","      <td>0.448600</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.918200</td>\n","      <td>1.146343</td>\n","      <td>0.475200</td>\n","      <td>0.377700</td>\n","      <td>0.377700</td>\n","      <td>0.440500</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.946800</td>\n","      <td>1.109124</td>\n","      <td>0.430800</td>\n","      <td>0.403100</td>\n","      <td>0.403100</td>\n","      <td>0.449300</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.951000</td>\n","      <td>1.148365</td>\n","      <td>0.443200</td>\n","      <td>0.416600</td>\n","      <td>0.416600</td>\n","      <td>0.462700</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.963700</td>\n","      <td>1.081059</td>\n","      <td>0.485200</td>\n","      <td>0.435500</td>\n","      <td>0.435500</td>\n","      <td>0.493100</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.940100</td>\n","      <td>1.152081</td>\n","      <td>0.422000</td>\n","      <td>0.382600</td>\n","      <td>0.382600</td>\n","      <td>0.426400</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.814300</td>\n","      <td>1.202284</td>\n","      <td>0.462000</td>\n","      <td>0.413300</td>\n","      <td>0.413300</td>\n","      <td>0.466400</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.749700</td>\n","      <td>1.284986</td>\n","      <td>0.438000</td>\n","      <td>0.410500</td>\n","      <td>0.410500</td>\n","      <td>0.449900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-100\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-100/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-100/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-100/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-100/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-150\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-150/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-150/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-150/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-150/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-200\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-200/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-200/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-200/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-200/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-250\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-250/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-250/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-250/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-250/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-300\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-300/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-300/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-300/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-300/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-350\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-350/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-350/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-350/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-350/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-400\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-400/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-400/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-400/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-400/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-450\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-450/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-450/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-450/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-450/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-500\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-500/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-550\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-550/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-550/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-550/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-550/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-600\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-600/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-600/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-600/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-600/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-650\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-650/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-650/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-650/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-650/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-700\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-700/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-700/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-700/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-700/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-750\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-750/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-750/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-750/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-750/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-800\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-800/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-800/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-800/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-800/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-850\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-850/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-850/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-850/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-850/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-900\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-900/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-900/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-900/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-900/special_tokens_map.json\n"]}]},{"cell_type":"markdown","metadata":{"id":"FMkR5GX8qEIB"},"source":["# **Testing**"]},{"cell_type":"code","metadata":{"id":"lSJ7XnOTwP2g"},"source":["class_names = [\"IMPLAUSIBLE\", \"NEUTRAL\", \"PLAUSIBLE\"]\n","\n","LABEL_DICT = {}\n","LABEL_DICT[class_names[0]] = 0\n","LABEL_DICT[class_names[1]] = 1\n","LABEL_DICT[class_names[2]] = 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"to0VNWg5GMti","executionInfo":{"status":"ok","timestamp":1625751778126,"user_tz":-360,"elapsed":429,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"a2ccccfd-25e1-4629-c1be-44f3fcd424c2"},"source":["print(tokenizer.batch_decode(train_dataset[499:500]['input_ids']))\n","\n","labels_ids = train_dataset[499:500]['labels']#[test_dataset[499:500]['labels'] == -100] = tokenizer.pad_token_id\n","labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n","#print(labels_ids)\n","output = tokenizer.batch_decode(labels_ids, skip_special_tokens=False)\n","print(output[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[\"solve: def sat(x: List[int], a: int=-165, r: int=1, l: int=42): assert type(x) is list and all(type(a) is int for a in x), 'x must be of type List[int]' return x[0] == a and len(x) == l and all([x[i] * r == x[i + 1] for i in range(len(x) - 1)])</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\"]\n","sol(a=-165, r=1, l=42): return [a * r ** i for i in range(l)]</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AUCrq4edW5j3","executionInfo":{"status":"ok","timestamp":1625751805282,"user_tz":-360,"elapsed":452,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"a2743cbd-eb9a-4148-af60-5bbae0b62f74"},"source":["print(tokenizer.special_tokens_map)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': \"['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']\"}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PBIhqWDJPT_v"},"source":["from transformers import AutoModelForSequenceClassification\n","model = AutoModelForSequenceClassification.from_pretrained(project_path+'Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-900',num_labels=3)\n","model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lEekCQDmPU_V"},"source":["start = 200\n","end = 210\n","model.eval()\n","outputs = model(input_ids=test_dataset[start:end]['input_ids'].to(device),attention_mask=test_dataset[start:end]['attention_mask'].to(device))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9WDuXv11PYA-","executionInfo":{"status":"ok","timestamp":1636923665261,"user_tz":480,"elapsed":1017,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12040636431562290492"}},"outputId":"066def30-a1d8-4f89-b0a7-1e3f34155264"},"source":["print(np.argmax(outputs.logits.detach().cpu().numpy(),axis=1))\n","print(test_dataset[start:end]['labels'])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2 2 2 2 2 1 2 1 1 2]\n","tensor([0, 0, 1, 2, 1, 0, 1, 0, 0, 2])\n"]}]},{"cell_type":"code","metadata":{"id":"BinEuSh8YNuf"},"source":["accuracy = Accuracy(actual_str,output_str)\n","sommth_bleu_score = round(_bleu(actual_str, output_str),2)\n","\n","print(accuracy)\n","print(sommth_bleu_score)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JTPCopoGZzTd"},"source":["total_output_str=[]\n","batch_size = 100\n","\n","curr = 0\n","for i in range(0,len(test_dataset),batch_size):\n","  end = min(i+batch_size,len(test_dataset))\n","  code_tokens = ed.generate(input_ids=test_dataset[i:end]['input_ids'].to(device),attention_mask=test_dataset[i:end]['attention_mask'].to(device))\n","  \n","  codes = decoder_tokenizer.batch_decode(code_tokens,skip_special_tokens=True)\n","\n","  for c in codes:\n","    total_output_str.append(c)\n","  print(i)\n","  if(end == len(test_dataset)):\n","    break\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RwXy5K__TnQ1","executionInfo":{"status":"ok","timestamp":1624463170470,"user_tz":-360,"elapsed":12,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"b288768f-b9c7-4541-8ad5-17bf675fd7cd"},"source":["print(len(total_output_str))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["6545\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XnxauUisXJ14"},"source":["class Example(object):\n","    \"\"\"A single training/test example.\"\"\"\n","    def __init__(self,\n","                 idx,\n","                 source,\n","                 target,\n","                 ):\n","        self.idx = idx\n","        self.source = source\n","        self.target = target"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r1haZjJ8Xe8E"},"source":["import pickle\n","with open(project_path+'Pickles/pickle_test_buggy_fixed_1.pickle', 'rb') as f:\n","  test_examples = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K5vm5E9gXgfR","executionInfo":{"status":"ok","timestamp":1624463170958,"user_tz":-360,"elapsed":15,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"296d3f96-a55a-463f-b3fe-41be9de8f284"},"source":["total_actual_str=[]\n","\n","for te in test_examples:\n","  total_actual_str.append(te.target)\n","\n","print(len(total_actual_str))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["6545\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bFQg6nPQnmKh"},"source":["import pickle\n","with open(project_path+'Pickles/pickle_pred_test_buggy_fixed_13000_1.pickle', 'wb') as f:\n","  pickle.dump((total_actual_str,total_output_str),f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D6m6Eu4uoEUl"},"source":["import pickle\n","with open(project_path+'Pickles/pickle_pred_test_buggy_fixed_13000_1.pickle', 'rb') as f:\n","  total_actual_str,total_output_str = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bDwUATPdX0JK","executionInfo":{"status":"ok","timestamp":1624464471028,"user_tz":-360,"elapsed":414,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"a8eca143-6574-43a2-db93-e0e02885563d"},"source":["print(total_actual_str[100])\n","print(total_output_str[100])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["public void METHOD_1 ( ) { TYPE_1 query = new TYPE_1 ( ) ; TYPE_2 VAR_1 = TYPE_3 . METHOD_2 ( VAR_2 class ) ; TYPE_3 . METHOD_3 ( VAR_1 . getId ( ) ) . METHOD_4 ( 1 ) ; TYPE_3 . METHOD_5 ( VAR_1 ) ; java.lang.Long count = VAR_3 . METHOD_6 ( VAR_1 , query ) ; TYPE_4 . assertEquals ( INT_2 , count . METHOD_7 ( ) ) ; }\n","public void METHOD_1 ( ) { TYPE_1 query = new TYPE_1 ( ) ; TYPE_2 VAR_1 = TYPE_3. METHOD_2 ( VAR_2 class ) ; TYPE_3. METHOD_3 ( VAR_1. getId ( ) ). METHOD_4 ( INT_1 ) ; TYPE_3. METHOD_5 ( VAR_1 ) ; java.lang.Long count = VAR_3. METHOD_6 ( VAR_1, query ) ; TYPE_4. assertEquals ( INT_2, count. METHOD_7 ( ) ) ; }\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KUFMXJPrxaqs","executionInfo":{"status":"ok","timestamp":1624464289031,"user_tz":-360,"elapsed":3404,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"5283b33f-8801-4c03-92a2-3489af3fa4de"},"source":["accuracy = Accuracy(total_actual_str,total_output_str)\n","sommth_bleu_score = round(_bleu(total_actual_str, total_output_str),2)\n","\n","print(accuracy)\n","print(sommth_bleu_score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[['public', 'java.lang.String', 'METHOD_1', '(', ')', '{', 'if', '(', '(', 'METHOD_2', '(', ')', ')', '&&', '(', 'METHOD_3', '(', 'VAR_1', '.', 'METHOD_4', '(', ')', ')', ')', ')', '{', 'return', 'VAR_1', '.', 'METHOD_4', '(', ')', ';', '}', 'else', 'if', '(', 'METHOD_3', '(', 'VAR_3', '.', 'METHOD_5', '(', ')', '.', 'METHOD_6', '(', ')', ')', ')', '{', 'return', 'VAR_3', '.', 'METHOD_5', '(', ')', '.', 'METHOD_6', '(', ')', ';', '}', 'else', '{', 'return', 'VAR_4', '.', 'METHOD_4', '(', ')', ';', '}', '}'], ['private', 'void', 'METHOD_1', '(', 'TYPE_1', 'index', ',', 'java.util.Collection', '<', 'TYPE_2', '>', 'VAR_1', ')', '{', 'TYPE_1', 'VAR_2', '=', 'index', '.', 'METHOD_2', '(', 'VAR_3', ')', ';', 'for', '(', 'TYPE_3', '<', 'TYPE_2', '>', 'VAR_4', ':', 'this', '.', 'VAR_1', '.', 'values', '(', ')', ')', '{', 'VAR_4', '.', 'METHOD_3', '(', 'VAR_2', ',', 'null', ')', ';', '}', 'METHOD_4', '(', 'index', ',', 'VAR_1', ')', ';', '}'], ['public', 'void', 'remove', '(', 'int', 'id', ')', '{', 'try', '{', 'java.lang.String', 'query', '=', 'STRING_1', ';', 'TYPE_1', 'VAR_1', '=', 'METHOD_1', '(', ')', ';', 'TYPE_2', 'VAR_2', '=', 'VAR_1', '.', 'METHOD_2', '(', 'query', ')', ';', 'VAR_2', '.', 'METHOD_3', '(', '1', ',', 'id', ')', ';', 'VAR_2', '.', 'METHOD_4', '(', ')', ';', '}', 'catch', '(', 'TYPE_3', 'VAR_3', ')', '{', 'java.lang.System.out.println', '(', 'STRING_2', ')', ';', '}', '}'], ['private', 'java.util.List', '<', 'TYPE_1', '>', 'METHOD_1', '(', ')', '{', 'java.util.List', '<', 'TYPE_1', '>', 'VAR_2', '=', 'new', 'java.util.ArrayList', '<', '>', '(', ')', ';', 'for', '(', 'int', 'i', '=', '0', ';', 'i', '<', '(', 'VAR_3', '.', 'size', '(', ')', ')', ';', 'i', '++', ')', '{', 'TYPE_1', 'VAR_1', '=', 'new', 'TYPE_1', '(', ')', ';', 'VAR_1', '.', 'METHOD_2', '(', 'VAR_3', '.', 'get', '(', 'i', ')', '.', 'METHOD_3', '(', ')', ')', ';', 'VAR_2', '.', 'add', '(', 'VAR_1', ')', ';', '}', 'return', 'VAR_2', ';', '}'], ['private', 'void', 'METHOD_1', '(', 'java.util.List', '<', 'TYPE_1', '>', 'parameters', ',', 'TYPE_2', 'VAR_1', ')', '{', 'while', '(', 'VAR_1', '.', 'METHOD_2', '(', ')', ')', '{', 'TYPE_3', 'VAR_2', '=', 'METHOD_3', '(', 'VAR_1', ')', ';', 'if', '(', 'VAR_2', '==', 'null', ')', '{', 'break', ';', '}', 'if', '(', 'VAR_2', '.', 'METHOD_4', '(', ')', ')', '{', 'METHOD_6', '(', 'parameters', ',', 'METHOD_7', '(', 'VAR_2', ')', ')', ';', '}', 'VAR_1', '=', '(', '(', 'TYPE_2', ')', '(', 'VAR_2', '.', 'METHOD_8', '(', ')', ')', ')', ';', '}', '}']]\n","[['public', 'java.lang.String', 'METHOD_1', '(', ')', '{', 'if', '(', '(', 'METHOD_2', '(', ')', ')', '&&', '(', 'METHOD_3', '(', 'VAR_1.', 'METHOD_4', '(', ')', ')', ')', ')', '{', 'return', 'VAR_2.', 'METHOD_4', '(', ')', ';', '}', 'else', 'if', '(', 'METHOD_3', '(', 'VAR_3.', 'METHOD_5', '(', ').', 'METHOD_6', '(', ')', ')', ')', '{', 'return', 'VAR_3.', 'METHOD_5', '(', ').', 'METHOD_6', '(', ')', ';', '}', 'else', '{', 'return', 'VAR_4.', 'METHOD_4', '(', ')', ';', '}', '}'], ['private', 'void', 'METHOD_1', '(', 'TYPE_1', 'index,', 'java.util.Collection', '<', 'TYPE_2', '>', 'VAR_1', ')', '{', 'TYPE_1', 'VAR_2', '=', 'index.', 'METHOD_2', '(', 'VAR_3', ')', ';', 'for', '(', 'TYPE_3', '<', 'TYPE_2', '>', 'VAR_4', ':', 'this.', 'VAR_1.', 'values', '(', ')', ')', '{', 'VAR_4.', 'METHOD_3', '(', 'VAR_2,', 'null', ')', ';', '}', 'METHOD_4', '(', 'VAR_2,', 'VAR_1', ')', ';', '}'], ['public', 'void', 'remove', '(', 'int', 'id', ')', '{', 'try', '{', 'java.lang.String', 'query', '=', 'STRING_1', ';', 'TYPE_1', 'VAR_1', '=', 'METHOD_1', '(', ')', ';', 'TYPE_2', 'VAR_2', '=', 'VAR_1.', 'METHOD_2', '(', 'query', ')', ';', 'VAR_2.', 'METHOD_3', '(', '1,', 'id', ')', ';', 'VAR_2.', 'METHOD_4', '(', ')', ';', '}', 'catch', '(', 'TYPE_3', 'VAR_3', ')', '{', 'VAR_3.', 'METHOD_5', '(', ')', ';', 'java.lang.System.out.println', '(', 'STRING_2', ')', ';', '}', '}'], ['private', 'java.util.List', '<', 'TYPE_1', '>', 'METHOD_1', '(', ')', '{', 'TYPE_1', 'VAR_1', '=', 'new', 'TYPE_1', '(', ')', ';', 'java.util.List', '<', 'TYPE_1', '>', 'VAR_2', '=', 'new', 'java.util.ArrayList', '<', '>', '(', ')', ';', 'for', '(', 'int', 'i', '=', '0', ';', 'i', '<', '(', 'VAR_3.', 'size', '(', ')', ')', ';', 'i', '++', ')', '{', 'VAR_1.', 'METHOD_2', '(', 'VAR_3.', 'get', '(', 'i', ').', 'METHOD_3', '(', ')', ')', ';', 'VAR_2.', 'add', '(', 'VAR_1', ')', ';', '}', 'return', 'VAR_2', ';', '}'], ['private', 'void', 'METHOD_1', '(', 'java.util.List', '<', 'TYPE_1', '>', 'parameters,', 'TYPE_2', 'VAR_1', ')', '{', 'while', '(', 'VAR_1.', 'METHOD_2', '(', ')', ')', '{', 'TYPE_3', 'VAR_2', '=', 'METHOD_3', '(', 'VAR_1', ')', ';', 'if', '(', 'VAR_2', '==', 'null', ')', '{', 'break', ';', '}', 'if', '(', 'TYPE_4.', 'METHOD_4', '(', 'VAR_2.', 'METHOD_5', '(', ')', ')', ')', '{', 'METHOD_6', '(', 'parameters,', 'METHOD_7', '(', 'VAR_2', ')', ')', ';', '}', 'VAR_1', '=', '(', '(', 'TYPE_2', ')', '(', 'VAR_2.', 'METHOD_8', '(', ')', ')', ')', ';', '}', '}']]\n","0.17\n","61.45\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IGGJYnLmxV7E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624464281813,"user_tz":-360,"elapsed":3807,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"647a87ea-6783-4c93-aa76-bf5a73740eea"},"source":["accuracy = Accuracy(total_actual_str,total_actual_str)\n","sommth_bleu_score = round(_bleu(total_actual_str, total_actual_str),2)\n","\n","print(accuracy)\n","print(sommth_bleu_score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[['public', 'java.lang.String', 'METHOD_1', '(', ')', '{', 'if', '(', '(', 'METHOD_2', '(', ')', ')', '&&', '(', 'METHOD_3', '(', 'VAR_1', '.', 'METHOD_4', '(', ')', ')', ')', ')', '{', 'return', 'VAR_1', '.', 'METHOD_4', '(', ')', ';', '}', 'else', 'if', '(', 'METHOD_3', '(', 'VAR_3', '.', 'METHOD_5', '(', ')', '.', 'METHOD_6', '(', ')', ')', ')', '{', 'return', 'VAR_3', '.', 'METHOD_5', '(', ')', '.', 'METHOD_6', '(', ')', ';', '}', 'else', '{', 'return', 'VAR_4', '.', 'METHOD_4', '(', ')', ';', '}', '}'], ['private', 'void', 'METHOD_1', '(', 'TYPE_1', 'index', ',', 'java.util.Collection', '<', 'TYPE_2', '>', 'VAR_1', ')', '{', 'TYPE_1', 'VAR_2', '=', 'index', '.', 'METHOD_2', '(', 'VAR_3', ')', ';', 'for', '(', 'TYPE_3', '<', 'TYPE_2', '>', 'VAR_4', ':', 'this', '.', 'VAR_1', '.', 'values', '(', ')', ')', '{', 'VAR_4', '.', 'METHOD_3', '(', 'VAR_2', ',', 'null', ')', ';', '}', 'METHOD_4', '(', 'index', ',', 'VAR_1', ')', ';', '}'], ['public', 'void', 'remove', '(', 'int', 'id', ')', '{', 'try', '{', 'java.lang.String', 'query', '=', 'STRING_1', ';', 'TYPE_1', 'VAR_1', '=', 'METHOD_1', '(', ')', ';', 'TYPE_2', 'VAR_2', '=', 'VAR_1', '.', 'METHOD_2', '(', 'query', ')', ';', 'VAR_2', '.', 'METHOD_3', '(', '1', ',', 'id', ')', ';', 'VAR_2', '.', 'METHOD_4', '(', ')', ';', '}', 'catch', '(', 'TYPE_3', 'VAR_3', ')', '{', 'java.lang.System.out.println', '(', 'STRING_2', ')', ';', '}', '}'], ['private', 'java.util.List', '<', 'TYPE_1', '>', 'METHOD_1', '(', ')', '{', 'java.util.List', '<', 'TYPE_1', '>', 'VAR_2', '=', 'new', 'java.util.ArrayList', '<', '>', '(', ')', ';', 'for', '(', 'int', 'i', '=', '0', ';', 'i', '<', '(', 'VAR_3', '.', 'size', '(', ')', ')', ';', 'i', '++', ')', '{', 'TYPE_1', 'VAR_1', '=', 'new', 'TYPE_1', '(', ')', ';', 'VAR_1', '.', 'METHOD_2', '(', 'VAR_3', '.', 'get', '(', 'i', ')', '.', 'METHOD_3', '(', ')', ')', ';', 'VAR_2', '.', 'add', '(', 'VAR_1', ')', ';', '}', 'return', 'VAR_2', ';', '}'], ['private', 'void', 'METHOD_1', '(', 'java.util.List', '<', 'TYPE_1', '>', 'parameters', ',', 'TYPE_2', 'VAR_1', ')', '{', 'while', '(', 'VAR_1', '.', 'METHOD_2', '(', ')', ')', '{', 'TYPE_3', 'VAR_2', '=', 'METHOD_3', '(', 'VAR_1', ')', ';', 'if', '(', 'VAR_2', '==', 'null', ')', '{', 'break', ';', '}', 'if', '(', 'VAR_2', '.', 'METHOD_4', '(', ')', ')', '{', 'METHOD_6', '(', 'parameters', ',', 'METHOD_7', '(', 'VAR_2', ')', ')', ';', '}', 'VAR_1', '=', '(', '(', 'TYPE_2', ')', '(', 'VAR_2', '.', 'METHOD_8', '(', ')', ')', ')', ';', '}', '}']]\n","[['public', 'java.lang.String', 'METHOD_1', '(', ')', '{', 'if', '(', '(', 'METHOD_2', '(', ')', ')', '&&', '(', 'METHOD_3', '(', 'VAR_1', '.', 'METHOD_4', '(', ')', ')', ')', ')', '{', 'return', 'VAR_1', '.', 'METHOD_4', '(', ')', ';', '}', 'else', 'if', '(', 'METHOD_3', '(', 'VAR_3', '.', 'METHOD_5', '(', ')', '.', 'METHOD_6', '(', ')', ')', ')', '{', 'return', 'VAR_3', '.', 'METHOD_5', '(', ')', '.', 'METHOD_6', '(', ')', ';', '}', 'else', '{', 'return', 'VAR_4', '.', 'METHOD_4', '(', ')', ';', '}', '}'], ['private', 'void', 'METHOD_1', '(', 'TYPE_1', 'index', ',', 'java.util.Collection', '<', 'TYPE_2', '>', 'VAR_1', ')', '{', 'TYPE_1', 'VAR_2', '=', 'index', '.', 'METHOD_2', '(', 'VAR_3', ')', ';', 'for', '(', 'TYPE_3', '<', 'TYPE_2', '>', 'VAR_4', ':', 'this', '.', 'VAR_1', '.', 'values', '(', ')', ')', '{', 'VAR_4', '.', 'METHOD_3', '(', 'VAR_2', ',', 'null', ')', ';', '}', 'METHOD_4', '(', 'index', ',', 'VAR_1', ')', ';', '}'], ['public', 'void', 'remove', '(', 'int', 'id', ')', '{', 'try', '{', 'java.lang.String', 'query', '=', 'STRING_1', ';', 'TYPE_1', 'VAR_1', '=', 'METHOD_1', '(', ')', ';', 'TYPE_2', 'VAR_2', '=', 'VAR_1', '.', 'METHOD_2', '(', 'query', ')', ';', 'VAR_2', '.', 'METHOD_3', '(', '1', ',', 'id', ')', ';', 'VAR_2', '.', 'METHOD_4', '(', ')', ';', '}', 'catch', '(', 'TYPE_3', 'VAR_3', ')', '{', 'java.lang.System.out.println', '(', 'STRING_2', ')', ';', '}', '}'], ['private', 'java.util.List', '<', 'TYPE_1', '>', 'METHOD_1', '(', ')', '{', 'java.util.List', '<', 'TYPE_1', '>', 'VAR_2', '=', 'new', 'java.util.ArrayList', '<', '>', '(', ')', ';', 'for', '(', 'int', 'i', '=', '0', ';', 'i', '<', '(', 'VAR_3', '.', 'size', '(', ')', ')', ';', 'i', '++', ')', '{', 'TYPE_1', 'VAR_1', '=', 'new', 'TYPE_1', '(', ')', ';', 'VAR_1', '.', 'METHOD_2', '(', 'VAR_3', '.', 'get', '(', 'i', ')', '.', 'METHOD_3', '(', ')', ')', ';', 'VAR_2', '.', 'add', '(', 'VAR_1', ')', ';', '}', 'return', 'VAR_2', ';', '}'], ['private', 'void', 'METHOD_1', '(', 'java.util.List', '<', 'TYPE_1', '>', 'parameters', ',', 'TYPE_2', 'VAR_1', ')', '{', 'while', '(', 'VAR_1', '.', 'METHOD_2', '(', ')', ')', '{', 'TYPE_3', 'VAR_2', '=', 'METHOD_3', '(', 'VAR_1', ')', ';', 'if', '(', 'VAR_2', '==', 'null', ')', '{', 'break', ';', '}', 'if', '(', 'VAR_2', '.', 'METHOD_4', '(', ')', ')', '{', 'METHOD_6', '(', 'parameters', ',', 'METHOD_7', '(', 'VAR_2', ')', ')', ';', '}', 'VAR_1', '=', '(', '(', 'TYPE_2', ')', '(', 'VAR_2', '.', 'METHOD_8', '(', ')', ')', ')', ';', '}', '}']]\n","100.0\n","100.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"djtFAyfe2ncv","executionInfo":{"status":"ok","timestamp":1624032134883,"user_tz":-360,"elapsed":535,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"06154810530490924203"}},"outputId":"47eec9a3-21e7-4b9f-ba14-d44bba4ccdac"},"source":["print(ed.config.encoder.max_length)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["20\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ht2OMlcq5fF","executionInfo":{"status":"ok","timestamp":1623752484246,"user_tz":-360,"elapsed":420,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"06154810530490924203"}},"outputId":"edb45d68-7745-4517-f91b-ba8c78620aa5"},"source":["import torch\n","output_ids_padding = torch.where(train_labels[0]== -100,led_tokenizer.pad_token_id,train_labels[0])\n","print(led_tokenizer.decode(output_ids_padding))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<s>[problem_tags]greedy, math, sortings[problem_difficulty]1100[req_time]218 ms[req_memory]400 KB[code_text]#include<bits/stdc++.h>\r\r\n","using namespace std;\r\r\n","\r\r\n","int main()\r\r\n","{\r\r\n","\tint t; cin>>t; while(t-->0){\r\r\n","\t\tint n; cin>>n; int a[n]; for(int i=0;i<n;i++) cin>>a[i];\r\r\n","\t\tint p=n-1; sort(a,a+n);\r\r\n","\t\tfor(int i=0;i<p;i++){\r\r\n","\t\t\tif(a[i+1]-a[i] < a[p]){\r\r\n","\t\t\t\tp--; i--;\r\r\n","\t\t\t}\r\r\n","\t\t}\r\r\n","\t\tcout << p+1 << endl;\r\r\n","\t}\r\r\n","}</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tSp5J6ltjHP6"},"source":["import torch\n","\n","from datasets import load_dataset, load_metric\n","from transformers import LEDTokenizer, LEDForConditionalGeneration\n","\n","# load pubmed\n","pubmed_test = load_dataset(\"scientific_papers\", \"pubmed\", ignore_verifications=True, split=\"test\")\n","\n","# load tokenizer\n","tokenizer = LEDTokenizer.from_pretrained(\"patrickvonplaten/led-large-16384-pubmed\")\n","model = LEDForConditionalGeneration.from_pretrained(\"patrickvonplaten/led-large-16384-pubmed\").to(\"cuda\").half()\n","\n","\n","def generate_answer(batch):\n","  inputs_dict = tokenizer(batch[\"article\"], padding=\"max_length\", max_length=8192, return_tensors=\"pt\", truncation=True)\n","  input_ids = inputs_dict.input_ids.to(\"cuda\")\n","  attention_mask = inputs_dict.attention_mask.to(\"cuda\")\n","  global_attention_mask = torch.zeros_like(attention_mask)\n","  # put global attention on <s> token\n","  global_attention_mask[:, 0] = 1\n","\n","  predicted_abstract_ids = model.generate(input_ids, attention_mask=attention_mask, global_attention_mask=global_attention_mask)\n","  batch[\"predicted_abstract\"] = tokenizer.batch_decode(predicted_abstract_ids, skip_special_tokens=True)\n","  return batch\n","\n","\n","result = pubmed_test.map(generate_answer, batched=True, batch_size=4)\n","\n","# load rouge\n","rouge = load_metric(\"rouge\")\n","\n","print(\"Result:\", rouge.compute(predictions=result[\"predicted_abstract\"], references=result[\"abstract\"], rouge_types=[\"rouge2\"])[\"rouge2\"].mid)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UkDe4LKiJcPI"},"source":["for i in range(len(train_labels)):\n","  for x in train_labels[i]:\n","    if(x>50277 or x<0):\n","      print(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t-JsofAhQU-B"},"source":["for x in train_labels[0]:\n","  if(x!=1):\n","    #print(x)\n","    #s = led_tokenizer.convert_ids_to_tokens(torch.tensor([x]))\n","    #x = led_model.get_decoder().embed_tokens(train_labels[0])[0]\n","    #print(s)\n","    m = led_model.get_decoder()\n","    ss = m(tensorify([[x]]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zJxUK4pJb6nw","executionInfo":{"status":"ok","timestamp":1622920670945,"user_tz":-360,"elapsed":575,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"74e9e588-8025-48f7-d830-47c1e9c7a61b"},"source":["arr = torch.zeros_like(train_labels[0])\n","print(len(arr))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["4096\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XxnwUjfMe3Aa"},"source":["print(led_model.config.max_decoder_position_embeddings)\n","dec = led_model.get_decoder()\n","print(led_model.get_decoder().embed_tokens)\n","dec.set_input_embeddings(led_model.get_encoder().embed_tokens)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":340},"id":"-pFi8xqyaGAX","executionInfo":{"status":"error","timestamp":1622923729558,"user_tz":-360,"elapsed":389,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"bff6c710-6fd9-45bf-e400-01763dfbf57f"},"source":["x = edm.get_decoder()\n","ss = x(tensorify([arr[:1024]]))"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-49-2bb4de1c05e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensorify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/reformer/modeling_reformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, position_ids, attention_mask, head_mask, inputs_embeds, num_hashes, past_buckets_states, use_cache, output_hidden_states, output_attentions, return_dict, labels)\u001b[0m\n\u001b[1;32m   2236\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2237\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2238\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2239\u001b[0m         )\n\u001b[1;32m   2240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/reformer/modeling_reformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, num_hashes, past_buckets_states, use_cache, output_hidden_states, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m   2083\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2084\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2085\u001b[0;31m             \u001b[0mstart_idx_pos_encodings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_idx_pos_encodings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2086\u001b[0m         )\n\u001b[1;32m   2087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/reformer/modeling_reformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, position_ids, inputs_embeds, start_idx_pos_encodings)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m# add positional embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/reformer/modeling_reformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, position_ids)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxial_pos_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 raise ValueError(\n\u001b[0;32m--> 156\u001b[0;31m                     \u001b[0;34mf\"If training, make sure that config.axial_pos_shape factors: {self.axial_pos_shape} multiply to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                     \u001b[0;34mf\"sequence length. Got prod({self.axial_pos_shape}) != sequence_length: {sequence_length}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                     \u001b[0;34mf\"You might want to consider padding your sequence length to {reduce(mul, self.axial_pos_shape)} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: If training, make sure that config.axial_pos_shape factors: (128, 512) multiply to sequence length. Got prod((128, 512)) != sequence_length: 1024. You might want to consider padding your sequence length to 65536 or changing config.axial_pos_shape."]}]},{"cell_type":"code","metadata":{"id":"UsKew13SR3sD"},"source":["print(ss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x4u0kzyrFKx5","executionInfo":{"status":"ok","timestamp":1622911805192,"user_tz":-360,"elapsed":405,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"95c67d2e-e857-482f-b1a2-17a62573c430"},"source":["print(len(led_tokenizer))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["50265\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qOlwP_wSFO8u"},"source":["print(led_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j5vDcLYyhSbl"},"source":["model = led_model.get_decoder()\n","#x.from_pretrained(\"allenai/led-base-16384\")\n","model.max_target_positions = 2048"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8kbNwdP1m8fq"},"source":["from transformers import EncoderDecoderModel,AutoModelForCausalLM\n","\n","encoder_model = AutoModelForCausalLM.from_pretrained('allenai/longformer-base-4096')\n","#encoder_model.resize_token_embeddings(len(encoder_tokenizer))\n","\n","encoder_model.save_pretrained(project_path+'Saved_Models/Longformer_Encoder_Init_2')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KoDI4zbRpeX1"},"source":["from transformers import EncoderDecoderModel,AutoModelForSeq2SeqLM, ReformerModel,ReformerForMaskedLM\n","\n","edm = EncoderDecoderModel.from_encoder_decoder_pretrained(project_path+'Saved_Models/asd_E',project_path+'Saved_Models/asd_D')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wMMSQ3nMxWAY","executionInfo":{"status":"ok","timestamp":1623221292691,"user_tz":-360,"elapsed":8787,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"12a3852a-cc35-4926-9005-53906401f8ea"},"source":["print(edm.config.decoder.max_position_embeddings)\n","\n","edm.save_pretrained(project_path+'Saved_Models/asd_ED')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["65536\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IaiojYkjgZMV"},"source":["from transformers import ReformerModel, ReformerConfig\n","# Initializing a Reformer configuration\n","configuration = ReformerConfig.from_pretrained(\"google/reformer-enwik8\", lsh_attn_chunk_length=16386, local_attn_chunk_length=16386)\n","# Initializing a Reformer model\n","enc_model = ReformerModel(configuration)\n","\n","enc_model.save_pretrained(project_path+'Saved_Models/asd_E')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fHywIi9Lgps7"},"source":["from transformers import ReformerForMaskedLM, ReformerConfig\n","# Initializing a Reformer configuration\n","configuration = ReformerConfig.from_pretrained(\"google/reformer-enwik8\", lsh_attn_chunk_length=16386, local_attn_chunk_length=16386)\n","configuration.is_decoder=False\n","# Initializing a Reformer model\n","dec_model = ReformerForMaskedLM(configuration)\n","\n","dec_model.save_pretrained(project_path+'Saved_Models/asd_D')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZGHTUf4ecHdH"},"source":["red = AutoModelForSeq2SeqLM.from_pretrained(project_path+'Saved_Models/asd_ED')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L--c2w-3h6KW","executionInfo":{"status":"ok","timestamp":1623221451026,"user_tz":-360,"elapsed":340,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"55240be5-4d04-43d3-b253-28b0c90f4d3f"},"source":["print(red.config.decoder.is_decoder)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dl3iiv78lHjz","executionInfo":{"status":"ok","timestamp":1623222892873,"user_tz":-360,"elapsed":4739,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"4dc8acd5-71b5-4922-97a2-cbdeccf772a7"},"source":["cnt_1024 = 0\n","cnt_4096 = 0\n","\n","for x in train_labels:\n","  try:\n","    if(x.tolist().index(1)+1<=1023):\n","      cnt_1024=cnt_1024+1\n","    else:\n","      cnt_4096 = cnt_4096+1\n","  except:\n","    cnt_4096 = cnt_4096+1\n","\n","print(cnt_1024)\n","print(cnt_4096)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["16863\n","12389\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"81l9k2RDnro3","executionInfo":{"status":"ok","timestamp":1623222847906,"user_tz":-360,"elapsed":323,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"1655e8db-b97c-47cd-ba01-1aba646dc43e"},"source":["print(len(train_encoding['input_ids']))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["29252\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mGMhJU43lwrD","executionInfo":{"status":"ok","timestamp":1623222574131,"user_tz":-360,"elapsed":349,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"5b5ffb29-b5cc-4f40-df68-fb382ffe792c"},"source":["print(train_encoding['input_ids'][0].tolist().index(1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["626\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238,"referenced_widgets":["3fd406cb781c4531bfeae59f1b2f8460","0ed49ed0fabc433892cb6e66256b110a","9f2417e77b5c40529814b17863ed7abc","0c34082f5e4440f8a83b57148659ef8e","057582f7457a420d8756a3ba6d057634","dd767d8c985a4576a49fac5b8d9be619","08929d7f50684c7c8ada1dfd288038e9","38ec365837fa4ff0a2be6c8cba2ab4d2","7d0bb7a8222c4cdd93ebe7343c255476","7270e156c2ff4542bd03b3a45226bb57","27d0397128774943a646b8e58302a4c0","8d6ab9f9e9f64ec29c325fafb95f606b","5019419281ac4713bb661ff4d40a7517","0aaa5b3202324f09a008ba9d56dd9a25","5b6f621fe077499e8f3d16861ad6d3b8","486c7fddcdb6442f8196ee95d637ab75"]},"id":"kssh2MlxlRC1","executionInfo":{"status":"ok","timestamp":1623827507768,"user_tz":-360,"elapsed":19049,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"06154810530490924203"}},"outputId":"51559d13-ea70-4448-d004-da2dd8c46b9d"},"source":["#python_code = \"def convert(x): return x\"\n","PHP_CODE = \"\"\"\n","public static <mask> set(string $key, $value) {\n","    if (!in_array($key, self::$allowedKeys)) {\n","        throw new \\InvalidArgumentException('Invalid key given');\n","    }\n","    self::$storedValues[$key] = $value;\n","}\n","\"\"\".lstrip()\n","\n","from transformers import pipeline, EncoderDecoderModel\n","\n","#summarizer = pipeline(\"summarization\")\n","\n","ed_model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"microsoft/codebert-base-mlm\",\"microsoft/codebert-base\")\n","'''\n","fill_mask = pipeline(\n","    \"summarization\",\n","    model=model,\n","    tokenizer=\"microsoft/codebert-base-mlm\"\n",")\n","\n","print(fill_mask(PHP_CODE))\n","'''\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at microsoft/codebert-base-mlm were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3fd406cb781c4531bfeae59f1b2f8460","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=498.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d0bb7a8222c4cdd93ebe7343c255476","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=498627950.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of RobertaForCausalLM were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.value.bias', 'lm_head.layer_norm.bias', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'lm_head.bias', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.8.crossattention.self.value.bias', 'lm_head.decoder.weight', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.query.weight', 'lm_head.dense.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'lm_head.dense.weight', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.value.bias', 'lm_head.layer_norm.weight', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nfill_mask = pipeline(\\n    \"summarization\",\\n    model=model,\\n    tokenizer=\"microsoft/codebert-base-mlm\"\\n)\\n\\nprint(fill_mask(PHP_CODE))\\n'"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":553,"referenced_widgets":["7e43d9250d9c4fe98cf2194b98c78718","1a94aa7269f04ec0a6225998be67fe19","ee9becdbc1304049894383e58d3494af","b74e72c12b5b4616a8442c4cb6c43d66","4eac87fde4cd41069b79a176f4f0ef2c","05b4472fa511434d976e4fdfe07f0b0e","6d57a22c25154c0bbe08e30c14b14058","257914342d4d46b18d18ce634df1491e","a68e0782e4a5468db873a756625b19de","de2be8b05cce43bfaa77683c05d88601","a5d2b9fc93804566a996519a9effd1b4","da2b4c1886aa436bb65d7bf84ec83591","5dcbe6b0e6ff4a809bbe5169c26ccc66","0c8efdfc214a4555b45553902871ca21","70a386e1270d4cec81a6f8094949f78a","97e7fd5fe96240029d5c945237f2698f","9203100138a345008a2f9a8fbf0d2b64","e1fd4543d8954cf9a39a44e87ff88d51","0619c1520fef496cbe7c7ff7849f5a3e","cf4a578094e34e49b2aa06645c967a45","efc714bbf70346978fc96984d874c14e","4043d03dae6340f69a78ca3de9769269","4f16ea15084949d9ba31135f95e46883","63fccdf13da943d5b6465aac5de450c9","5363e51c14074513a213eee6a32be738","cc3f26fa8f3f408da359dd9fb8951240","42d306f457d342cd9145fa9ac8849bb3","593bba70198e43ff84d417e394fa37ec","4ee0adef37534792857a6d87798d17cb","8eddc5a2839c4b359b7415194dfa7f0f","221f4aaf860c4a6fbafd774a348bb227","d10fc488334e4677842ef6c6230a8d5a"]},"id":"mOUktUDZpWTS","executionInfo":{"status":"error","timestamp":1623830636311,"user_tz":-360,"elapsed":18035,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"06154810530490924203"}},"outputId":"3c42d94d-2c19-4b6a-f721-9856c404adce"},"source":["summarizer = pipeline(\"text-generation\", model=\"microsoft/codebert-base\", tokenizer=\"microsoft/codebert-base\", framework=\"tf\")\n","summarizer(\"def convert_int_to_str(x):\", min_length=5, max_length=50)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e43d9250d9c4fe98cf2194b98c78718","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898822.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a68e0782e4a5468db873a756625b19de","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9203100138a345008a2f9a8fbf0d2b64","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=150.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5363e51c14074513a213eee6a32be738","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=25.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"error","ename":"PipelineException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mPipelineException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-65f1399abde7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummarizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text-generation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"microsoft/codebert-base\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"microsoft/codebert-base\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msummarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"def convert_int_to_str(x):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"feature_extractor\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtask_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, return_full_text, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_model_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALLOWED_MODELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_full_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_full_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mcheck_model_type\u001b[0;34m(self, supported_models)\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m                 \u001b[0;34mf\"The model '{self.model.__class__.__name__}' is not supported for {self.task}. Supported models are {supported_models}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m             )\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mPipelineException\u001b[0m: The model 'RobertaModel' is not supported for text-generation. Supported models are ['XLNetLMHeadModel', 'TransfoXLLMHeadModel', 'ReformerModelWithLMHead', 'GPT2LMHeadModel', 'GPTNeoForCausalLM', 'OpenAIGPTLMHeadModel', 'CTRLLMHeadModel', 'TFXLNetLMHeadModel', 'TFTransfoXLLMHeadModel', 'TFGPT2LMHeadModel', 'TFOpenAIGPTLMHeadModel', 'TFCTRLLMHeadModel']"]}]}]}