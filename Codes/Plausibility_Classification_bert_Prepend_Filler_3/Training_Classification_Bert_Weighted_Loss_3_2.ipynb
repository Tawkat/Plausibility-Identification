{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Training_Classification_Bert_Weighted_Loss_3_2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"372e5db7a46b464a9200d8332b93f7df":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_de15fccdfbd84797a37f685f0ff2bca7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_85bfaac7f795418686b7deff5c09d3eb","IPY_MODEL_6416a0893eea4f1bb0c5bb7b4a3c758d","IPY_MODEL_8ee5fff0a9244e8689acc96f9ba31e2c"]}},"de15fccdfbd84797a37f685f0ff2bca7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"85bfaac7f795418686b7deff5c09d3eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d1b7cf4b365948bf9ca04887303c9d55","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e4b8c8429c624c4c8d4bea08cabad02c"}},"6416a0893eea4f1bb0c5bb7b4a3c758d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_559f2b6a898240f095b491ced12232a5","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":29,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":29,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0d72145305ef435ea89c5bc0e868d190"}},"8ee5fff0a9244e8689acc96f9ba31e2c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d188c899084745cb9330cffb9bfdaa6f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29.0/29.0 [00:00&lt;00:00, 493B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b978275ba5474d6598a3eb9fa5293928"}},"d1b7cf4b365948bf9ca04887303c9d55":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e4b8c8429c624c4c8d4bea08cabad02c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"559f2b6a898240f095b491ced12232a5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0d72145305ef435ea89c5bc0e868d190":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d188c899084745cb9330cffb9bfdaa6f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b978275ba5474d6598a3eb9fa5293928":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"55f7ea7504194c329a3ec27d26c17bbb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_54119a8bf8f741b9b745aa6acd845e6d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_56bfe13e46be4658afba7506b594da3b","IPY_MODEL_5e2c81c54ec6447e902f46ddde315517","IPY_MODEL_61fc0b1739ee406794e4a809f5ba058f"]}},"54119a8bf8f741b9b745aa6acd845e6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"56bfe13e46be4658afba7506b594da3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8969f805094749bfbf9e6d67a6babd93","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_966c84f4074c48ca936eb0d02616076b"}},"5e2c81c54ec6447e902f46ddde315517":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1304bbc7d9a140e9b0fdc2d6f7dd0aac","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":570,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":570,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_69055c854d6d4085af17930770a16f58"}},"61fc0b1739ee406794e4a809f5ba058f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_96066254a7ca4cc688db2d39d392d792","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 570/570 [00:00&lt;00:00, 13.4kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3f074ca2961a4d2b8183620974a0e264"}},"8969f805094749bfbf9e6d67a6babd93":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"966c84f4074c48ca936eb0d02616076b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1304bbc7d9a140e9b0fdc2d6f7dd0aac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"69055c854d6d4085af17930770a16f58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"96066254a7ca4cc688db2d39d392d792":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3f074ca2961a4d2b8183620974a0e264":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4fe543c039254e3cb221101384e7b69b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_535486550eaf4c87a7ebdba58e1ac4f5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f0fc69514cbc4ceaaadf7f4f4a804bae","IPY_MODEL_2de38705aa9846929d56577793d57c72","IPY_MODEL_af8a55260ddb4f07b68dfc4b1fd5af99"]}},"535486550eaf4c87a7ebdba58e1ac4f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f0fc69514cbc4ceaaadf7f4f4a804bae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_20f27f6f87824f37a60fcd70c960da94","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eae71534c5dd4d568f201d4bddb35c63"}},"2de38705aa9846929d56577793d57c72":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5770d12edbac457aa9cd410b7dcd3771","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":213450,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":213450,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ce13a9966d5b4f949cdef20a04a0b90c"}},"af8a55260ddb4f07b68dfc4b1fd5af99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_472bc88f9ed547229d77326d67657e7f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 208k/208k [00:00&lt;00:00, 710kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bf3d396e27664c5194d56fbde00fa4e4"}},"20f27f6f87824f37a60fcd70c960da94":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"eae71534c5dd4d568f201d4bddb35c63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5770d12edbac457aa9cd410b7dcd3771":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ce13a9966d5b4f949cdef20a04a0b90c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"472bc88f9ed547229d77326d67657e7f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bf3d396e27664c5194d56fbde00fa4e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2fccdf6f15f443d8a7ba3c51ab62c6a9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0f1c5d774e4340a79bbccef023395ccc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bf438886a30043929b9774a62e4946aa","IPY_MODEL_f751435e4ad3405782fe67609ed72129","IPY_MODEL_3bf03e876a3840ef94a425572c979e09"]}},"0f1c5d774e4340a79bbccef023395ccc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bf438886a30043929b9774a62e4946aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fe7dcfe8eeb44da0ab6e496036eaac46","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aa3be8db1a4e49a7bd2417d0c2ff5473"}},"f751435e4ad3405782fe67609ed72129":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_72bc60d51c3b400888a102fc8d6aed86","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":435797,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":435797,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2494c3f00ee240698922556db073d919"}},"3bf03e876a3840ef94a425572c979e09":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b84746c6718e4c068db5aa55ff4e53d6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 426k/426k [00:00&lt;00:00, 984kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d7197e85cc3041cb86bf7b636b7bae3b"}},"fe7dcfe8eeb44da0ab6e496036eaac46":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"aa3be8db1a4e49a7bd2417d0c2ff5473":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"72bc60d51c3b400888a102fc8d6aed86":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2494c3f00ee240698922556db073d919":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b84746c6718e4c068db5aa55ff4e53d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d7197e85cc3041cb86bf7b636b7bae3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f2eeafd58f884b2d8e028b17dcf89448":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3682cb47bb4f44b0bfc855d76f1bdd0d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_86e0694b95b947b6b16f935e0ad3ef95","IPY_MODEL_1b43e7d5fa1741879cc304f8cef62a7c","IPY_MODEL_2a49714a8a18417d8d819a13bca8b462"]}},"3682cb47bb4f44b0bfc855d76f1bdd0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"86e0694b95b947b6b16f935e0ad3ef95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_684cacca80d34e81b594bacd65a82ada","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d3e59f72a0bd43b3a57a353d665072f8"}},"1b43e7d5fa1741879cc304f8cef62a7c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b097a2dfda774a37bf6211e377c97186","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":435779157,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":435779157,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_09e8ebf5fc4a49b494f1780b6113c33d"}},"2a49714a8a18417d8d819a13bca8b462":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_13e8a798f3fb41bc951a9f6f12e13fc8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 416M/416M [00:16&lt;00:00, 26.4MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6162a81e5c334cc684c3d33cc648b2de"}},"684cacca80d34e81b594bacd65a82ada":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d3e59f72a0bd43b3a57a353d665072f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b097a2dfda774a37bf6211e377c97186":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"09e8ebf5fc4a49b494f1780b6113c33d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"13e8a798f3fb41bc951a9f6f12e13fc8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6162a81e5c334cc684c3d33cc648b2de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"775f7d119bc5438e9e4811f15f37e7fe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_226d3ed0b19d4d72945c1df5165e0d9d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_98cdcd0b1bc9418c8cc3409818b41669","IPY_MODEL_87e57c448ad94acba0fde5df95b779fd","IPY_MODEL_caa7c1818d2645c3ad67090fa2d09445"]}},"226d3ed0b19d4d72945c1df5165e0d9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"98cdcd0b1bc9418c8cc3409818b41669":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4205856b17c6495882a06302dc7d9981","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: ","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bd962109ce2d4c32a198a90549025c56"}},"87e57c448ad94acba0fde5df95b779fd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9a70d19aa4864d8d916ff5b20b196784","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1248,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1248,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d5cdfe344d7e483eb8cdb6c318bdc1af"}},"caa7c1818d2645c3ad67090fa2d09445":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e3e02e2de51748918b3c7b2b5de545f9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2.64k/? [00:00&lt;00:00, 60.2kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_728d0b5b18184985b2e84367bffad9a1"}},"4205856b17c6495882a06302dc7d9981":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bd962109ce2d4c32a198a90549025c56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9a70d19aa4864d8d916ff5b20b196784":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d5cdfe344d7e483eb8cdb6c318bdc1af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e3e02e2de51748918b3c7b2b5de545f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"728d0b5b18184985b2e84367bffad9a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"984e1febf2d24bd0a7892e065bd66d63":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6bf2c39891e24d3faa8e0b1537cb81a9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5f4c1790959047918a567137462362b3","IPY_MODEL_15a505806c6d4f5589f7d7477d9e7570","IPY_MODEL_8ac2390b65c84226a118902566e1e0a2"]}},"6bf2c39891e24d3faa8e0b1537cb81a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5f4c1790959047918a567137462362b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c873d31d92da4370811be75702364ed0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Skipping the first batches: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a68cbd63ae7b4f64b9219a2ae2674832"}},"15a505806c6d4f5589f7d7477d9e7570":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_895ced84970e420daca4c8bed6f218be","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1520,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1520,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d2d099d47db64f70a50fdc2b4cc0c334"}},"8ac2390b65c84226a118902566e1e0a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2c1d73736601424f8646fca4e099e7f3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1520/1520 [00:08&lt;00:00, 572.47it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0fba7b04119445e283863f8b9dfe1c18"}},"c873d31d92da4370811be75702364ed0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a68cbd63ae7b4f64b9219a2ae2674832":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"895ced84970e420daca4c8bed6f218be":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d2d099d47db64f70a50fdc2b4cc0c334":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2c1d73736601424f8646fca4e099e7f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0fba7b04119445e283863f8b9dfe1c18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3fd406cb781c4531bfeae59f1b2f8460":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0ed49ed0fabc433892cb6e66256b110a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9f2417e77b5c40529814b17863ed7abc","IPY_MODEL_0c34082f5e4440f8a83b57148659ef8e"]}},"0ed49ed0fabc433892cb6e66256b110a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9f2417e77b5c40529814b17863ed7abc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_057582f7457a420d8756a3ba6d057634","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":498,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":498,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dd767d8c985a4576a49fac5b8d9be619"}},"0c34082f5e4440f8a83b57148659ef8e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_08929d7f50684c7c8ada1dfd288038e9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 498/498 [00:02&lt;00:00, 240B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_38ec365837fa4ff0a2be6c8cba2ab4d2"}},"057582f7457a420d8756a3ba6d057634":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"dd767d8c985a4576a49fac5b8d9be619":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"08929d7f50684c7c8ada1dfd288038e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"38ec365837fa4ff0a2be6c8cba2ab4d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7d0bb7a8222c4cdd93ebe7343c255476":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7270e156c2ff4542bd03b3a45226bb57","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_27d0397128774943a646b8e58302a4c0","IPY_MODEL_8d6ab9f9e9f64ec29c325fafb95f606b"]}},"7270e156c2ff4542bd03b3a45226bb57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"27d0397128774943a646b8e58302a4c0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5019419281ac4713bb661ff4d40a7517","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":498627950,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":498627950,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0aaa5b3202324f09a008ba9d56dd9a25"}},"8d6ab9f9e9f64ec29c325fafb95f606b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5b6f621fe077499e8f3d16861ad6d3b8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 499M/499M [00:14&lt;00:00, 33.9MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_486c7fddcdb6442f8196ee95d637ab75"}},"5019419281ac4713bb661ff4d40a7517":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0aaa5b3202324f09a008ba9d56dd9a25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5b6f621fe077499e8f3d16861ad6d3b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"486c7fddcdb6442f8196ee95d637ab75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7e43d9250d9c4fe98cf2194b98c78718":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1a94aa7269f04ec0a6225998be67fe19","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ee9becdbc1304049894383e58d3494af","IPY_MODEL_b74e72c12b5b4616a8442c4cb6c43d66"]}},"1a94aa7269f04ec0a6225998be67fe19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ee9becdbc1304049894383e58d3494af":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4eac87fde4cd41069b79a176f4f0ef2c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":898822,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898822,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_05b4472fa511434d976e4fdfe07f0b0e"}},"b74e72c12b5b4616a8442c4cb6c43d66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6d57a22c25154c0bbe08e30c14b14058","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 899k/899k [00:01&lt;00:00, 890kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_257914342d4d46b18d18ce634df1491e"}},"4eac87fde4cd41069b79a176f4f0ef2c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"05b4472fa511434d976e4fdfe07f0b0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6d57a22c25154c0bbe08e30c14b14058":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"257914342d4d46b18d18ce634df1491e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a68e0782e4a5468db873a756625b19de":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_de2be8b05cce43bfaa77683c05d88601","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a5d2b9fc93804566a996519a9effd1b4","IPY_MODEL_da2b4c1886aa436bb65d7bf84ec83591"]}},"de2be8b05cce43bfaa77683c05d88601":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a5d2b9fc93804566a996519a9effd1b4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5dcbe6b0e6ff4a809bbe5169c26ccc66","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0c8efdfc214a4555b45553902871ca21"}},"da2b4c1886aa436bb65d7bf84ec83591":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_70a386e1270d4cec81a6f8094949f78a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:00&lt;00:00, 746kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_97e7fd5fe96240029d5c945237f2698f"}},"5dcbe6b0e6ff4a809bbe5169c26ccc66":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0c8efdfc214a4555b45553902871ca21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"70a386e1270d4cec81a6f8094949f78a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"97e7fd5fe96240029d5c945237f2698f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9203100138a345008a2f9a8fbf0d2b64":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e1fd4543d8954cf9a39a44e87ff88d51","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0619c1520fef496cbe7c7ff7849f5a3e","IPY_MODEL_cf4a578094e34e49b2aa06645c967a45"]}},"e1fd4543d8954cf9a39a44e87ff88d51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0619c1520fef496cbe7c7ff7849f5a3e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_efc714bbf70346978fc96984d874c14e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":150,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":150,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4043d03dae6340f69a78ca3de9769269"}},"cf4a578094e34e49b2aa06645c967a45":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4f16ea15084949d9ba31135f95e46883","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 150/150 [00:00&lt;00:00, 333B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_63fccdf13da943d5b6465aac5de450c9"}},"efc714bbf70346978fc96984d874c14e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4043d03dae6340f69a78ca3de9769269":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4f16ea15084949d9ba31135f95e46883":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"63fccdf13da943d5b6465aac5de450c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5363e51c14074513a213eee6a32be738":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cc3f26fa8f3f408da359dd9fb8951240","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_42d306f457d342cd9145fa9ac8849bb3","IPY_MODEL_593bba70198e43ff84d417e394fa37ec"]}},"cc3f26fa8f3f408da359dd9fb8951240":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"42d306f457d342cd9145fa9ac8849bb3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4ee0adef37534792857a6d87798d17cb","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":25,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":25,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8eddc5a2839c4b359b7415194dfa7f0f"}},"593bba70198e43ff84d417e394fa37ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_221f4aaf860c4a6fbafd774a348bb227","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 25.0/25.0 [00:00&lt;00:00, 272B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d10fc488334e4677842ef6c6230a8d5a"}},"4ee0adef37534792857a6d87798d17cb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8eddc5a2839c4b359b7415194dfa7f0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"221f4aaf860c4a6fbafd774a348bb227":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d10fc488334e4677842ef6c6230a8d5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"MpxvQ14HFYM1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636949817840,"user_tz":480,"elapsed":23495,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06154810530490924203"}},"outputId":"c4ee0d1e-ae41-4207-8022-53b259dbc851"},"source":["from google.colab import drive\n","drive._mount('/content/drive/')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","metadata":{"id":"jGuiOxBdFh3k"},"source":["#!pip install -q keras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"utYxkMR9F0wq"},"source":["!pip install -q pydrive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OIJwvszjF4AZ"},"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WxE-L4LS3v5I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624902425292,"user_tz":-360,"elapsed":6377,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"e072e213-e04c-42e0-ced5-87181582377d"},"source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Y8N8IE0Z30_Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636949863573,"user_tz":480,"elapsed":25690,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06154810530490924203"}},"outputId":"7e7ed64a-f4f6-4333-e60c-dbdf43dc67ec"},"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla K80\n"]}]},{"cell_type":"code","metadata":{"id":"yAUVCCQ96jsT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636926261550,"user_tz":480,"elapsed":6298,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12040636431562290492"}},"outputId":"2b218661-4d59-4ab6-e84b-28bd26c5156c"},"source":["!nvidia-smi\n","\n","from tensorflow.python.client import device_lib\n","device_lib.list_local_devices()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Nov 14 21:44:17 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   46C    P8    29W / 149W |      3MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]},{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 4166222181018048320\n"," xla_global_id: -1, name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 10843127808\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 15994622152920921938\n"," physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n"," xla_global_id: 416903419]"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"6-PaQ17P36m8","colab":{"base_uri":"https://localhost:8080/","height":904},"executionInfo":{"status":"ok","timestamp":1636949893322,"user_tz":480,"elapsed":29756,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06154810530490924203"}},"outputId":"ce06864e-a895-4ae9-a7d1-2904db4c7001"},"source":["#!pip install transformers\n","!pip install git+https://github.com/huggingface/transformers"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/huggingface/transformers\n","  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-s9t8_iyk\n","  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-s9t8_iyk\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (2019.12.20)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (21.2)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 13.2 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (3.3.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (2.23.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n","\u001b[K     |████████████████████████████████| 59 kB 6.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (1.19.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (4.8.2)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 42.7 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 41.4 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (4.62.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.13.0.dev0) (3.10.0.2)\n","Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.13.0.dev0) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.13.0.dev0) (3.6.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (2021.10.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (7.1.2)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.13.0.dev0-py3-none-any.whl size=3128477 sha256=9c9dfcda48325504b2333fb4cf93b7e9fa312331501689ee7358f71899d0734d\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-6lubfxud/wheels/35/2e/a7/d819e3310040329f0f47e57c9e3e7a7338aa5e74c49acfe522\n","Successfully built transformers\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.13.0.dev0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["yaml"]}}},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"hYNfHEVCUTJM"},"source":["project_path='/content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b7Re8ir-aRg4","executionInfo":{"status":"ok","timestamp":1623930507463,"user_tz":-360,"elapsed":407,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"06154810530490924203"}},"outputId":"5f8c4590-62d5-41ce-b064-66903de9f725"},"source":["#cd '/content/drive/My Drive/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SmZ_NAJRUc7v"},"source":["#cd $project_path"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XutRrfaDUh-p"},"source":["#ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jEvmy_hdVu99"},"source":["import numpy as np\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eak_teqZUmjI"},"source":["def tensorify(lst):\n","    \"\"\"\n","    List must be nested list of tensors (with no varying lengths within a dimension).\n","    Nested list of nested lengths [D1, D2, ... DN] -> tensor([D1, D2, ..., DN)\n","\n","    :return: nested list D\n","    \"\"\"\n","    # base case, if the current list is not nested anymore, make it into tensor\n","    if type(lst[0]) != list:\n","        if type(lst) == torch.Tensor:\n","            return lst\n","        elif type(lst[0]) == torch.Tensor:\n","            return torch.stack(lst, dim=0)\n","        else:  # if the elements of lst are floats or something like that\n","            return torch.tensor(lst)\n","    current_dimension_i = len(lst)\n","    for d_i in range(current_dimension_i):\n","        tensor = tensorify(lst[d_i])\n","        lst[d_i] = tensor\n","    # end of loop lst[d_i] = tensor([D_i, ... D_0])\n","    tensor_lst = torch.stack(lst, dim=0)\n","    return tensor_lst"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KzLahl8DjRbo"},"source":["import torch\n","\n","class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","        self.temp = None\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EZ98pV7F4ctw"},"source":["######## Shuffling Training Dataset for Plausibility Classification ######################\n","#########################################################################\n","\n","import pickle\n","\n","with open(project_path+'Pickles/pickle_shuffled_train_clarification_single_filler_dataset_3.pickle', 'rb') as f:\n","  shuffled_train_dataset = pickle.load(f)\n","  #pickle.dump((test_df['labels'],predictions),f)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T5gyjQ3FjUJd"},"source":["import pickle\n","\n","with open(project_path+'Pickles/pickle_train_clarification_single_filler_dataset_3.pickle', 'rb') as f:\n","  train_dataset = pickle.load(f)\n","  #pickle.dump((test_df['labels'],predictions),f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EeWHCErDz2kz"},"source":["import pickle\n","\n","with open(project_path+'Pickles/pickle_valid_clarification_single_filler_dataset_3.pickle', 'rb') as f:\n","  val_dataset = pickle.load(f)\n","  #pickle.dump((test_df['labels'],predictions),f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ja9xsfbkOUbD"},"source":["'''\n","import pickle\n","\n","with open(project_path+'Pickles/pickle_valid_puzzle_shuffled_1000_dataset_1.pickle', 'rb') as f:\n","  shuffled_val_dataset = pickle.load(f)\n","  #pickle.dump((test_df['labels'],predictions),f)\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QVXCtnSBjW5P"},"source":["import pickle\n","\n","with open(project_path+'Pickles/pickle_valid_small_clarification_single_filler_dataset_3.pickle', 'rb') as f: \n","  val_small_dataset = pickle.load(f)\n","  #pickle.dump((test_df['labels'],predictions),f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KEX_2Di5jZFM"},"source":["\n","import pickle\n","\n","with open(project_path+'Pickles/pickle_test_clarification_single_filler_dataset_3.pickle', 'rb') as f:\n","  test_dataset = pickle.load(f)\n","  #pickle.dump((test_df['labels'],predictions),f)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XTNsqVdCBlzb","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["372e5db7a46b464a9200d8332b93f7df","de15fccdfbd84797a37f685f0ff2bca7","85bfaac7f795418686b7deff5c09d3eb","6416a0893eea4f1bb0c5bb7b4a3c758d","8ee5fff0a9244e8689acc96f9ba31e2c","d1b7cf4b365948bf9ca04887303c9d55","e4b8c8429c624c4c8d4bea08cabad02c","559f2b6a898240f095b491ced12232a5","0d72145305ef435ea89c5bc0e868d190","d188c899084745cb9330cffb9bfdaa6f","b978275ba5474d6598a3eb9fa5293928","55f7ea7504194c329a3ec27d26c17bbb","54119a8bf8f741b9b745aa6acd845e6d","56bfe13e46be4658afba7506b594da3b","5e2c81c54ec6447e902f46ddde315517","61fc0b1739ee406794e4a809f5ba058f","8969f805094749bfbf9e6d67a6babd93","966c84f4074c48ca936eb0d02616076b","1304bbc7d9a140e9b0fdc2d6f7dd0aac","69055c854d6d4085af17930770a16f58","96066254a7ca4cc688db2d39d392d792","3f074ca2961a4d2b8183620974a0e264","4fe543c039254e3cb221101384e7b69b","535486550eaf4c87a7ebdba58e1ac4f5","f0fc69514cbc4ceaaadf7f4f4a804bae","2de38705aa9846929d56577793d57c72","af8a55260ddb4f07b68dfc4b1fd5af99","20f27f6f87824f37a60fcd70c960da94","eae71534c5dd4d568f201d4bddb35c63","5770d12edbac457aa9cd410b7dcd3771","ce13a9966d5b4f949cdef20a04a0b90c","472bc88f9ed547229d77326d67657e7f","bf3d396e27664c5194d56fbde00fa4e4","2fccdf6f15f443d8a7ba3c51ab62c6a9","0f1c5d774e4340a79bbccef023395ccc","bf438886a30043929b9774a62e4946aa","f751435e4ad3405782fe67609ed72129","3bf03e876a3840ef94a425572c979e09","fe7dcfe8eeb44da0ab6e496036eaac46","aa3be8db1a4e49a7bd2417d0c2ff5473","72bc60d51c3b400888a102fc8d6aed86","2494c3f00ee240698922556db073d919","b84746c6718e4c068db5aa55ff4e53d6","d7197e85cc3041cb86bf7b636b7bae3b"]},"executionInfo":{"status":"ok","timestamp":1636949910617,"user_tz":480,"elapsed":8944,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06154810530490924203"}},"outputId":"327e1db3-ea26-4b5f-a961-34155e576487"},"source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-cased') #, skip_special_tokens=True)\n","\n","special_tokens_dict = {'additional_special_tokens': ['[FILLER]','[\\FILLER]']}\n","num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"372e5db7a46b464a9200d8332b93f7df","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"55f7ea7504194c329a3ec27d26c17bbb","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4fe543c039254e3cb221101384e7b69b","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2fccdf6f15f443d8a7ba3c51ab62c6a9","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aETyN_olnOGA","executionInfo":{"status":"ok","timestamp":1636926143781,"user_tz":480,"elapsed":56,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12040636431562290492"}},"outputId":"cef0e310-872b-478c-959c-31af9ba5e69b"},"source":["'''\n","decoder_tokenizer.cls_token = decoder_tokenizer.bos_token\n","decoder_tokenizer.sep_token = decoder_tokenizer.eos_token\n","decoder_tokenizer.pad_token = decoder_tokenizer.eos_token\n","encoder_tokenizer.pad_token = decoder_tokenizer.eos_token\n","'''\n","\n","print(tokenizer.cls_token,tokenizer.sep_token,tokenizer.bos_token,tokenizer.eos_token,tokenizer.pad_token,tokenizer.sep_token_id,tokenizer.pad_token_id)\n","print(tokenizer.special_tokens_map)\n","#print(decoder_tokenizer.cls_token,decoder_tokenizer.sep_token,decoder_tokenizer.bos_token,decoder_tokenizer.eos_token,decoder_tokenizer.pad_token,decoder_tokenizer.sep_token_id,decoder_tokenizer.pad_token_id)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using bos_token, but it is not set yet.\n","Using eos_token, but it is not set yet.\n"]},{"output_type":"stream","name":"stdout","text":["[CLS] [SEP] None None [PAD] 102 0\n","{'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]', 'additional_special_tokens': ['[FILLER]', '[\\\\FILLER]']}\n"]}]},{"cell_type":"code","metadata":{"id":"STcaFc6xJMOR","colab":{"base_uri":"https://localhost:8080/","height":188,"referenced_widgets":["f2eeafd58f884b2d8e028b17dcf89448","3682cb47bb4f44b0bfc855d76f1bdd0d","86e0694b95b947b6b16f935e0ad3ef95","1b43e7d5fa1741879cc304f8cef62a7c","2a49714a8a18417d8d819a13bca8b462","684cacca80d34e81b594bacd65a82ada","d3e59f72a0bd43b3a57a353d665072f8","b097a2dfda774a37bf6211e377c97186","09e8ebf5fc4a49b494f1780b6113c33d","13e8a798f3fb41bc951a9f6f12e13fc8","6162a81e5c334cc684c3d33cc648b2de"]},"executionInfo":{"status":"ok","timestamp":1636611041507,"user_tz":480,"elapsed":21658,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12040636431562290492"}},"outputId":"e35300fb-a712-41d9-f87d-c4cd7c693f7f"},"source":["'''\n","from transformers import AutoModelForSequenceClassification\n","\n","bert_new = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\",num_labels=3)\n","\n","\n","print(bert_new.get_input_embeddings())\n","\n","bert_new.resize_token_embeddings(len(tokenizer))\n","\n","print(bert_new.get_input_embeddings())\n","\n","bert_new.save_pretrained(project_path+'Saved_Models/PLAUSIBILITY_CLASSIFICATION_BERT_1')\n","'''\n","\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f2eeafd58f884b2d8e028b17dcf89448","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Embedding(28996, 768, padding_idx=0)\n","Embedding(28998, 768)\n"]}]},{"cell_type":"code","metadata":{"id":"6HsV4dm8j9qT"},"source":["from transformers import AutoModelForSequenceClassification\n","model = AutoModelForSequenceClassification.from_pretrained(project_path+'Saved_Models/PLAUSIBILITY_CLASSIFICATION_BERT_1',num_labels=3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pMamweLLLhWz","executionInfo":{"status":"ok","timestamp":1636926299160,"user_tz":480,"elapsed":33,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12040636431562290492"}},"outputId":"4f966b0c-0b8c-40c0-8104-6fd7afee89b5"},"source":["#model.config.decoder.add_cross_attention=True\n","#print(model.config.decoder)\n","print(model.get_input_embeddings())\n","print(model.config.pad_token_id)\n","#model.save_pretrained(project_path+'Saved_Models/BertGPT_2_decoder_cross_attention')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Embedding(28998, 768, padding_idx=0)\n","0\n"]}]},{"cell_type":"code","metadata":{"id":"cWzHwcz6BEeo"},"source":["#led_tokenizer = AutoTokenizer.from_pretrained(\"allenai/led-base-16384\")\n","#led_model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/led-base-16384\", gradient_checkpointing=True, use_cache=False,)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":785},"id":"MmYQNbcc44J4","executionInfo":{"status":"ok","timestamp":1636949926715,"user_tz":480,"elapsed":8497,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06154810530490924203"}},"outputId":"b49fc584-0b95-428a-eeba-816cd8f277bb"},"source":["!pip install datasets==1.2.1\n","!pip install rouge_score"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets==1.2.1\n","  Downloading datasets-1.2.1-py3-none-any.whl (159 kB)\n","\u001b[K     |████████████████████████████████| 159 kB 11.0 MB/s \n","\u001b[?25hCollecting tqdm<4.50.0,>=4.27\n","  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n","\u001b[K     |████████████████████████████████| 69 kB 6.8 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (4.8.2)\n","Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (3.0.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (1.19.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (1.1.5)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (2.23.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (0.3.4)\n","Collecting xxhash\n","  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n","\u001b[K     |████████████████████████████████| 243 kB 51.3 MB/s \n","\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (0.70.12.2)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.2.1) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.2.1) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.2.1) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.2.1) (3.0.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==1.2.1) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==1.2.1) (3.10.0.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.2.1) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.2.1) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.2.1) (1.15.0)\n","Installing collected packages: xxhash, tqdm, datasets\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.62.3\n","    Uninstalling tqdm-4.62.3:\n","      Successfully uninstalled tqdm-4.62.3\n","Successfully installed datasets-1.2.1 tqdm-4.49.0 xxhash-2.0.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tqdm"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting rouge_score\n","  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge_score) (0.12.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge_score) (3.2.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.19.5)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.15.0)\n","Installing collected packages: rouge-score\n","Successfully installed rouge-score-0.0.4\n"]}]},{"cell_type":"code","metadata":{"id":"f7M0Ok_QAaHI","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["775f7d119bc5438e9e4811f15f37e7fe","226d3ed0b19d4d72945c1df5165e0d9d","98cdcd0b1bc9418c8cc3409818b41669","87e57c448ad94acba0fde5df95b779fd","caa7c1818d2645c3ad67090fa2d09445","4205856b17c6495882a06302dc7d9981","bd962109ce2d4c32a198a90549025c56","9a70d19aa4864d8d916ff5b20b196784","d5cdfe344d7e483eb8cdb6c318bdc1af","e3e02e2de51748918b3c7b2b5de545f9","728d0b5b18184985b2e84367bffad9a1"]},"executionInfo":{"status":"ok","timestamp":1636949928400,"user_tz":480,"elapsed":1709,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06154810530490924203"}},"outputId":"1920e073-b49c-49f9-9014-1bbd19448f3c"},"source":["#from transformers import logging ################\n","#logging.set_verbosity_info() #####################\n","\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","\n","from datasets import load_dataset, load_metric\n","from transformers import (\n","    Trainer,\n","    TrainingArguments,\n","    AutoTokenizer,\n",")\n","\n","#tokenizer = tokenizer\n","\n","# load rouge\n","metric = load_metric(\"accuracy\")\n","\n","# compute Rouge score during validation\n","def compute_metrics(pred):\n","    logits, labels = pred\n","    predictions = np.argmax(logits, axis=-1)\n","\n","    accuracy = metric.compute(predictions=predictions, references=labels)['accuracy']\n","\n","    micro_f1 = f1_score(labels, predictions, average='micro')\n","    macro_f1 = f1_score(labels, predictions, average='macro')\n","    weighted_f1 = f1_score(labels, predictions, average='weighted')\n","\n","\n","\n","    return {\n","        \"Accuracy\": accuracy,\n","        \"micro_F1\": round(micro_f1, 4),\n","        \"macro_F1\": round(macro_f1, 4),\n","        \"weighted_F1\": round(weighted_f1, 4),\n","    }\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"775f7d119bc5438e9e4811f15f37e7fe","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.25k [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":955},"id":"9RKQPr9zbjFE","executionInfo":{"status":"ok","timestamp":1636949945340,"user_tz":480,"elapsed":16046,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06154810530490924203"}},"outputId":"cdc06aa1-55b5-454b-e5d9-8171e7978a91"},"source":["!pip install wandb\n","\n","import wandb\n","wandb.login()\n","\n","%env WANDB_PROJECT=Plausibility_Clarification_Bert_Training_3_2"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wandb\n","  Downloading wandb-0.12.6-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 13.7 MB/s \n","\u001b[?25hCollecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n","\u001b[K     |████████████████████████████████| 180 kB 49.0 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Collecting subprocess32>=3.5.3\n","  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 6.3 MB/s \n","\u001b[?25hCollecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.4.3-py2.py3-none-any.whl (139 kB)\n","\u001b[K     |████████████████████████████████| 139 kB 48.0 MB/s \n","\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Collecting configparser>=3.8.1\n","  Downloading configparser-5.1.0-py3-none-any.whl (19 kB)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Collecting yaspin>=1.0.0\n","  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n","Building wheels for collected packages: subprocess32, pathtools\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=6eefca4d714009f9402d1a2a1548eafaa64651fb256c1a79615f98d12acaa277\n","  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=809588e165bd2112ba342ba3f2f03a2396e000b3ec0e8121c93e450884b6531f\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built subprocess32 pathtools\n","Installing collected packages: smmap, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n","Successfully installed GitPython-3.1.24 configparser-5.1.0 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.4.3 shortuuid-1.0.8 smmap-5.0.0 subprocess32-3.5.4 wandb-0.12.6 yaspin-2.1.0\n"]},{"output_type":"display_data","data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"stream","name":"stdout","text":["env: WANDB_PROJECT=Plausibility_Clarification_Bert_Training_3_2\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CIJMsTjAQhMG","executionInfo":{"status":"ok","timestamp":1636949946396,"user_tz":480,"elapsed":1082,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06154810530490924203"}},"outputId":"a61161e1-1f0b-462a-86f8-785739da0800"},"source":["class_dic = {}\n","for i in range(3):\n","  class_dic[i]=0\n","\n","for i in range(len(train_dataset)):\n","  class_dic[int(train_dataset[i]['labels'])] += 1\n","\n","class_dic"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: 4950, 1: 6441, 2: 6569}"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BOUfARTdW_45","executionInfo":{"status":"ok","timestamp":1636925468404,"user_tz":480,"elapsed":825,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12040636431562290492"}},"outputId":"2c806c4c-aac4-494b-bf0a-8d0f9375466c"},"source":["print(max(class_dic.values()))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["6569\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wF6Ix7kZXKYh","executionInfo":{"status":"ok","timestamp":1636949966397,"user_tz":480,"elapsed":20005,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06154810530490924203"}},"outputId":"1fe3122b-3a51-4cdf-b853-09890fbb9c59"},"source":["class_weights = []\n","\n","max_class = max(class_dic.values())\n","\n","for i in range(3):\n","  class_weights.append(max_class/class_dic[i])\n","\n","print(class_weights)\n","class_weights = torch.FloatTensor(class_weights).to(device)\n","print(class_weights)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1.327070707070707, 1.0198726905759976, 1.0]\n","tensor([1.3271, 1.0199, 1.0000], device='cuda:0')\n"]}]},{"cell_type":"code","metadata":{"id":"Xcq6r1AHX1y6"},"source":["from torch import nn\n","from transformers import Trainer\n","\n","class MultiClassTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        labels = inputs.get(\"labels\")\n","        outputs = model(**inputs)\n","        logits = outputs.get('logits')\n","        loss_fct = nn.CrossEntropyLoss(weight = class_weights)\n","        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n","        return (loss, outputs) if return_outputs else loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z3u4_AvV5ysj"},"source":["batch_size = 8 ####################\n","\n","\n","\n","training_args = TrainingArguments(\n","    evaluation_strategy=\"steps\",\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    #fp16=True,\n","    #fp16_backend=\"apex\",\n","    output_dir=project_path+'Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/',\n","    logging_dir = project_path+'Saved_Logs/Training_1/Plausibility_Classification_Bert_3_2/',\n","    num_train_epochs = 20,  ##########################################################\n","    logging_steps=10, #250,\n","    eval_steps=50,  # 200, #5000,\n","    save_steps=50, #200, #500,\n","    warmup_steps=1, #1500,\n","    #save_total_limit=2,\n","    gradient_accumulation_steps=8, ############################################################\n","    load_best_model_at_end = False,\n","    #resume_from_checkpoint = project_path+'Saved_Models/Training_1/checkpoint-1500',\n","    report_to=\"wandb\",  # enable logging to W&B\n","    run_name=\"plausibility-classification-Bert-3-2-run-2\",  # name of the W&B run (optional)\n",")\n","\n","\n","# BEST TO ME by Accuracy project_path+'Saved_Logs/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-450"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KAwT_NCXG03r","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["984e1febf2d24bd0a7892e065bd66d63","6bf2c39891e24d3faa8e0b1537cb81a9","5f4c1790959047918a567137462362b3","15a505806c6d4f5589f7d7477d9e7570","8ac2390b65c84226a118902566e1e0a2","c873d31d92da4370811be75702364ed0","a68cbd63ae7b4f64b9219a2ae2674832","895ced84970e420daca4c8bed6f218be","d2d099d47db64f70a50fdc2b4cc0c334","2c1d73736601424f8646fca4e099e7f3","0fba7b04119445e283863f8b9dfe1c18"]},"outputId":"10f25195-7bf3-46e6-fdc6-88e0b15abb6b"},"source":["# instantiate trainer BATCH SIZE = 8 ############\n","trainer = MultiClassTrainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    #data_collator=data_collator,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    train_dataset= train_dataset,  #shuffled_train_dataset,  ########################################\n","    eval_dataset=test_dataset,  # val_dataset, \n",")\n","\n","# start training\n","#trainer.train()\n","trainer.train(project_path+'Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-750')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Loading model from /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-750).\n","***** Running training *****\n","  Num examples = 17960\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 8\n","  Total optimization steps = 5600\n","  Continuing training from checkpoint, will skip to saved global_step\n","  Continuing training from epoch 2\n","  Continuing training from global step 750\n","  Will skip the first 2 epochs then the first 1520 batches in the first epoch. If this takes a lot of time, you can add the `--ignore_data_skip` flag to your launch command, but you will resume the training on data already seen by your model.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"984e1febf2d24bd0a7892e065bd66d63","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1520 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtawkat\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_Bert_Training_3_2/runs/2cwf88ux\" target=\"_blank\">plausibility-classification-Bert-3-2-run-2</a></strong> to <a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_Bert_Training_3_2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1601' max='5600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1601/5600 3:35:13 < 16:53:47, 0.07 it/s, Epoch 5.71/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Micro F1</th>\n","      <th>Macro F1</th>\n","      <th>Weighted F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>800</td>\n","      <td>0.938000</td>\n","      <td>1.196234</td>\n","      <td>0.421200</td>\n","      <td>0.421200</td>\n","      <td>0.392800</td>\n","      <td>0.438800</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.778900</td>\n","      <td>1.288778</td>\n","      <td>0.421600</td>\n","      <td>0.421600</td>\n","      <td>0.401100</td>\n","      <td>0.442100</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.745600</td>\n","      <td>1.268582</td>\n","      <td>0.440800</td>\n","      <td>0.440800</td>\n","      <td>0.408500</td>\n","      <td>0.452600</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.717200</td>\n","      <td>1.401210</td>\n","      <td>0.443600</td>\n","      <td>0.443600</td>\n","      <td>0.396300</td>\n","      <td>0.446600</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.713300</td>\n","      <td>1.385923</td>\n","      <td>0.435200</td>\n","      <td>0.435200</td>\n","      <td>0.410900</td>\n","      <td>0.457800</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.773200</td>\n","      <td>1.414440</td>\n","      <td>0.412800</td>\n","      <td>0.412800</td>\n","      <td>0.390200</td>\n","      <td>0.430300</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.701500</td>\n","      <td>1.298336</td>\n","      <td>0.411200</td>\n","      <td>0.411200</td>\n","      <td>0.403700</td>\n","      <td>0.441000</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.499500</td>\n","      <td>1.785569</td>\n","      <td>0.373600</td>\n","      <td>0.373600</td>\n","      <td>0.372300</td>\n","      <td>0.399700</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.477400</td>\n","      <td>1.835930</td>\n","      <td>0.386400</td>\n","      <td>0.386400</td>\n","      <td>0.386500</td>\n","      <td>0.415000</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.560600</td>\n","      <td>1.686799</td>\n","      <td>0.396000</td>\n","      <td>0.396000</td>\n","      <td>0.386300</td>\n","      <td>0.418300</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.551500</td>\n","      <td>1.717747</td>\n","      <td>0.416800</td>\n","      <td>0.416800</td>\n","      <td>0.390600</td>\n","      <td>0.430700</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.531500</td>\n","      <td>1.636152</td>\n","      <td>0.406000</td>\n","      <td>0.406000</td>\n","      <td>0.394300</td>\n","      <td>0.433300</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.531800</td>\n","      <td>1.595624</td>\n","      <td>0.418800</td>\n","      <td>0.418800</td>\n","      <td>0.397100</td>\n","      <td>0.433500</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.283600</td>\n","      <td>2.126591</td>\n","      <td>0.394800</td>\n","      <td>0.394800</td>\n","      <td>0.382400</td>\n","      <td>0.415900</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.315400</td>\n","      <td>1.996134</td>\n","      <td>0.420400</td>\n","      <td>0.420400</td>\n","      <td>0.401600</td>\n","      <td>0.441900</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.356300</td>\n","      <td>2.080099</td>\n","      <td>0.408800</td>\n","      <td>0.408800</td>\n","      <td>0.400900</td>\n","      <td>0.436000</td>\n","    </tr>\n","  </tbody>\n","</table><p>\n","    <div>\n","      \n","      <progress value='233' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [233/313 02:10 < 00:45, 1.77 it/s]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-800\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-800/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-800/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-800/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-800/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-850\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-850/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-850/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-850/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-850/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-900\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-900/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-900/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-900/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-900/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-950\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-950/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-950/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-950/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-950/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1000\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1000/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1050\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1050/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1050/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1050/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1050/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1100\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1100/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1100/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1100/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1100/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1150\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1150/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1150/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1150/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1150/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1200\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1200/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1200/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1200/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1200/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1250\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1250/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1250/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1250/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1250/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1300\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1300/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1300/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1300/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1300/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1350\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1350/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1350/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1350/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1350/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1400\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1400/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1400/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1400/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1400/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1450\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1450/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1450/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1450/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1450/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1500\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1500/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1550\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1550/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1550/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1550/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-1550/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"8gNFJiB-grF6","outputId":"44b6de29-b74f-4ce2-c598-e27d7fd3f403"},"source":["# instantiate trainer BATCH SIZE = 8 ############\n","trainer = MultiClassTrainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    #data_collator=data_collator,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    train_dataset= train_dataset,  #shuffled_train_dataset,  ########################################\n","    eval_dataset=test_dataset,  # val_dataset, \n",")\n","\n","# start training\n","trainer.train()\n","#trainer.train(project_path+'Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-900')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running training *****\n","  Num examples = 17960\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 8\n","  Total optimization steps = 5600\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"]},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_Bert_Training_3_2/runs/2y8haluv\" target=\"_blank\">plausibility-classification-Bert-3-2-run-2</a></strong> to <a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_Bert_Training_3_2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='787' max='5600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 787/5600 3:04:35 < 18:51:47, 0.07 it/s, Epoch 2.81/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Micro F1</th>\n","      <th>Macro F1</th>\n","      <th>Weighted F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>1.099400</td>\n","      <td>1.135188</td>\n","      <td>0.348400</td>\n","      <td>0.348400</td>\n","      <td>0.276000</td>\n","      <td>0.301600</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.084200</td>\n","      <td>1.074268</td>\n","      <td>0.420400</td>\n","      <td>0.420400</td>\n","      <td>0.362500</td>\n","      <td>0.418300</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>1.116300</td>\n","      <td>1.067504</td>\n","      <td>0.481200</td>\n","      <td>0.481200</td>\n","      <td>0.316400</td>\n","      <td>0.397200</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.087600</td>\n","      <td>1.108826</td>\n","      <td>0.366000</td>\n","      <td>0.366000</td>\n","      <td>0.358300</td>\n","      <td>0.390500</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>1.084400</td>\n","      <td>1.090485</td>\n","      <td>0.377200</td>\n","      <td>0.377200</td>\n","      <td>0.374000</td>\n","      <td>0.407000</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.008400</td>\n","      <td>1.088289</td>\n","      <td>0.439200</td>\n","      <td>0.439200</td>\n","      <td>0.401100</td>\n","      <td>0.453900</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>1.008800</td>\n","      <td>1.092953</td>\n","      <td>0.470000</td>\n","      <td>0.470000</td>\n","      <td>0.389500</td>\n","      <td>0.456500</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.052900</td>\n","      <td>1.114945</td>\n","      <td>0.407200</td>\n","      <td>0.407200</td>\n","      <td>0.389600</td>\n","      <td>0.428100</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>1.037200</td>\n","      <td>1.046952</td>\n","      <td>0.510800</td>\n","      <td>0.510800</td>\n","      <td>0.387400</td>\n","      <td>0.468600</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>1.058600</td>\n","      <td>1.083083</td>\n","      <td>0.488400</td>\n","      <td>0.488400</td>\n","      <td>0.347500</td>\n","      <td>0.422900</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>1.045000</td>\n","      <td>1.058307</td>\n","      <td>0.494400</td>\n","      <td>0.494400</td>\n","      <td>0.381800</td>\n","      <td>0.457600</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.885900</td>\n","      <td>1.193976</td>\n","      <td>0.484400</td>\n","      <td>0.484400</td>\n","      <td>0.419600</td>\n","      <td>0.477700</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.911000</td>\n","      <td>1.128386</td>\n","      <td>0.392000</td>\n","      <td>0.392000</td>\n","      <td>0.386800</td>\n","      <td>0.421700</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.921000</td>\n","      <td>1.164315</td>\n","      <td>0.425200</td>\n","      <td>0.425200</td>\n","      <td>0.412300</td>\n","      <td>0.450700</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.945000</td>\n","      <td>1.076002</td>\n","      <td>0.481600</td>\n","      <td>0.481600</td>\n","      <td>0.431800</td>\n","      <td>0.487300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-50\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-50/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-50/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-50/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-50/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-100\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-100/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-100/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-100/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-100/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-150\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-150/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-150/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-150/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-150/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-200\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-200/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-200/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-200/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-200/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-250\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-250/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-250/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-250/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-250/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-300\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-300/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-300/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-300/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-300/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-350\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-350/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-350/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-350/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-350/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-400\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-400/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-400/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-400/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-400/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-450\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-450/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-450/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-450/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-450/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-500\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-500/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-550\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-550/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-550/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-550/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-550/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-600\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-600/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-600/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-600/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-600/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-650\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-650/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-650/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-650/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-650/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-700\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-700/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-700/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-700/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-700/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-750\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-750/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-750/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-750/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3_2/checkpoint-750/special_tokens_map.json\n"]}]},{"cell_type":"code","metadata":{"id":"KmmTpD9BjNXM","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"45051793-efff-4d5f-8f19-a42cccde88af"},"source":["# instantiate trainer BATCH SIZE = 8 ############\n","trainer = Trainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    #data_collator=data_collator,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    train_dataset= train_dataset,  #shuffled_train_dataset,  ########################################\n","    eval_dataset=test_dataset,  # val_dataset, \n",")\n","\n","# start training\n","trainer.train()\n","#trainer.train(project_path+'Saved_Logs/Training_1/Plausibility_Classification_Bert_2/checkpoint-900')"],"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 17960\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 8\n","  Total optimization steps = 5600\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtawkat\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_Bert_Training_3/runs/khrsj6wx\" target=\"_blank\">plausibility-classification-Bert-3-run-2</a></strong> to <a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_Bert_Training_3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='101' max='5600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 101/5600 21:01 < 19:27:25, 0.08 it/s, Epoch 0.36/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Micro F1</th>\n","      <th>Macro F1</th>\n","      <th>Weighted F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>1.091200</td>\n","      <td>1.143194</td>\n","      <td>0.417600</td>\n","      <td>0.234000</td>\n","      <td>0.234000</td>\n","      <td>0.277800</td>\n","    </tr>\n","  </tbody>\n","</table><p>\n","    <div>\n","      \n","      <progress value='269' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [269/313 02:20 < 00:23, 1.91 it/s]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-50\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-50/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-50/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-50/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-50/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='950' max='5600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 950/5600 3:45:23 < 18:25:33, 0.07 it/s, Epoch 3.39/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Micro F1</th>\n","      <th>Macro F1</th>\n","      <th>Weighted F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>1.091200</td>\n","      <td>1.143194</td>\n","      <td>0.417600</td>\n","      <td>0.234000</td>\n","      <td>0.234000</td>\n","      <td>0.277800</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.093200</td>\n","      <td>1.098558</td>\n","      <td>0.384800</td>\n","      <td>0.286900</td>\n","      <td>0.286900</td>\n","      <td>0.328600</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>1.113500</td>\n","      <td>1.062129</td>\n","      <td>0.464800</td>\n","      <td>0.279300</td>\n","      <td>0.279300</td>\n","      <td>0.353900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.081100</td>\n","      <td>1.090249</td>\n","      <td>0.436000</td>\n","      <td>0.393000</td>\n","      <td>0.393000</td>\n","      <td>0.446300</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>1.072300</td>\n","      <td>1.093444</td>\n","      <td>0.392400</td>\n","      <td>0.367300</td>\n","      <td>0.367300</td>\n","      <td>0.405600</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.024900</td>\n","      <td>1.125634</td>\n","      <td>0.456400</td>\n","      <td>0.389300</td>\n","      <td>0.389300</td>\n","      <td>0.446000</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>1.017700</td>\n","      <td>1.118906</td>\n","      <td>0.415600</td>\n","      <td>0.373300</td>\n","      <td>0.373300</td>\n","      <td>0.420800</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.054500</td>\n","      <td>1.108778</td>\n","      <td>0.396000</td>\n","      <td>0.362900</td>\n","      <td>0.362900</td>\n","      <td>0.398400</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>1.033900</td>\n","      <td>1.062676</td>\n","      <td>0.448800</td>\n","      <td>0.405500</td>\n","      <td>0.405500</td>\n","      <td>0.457100</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>1.049400</td>\n","      <td>1.060683</td>\n","      <td>0.501600</td>\n","      <td>0.380800</td>\n","      <td>0.380800</td>\n","      <td>0.453200</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>1.051900</td>\n","      <td>1.069072</td>\n","      <td>0.455600</td>\n","      <td>0.384600</td>\n","      <td>0.384600</td>\n","      <td>0.448600</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.918200</td>\n","      <td>1.146343</td>\n","      <td>0.475200</td>\n","      <td>0.377700</td>\n","      <td>0.377700</td>\n","      <td>0.440500</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.946800</td>\n","      <td>1.109124</td>\n","      <td>0.430800</td>\n","      <td>0.403100</td>\n","      <td>0.403100</td>\n","      <td>0.449300</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.951000</td>\n","      <td>1.148365</td>\n","      <td>0.443200</td>\n","      <td>0.416600</td>\n","      <td>0.416600</td>\n","      <td>0.462700</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.963700</td>\n","      <td>1.081059</td>\n","      <td>0.485200</td>\n","      <td>0.435500</td>\n","      <td>0.435500</td>\n","      <td>0.493100</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.940100</td>\n","      <td>1.152081</td>\n","      <td>0.422000</td>\n","      <td>0.382600</td>\n","      <td>0.382600</td>\n","      <td>0.426400</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.814300</td>\n","      <td>1.202284</td>\n","      <td>0.462000</td>\n","      <td>0.413300</td>\n","      <td>0.413300</td>\n","      <td>0.466400</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.749700</td>\n","      <td>1.284986</td>\n","      <td>0.438000</td>\n","      <td>0.410500</td>\n","      <td>0.410500</td>\n","      <td>0.449900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-100\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-100/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-100/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-100/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-100/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-150\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-150/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-150/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-150/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-150/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-200\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-200/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-200/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-200/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-200/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-250\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-250/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-250/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-250/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-250/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-300\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-300/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-300/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-300/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-300/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-350\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-350/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-350/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-350/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-350/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-400\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-400/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-400/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-400/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-400/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-450\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-450/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-450/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-450/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-450/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-500\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-500/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-550\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-550/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-550/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-550/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-550/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-600\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-600/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-600/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-600/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-600/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-650\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-650/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-650/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-650/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-650/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-700\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-700/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-700/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-700/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-700/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-750\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-750/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-750/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-750/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-750/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-800\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-800/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-800/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-800/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-800/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-850\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-850/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-850/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-850/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-850/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-900\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-900/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-900/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-900/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-900/special_tokens_map.json\n"]}]},{"cell_type":"markdown","metadata":{"id":"FMkR5GX8qEIB"},"source":["# **Testing**"]},{"cell_type":"code","metadata":{"id":"lSJ7XnOTwP2g"},"source":["class_names = [\"IMPLAUSIBLE\", \"NEUTRAL\", \"PLAUSIBLE\"]\n","\n","LABEL_DICT = {}\n","LABEL_DICT[class_names[0]] = 0\n","LABEL_DICT[class_names[1]] = 1\n","LABEL_DICT[class_names[2]] = 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"to0VNWg5GMti","executionInfo":{"status":"ok","timestamp":1625751778126,"user_tz":-360,"elapsed":429,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"a2ccccfd-25e1-4629-c1be-44f3fcd424c2"},"source":["print(tokenizer.batch_decode(train_dataset[499:500]['input_ids']))\n","\n","labels_ids = train_dataset[499:500]['labels']#[test_dataset[499:500]['labels'] == -100] = tokenizer.pad_token_id\n","labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n","#print(labels_ids)\n","output = tokenizer.batch_decode(labels_ids, skip_special_tokens=False)\n","print(output[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[\"solve: def sat(x: List[int], a: int=-165, r: int=1, l: int=42): assert type(x) is list and all(type(a) is int for a in x), 'x must be of type List[int]' return x[0] == a and len(x) == l and all([x[i] * r == x[i + 1] for i in range(len(x) - 1)])</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\"]\n","sol(a=-165, r=1, l=42): return [a * r ** i for i in range(l)]</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AUCrq4edW5j3","executionInfo":{"status":"ok","timestamp":1625751805282,"user_tz":-360,"elapsed":452,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"a2743cbd-eb9a-4148-af60-5bbae0b62f74"},"source":["print(tokenizer.special_tokens_map)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': \"['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']\"}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PBIhqWDJPT_v"},"source":["from transformers import AutoModelForSequenceClassification\n","model = AutoModelForSequenceClassification.from_pretrained(project_path+'Saved_Models/Training_1/Plausibility_Classification_Bert_3/checkpoint-900',num_labels=3)\n","model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lEekCQDmPU_V"},"source":["start = 200\n","end = 210\n","model.eval()\n","outputs = model(input_ids=test_dataset[start:end]['input_ids'].to(device),attention_mask=test_dataset[start:end]['attention_mask'].to(device))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9WDuXv11PYA-","executionInfo":{"status":"ok","timestamp":1636923665261,"user_tz":480,"elapsed":1017,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12040636431562290492"}},"outputId":"066def30-a1d8-4f89-b0a7-1e3f34155264"},"source":["print(np.argmax(outputs.logits.detach().cpu().numpy(),axis=1))\n","print(test_dataset[start:end]['labels'])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2 2 2 2 2 1 2 1 1 2]\n","tensor([0, 0, 1, 2, 1, 0, 1, 0, 0, 2])\n"]}]},{"cell_type":"code","metadata":{"id":"BinEuSh8YNuf"},"source":["accuracy = Accuracy(actual_str,output_str)\n","sommth_bleu_score = round(_bleu(actual_str, output_str),2)\n","\n","print(accuracy)\n","print(sommth_bleu_score)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JTPCopoGZzTd"},"source":["total_output_str=[]\n","batch_size = 100\n","\n","curr = 0\n","for i in range(0,len(test_dataset),batch_size):\n","  end = min(i+batch_size,len(test_dataset))\n","  code_tokens = ed.generate(input_ids=test_dataset[i:end]['input_ids'].to(device),attention_mask=test_dataset[i:end]['attention_mask'].to(device))\n","  \n","  codes = decoder_tokenizer.batch_decode(code_tokens,skip_special_tokens=True)\n","\n","  for c in codes:\n","    total_output_str.append(c)\n","  print(i)\n","  if(end == len(test_dataset)):\n","    break\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RwXy5K__TnQ1","executionInfo":{"status":"ok","timestamp":1624463170470,"user_tz":-360,"elapsed":12,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"b288768f-b9c7-4541-8ad5-17bf675fd7cd"},"source":["print(len(total_output_str))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["6545\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XnxauUisXJ14"},"source":["class Example(object):\n","    \"\"\"A single training/test example.\"\"\"\n","    def __init__(self,\n","                 idx,\n","                 source,\n","                 target,\n","                 ):\n","        self.idx = idx\n","        self.source = source\n","        self.target = target"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r1haZjJ8Xe8E"},"source":["import pickle\n","with open(project_path+'Pickles/pickle_test_buggy_fixed_1.pickle', 'rb') as f:\n","  test_examples = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K5vm5E9gXgfR","executionInfo":{"status":"ok","timestamp":1624463170958,"user_tz":-360,"elapsed":15,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"296d3f96-a55a-463f-b3fe-41be9de8f284"},"source":["total_actual_str=[]\n","\n","for te in test_examples:\n","  total_actual_str.append(te.target)\n","\n","print(len(total_actual_str))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["6545\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bFQg6nPQnmKh"},"source":["import pickle\n","with open(project_path+'Pickles/pickle_pred_test_buggy_fixed_13000_1.pickle', 'wb') as f:\n","  pickle.dump((total_actual_str,total_output_str),f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D6m6Eu4uoEUl"},"source":["import pickle\n","with open(project_path+'Pickles/pickle_pred_test_buggy_fixed_13000_1.pickle', 'rb') as f:\n","  total_actual_str,total_output_str = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bDwUATPdX0JK","executionInfo":{"status":"ok","timestamp":1624464471028,"user_tz":-360,"elapsed":414,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"a8eca143-6574-43a2-db93-e0e02885563d"},"source":["print(total_actual_str[100])\n","print(total_output_str[100])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["public void METHOD_1 ( ) { TYPE_1 query = new TYPE_1 ( ) ; TYPE_2 VAR_1 = TYPE_3 . METHOD_2 ( VAR_2 class ) ; TYPE_3 . METHOD_3 ( VAR_1 . getId ( ) ) . METHOD_4 ( 1 ) ; TYPE_3 . METHOD_5 ( VAR_1 ) ; java.lang.Long count = VAR_3 . METHOD_6 ( VAR_1 , query ) ; TYPE_4 . assertEquals ( INT_2 , count . METHOD_7 ( ) ) ; }\n","public void METHOD_1 ( ) { TYPE_1 query = new TYPE_1 ( ) ; TYPE_2 VAR_1 = TYPE_3. METHOD_2 ( VAR_2 class ) ; TYPE_3. METHOD_3 ( VAR_1. getId ( ) ). METHOD_4 ( INT_1 ) ; TYPE_3. METHOD_5 ( VAR_1 ) ; java.lang.Long count = VAR_3. METHOD_6 ( VAR_1, query ) ; TYPE_4. assertEquals ( INT_2, count. METHOD_7 ( ) ) ; }\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KUFMXJPrxaqs","executionInfo":{"status":"ok","timestamp":1624464289031,"user_tz":-360,"elapsed":3404,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"5283b33f-8801-4c03-92a2-3489af3fa4de"},"source":["accuracy = Accuracy(total_actual_str,total_output_str)\n","sommth_bleu_score = round(_bleu(total_actual_str, total_output_str),2)\n","\n","print(accuracy)\n","print(sommth_bleu_score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[['public', 'java.lang.String', 'METHOD_1', '(', ')', '{', 'if', '(', '(', 'METHOD_2', '(', ')', ')', '&&', '(', 'METHOD_3', '(', 'VAR_1', '.', 'METHOD_4', '(', ')', ')', ')', ')', '{', 'return', 'VAR_1', '.', 'METHOD_4', '(', ')', ';', '}', 'else', 'if', '(', 'METHOD_3', '(', 'VAR_3', '.', 'METHOD_5', '(', ')', '.', 'METHOD_6', '(', ')', ')', ')', '{', 'return', 'VAR_3', '.', 'METHOD_5', '(', ')', '.', 'METHOD_6', '(', ')', ';', '}', 'else', '{', 'return', 'VAR_4', '.', 'METHOD_4', '(', ')', ';', '}', '}'], ['private', 'void', 'METHOD_1', '(', 'TYPE_1', 'index', ',', 'java.util.Collection', '<', 'TYPE_2', '>', 'VAR_1', ')', '{', 'TYPE_1', 'VAR_2', '=', 'index', '.', 'METHOD_2', '(', 'VAR_3', ')', ';', 'for', '(', 'TYPE_3', '<', 'TYPE_2', '>', 'VAR_4', ':', 'this', '.', 'VAR_1', '.', 'values', '(', ')', ')', '{', 'VAR_4', '.', 'METHOD_3', '(', 'VAR_2', ',', 'null', ')', ';', '}', 'METHOD_4', '(', 'index', ',', 'VAR_1', ')', ';', '}'], ['public', 'void', 'remove', '(', 'int', 'id', ')', '{', 'try', '{', 'java.lang.String', 'query', '=', 'STRING_1', ';', 'TYPE_1', 'VAR_1', '=', 'METHOD_1', '(', ')', ';', 'TYPE_2', 'VAR_2', '=', 'VAR_1', '.', 'METHOD_2', '(', 'query', ')', ';', 'VAR_2', '.', 'METHOD_3', '(', '1', ',', 'id', ')', ';', 'VAR_2', '.', 'METHOD_4', '(', ')', ';', '}', 'catch', '(', 'TYPE_3', 'VAR_3', ')', '{', 'java.lang.System.out.println', '(', 'STRING_2', ')', ';', '}', '}'], ['private', 'java.util.List', '<', 'TYPE_1', '>', 'METHOD_1', '(', ')', '{', 'java.util.List', '<', 'TYPE_1', '>', 'VAR_2', '=', 'new', 'java.util.ArrayList', '<', '>', '(', ')', ';', 'for', '(', 'int', 'i', '=', '0', ';', 'i', '<', '(', 'VAR_3', '.', 'size', '(', ')', ')', ';', 'i', '++', ')', '{', 'TYPE_1', 'VAR_1', '=', 'new', 'TYPE_1', '(', ')', ';', 'VAR_1', '.', 'METHOD_2', '(', 'VAR_3', '.', 'get', '(', 'i', ')', '.', 'METHOD_3', '(', ')', ')', ';', 'VAR_2', '.', 'add', '(', 'VAR_1', ')', ';', '}', 'return', 'VAR_2', ';', '}'], ['private', 'void', 'METHOD_1', '(', 'java.util.List', '<', 'TYPE_1', '>', 'parameters', ',', 'TYPE_2', 'VAR_1', ')', '{', 'while', '(', 'VAR_1', '.', 'METHOD_2', '(', ')', ')', '{', 'TYPE_3', 'VAR_2', '=', 'METHOD_3', '(', 'VAR_1', ')', ';', 'if', '(', 'VAR_2', '==', 'null', ')', '{', 'break', ';', '}', 'if', '(', 'VAR_2', '.', 'METHOD_4', '(', ')', ')', '{', 'METHOD_6', '(', 'parameters', ',', 'METHOD_7', '(', 'VAR_2', ')', ')', ';', '}', 'VAR_1', '=', '(', '(', 'TYPE_2', ')', '(', 'VAR_2', '.', 'METHOD_8', '(', ')', ')', ')', ';', '}', '}']]\n","[['public', 'java.lang.String', 'METHOD_1', '(', ')', '{', 'if', '(', '(', 'METHOD_2', '(', ')', ')', '&&', '(', 'METHOD_3', '(', 'VAR_1.', 'METHOD_4', '(', ')', ')', ')', ')', '{', 'return', 'VAR_2.', 'METHOD_4', '(', ')', ';', '}', 'else', 'if', '(', 'METHOD_3', '(', 'VAR_3.', 'METHOD_5', '(', ').', 'METHOD_6', '(', ')', ')', ')', '{', 'return', 'VAR_3.', 'METHOD_5', '(', ').', 'METHOD_6', '(', ')', ';', '}', 'else', '{', 'return', 'VAR_4.', 'METHOD_4', '(', ')', ';', '}', '}'], ['private', 'void', 'METHOD_1', '(', 'TYPE_1', 'index,', 'java.util.Collection', '<', 'TYPE_2', '>', 'VAR_1', ')', '{', 'TYPE_1', 'VAR_2', '=', 'index.', 'METHOD_2', '(', 'VAR_3', ')', ';', 'for', '(', 'TYPE_3', '<', 'TYPE_2', '>', 'VAR_4', ':', 'this.', 'VAR_1.', 'values', '(', ')', ')', '{', 'VAR_4.', 'METHOD_3', '(', 'VAR_2,', 'null', ')', ';', '}', 'METHOD_4', '(', 'VAR_2,', 'VAR_1', ')', ';', '}'], ['public', 'void', 'remove', '(', 'int', 'id', ')', '{', 'try', '{', 'java.lang.String', 'query', '=', 'STRING_1', ';', 'TYPE_1', 'VAR_1', '=', 'METHOD_1', '(', ')', ';', 'TYPE_2', 'VAR_2', '=', 'VAR_1.', 'METHOD_2', '(', 'query', ')', ';', 'VAR_2.', 'METHOD_3', '(', '1,', 'id', ')', ';', 'VAR_2.', 'METHOD_4', '(', ')', ';', '}', 'catch', '(', 'TYPE_3', 'VAR_3', ')', '{', 'VAR_3.', 'METHOD_5', '(', ')', ';', 'java.lang.System.out.println', '(', 'STRING_2', ')', ';', '}', '}'], ['private', 'java.util.List', '<', 'TYPE_1', '>', 'METHOD_1', '(', ')', '{', 'TYPE_1', 'VAR_1', '=', 'new', 'TYPE_1', '(', ')', ';', 'java.util.List', '<', 'TYPE_1', '>', 'VAR_2', '=', 'new', 'java.util.ArrayList', '<', '>', '(', ')', ';', 'for', '(', 'int', 'i', '=', '0', ';', 'i', '<', '(', 'VAR_3.', 'size', '(', ')', ')', ';', 'i', '++', ')', '{', 'VAR_1.', 'METHOD_2', '(', 'VAR_3.', 'get', '(', 'i', ').', 'METHOD_3', '(', ')', ')', ';', 'VAR_2.', 'add', '(', 'VAR_1', ')', ';', '}', 'return', 'VAR_2', ';', '}'], ['private', 'void', 'METHOD_1', '(', 'java.util.List', '<', 'TYPE_1', '>', 'parameters,', 'TYPE_2', 'VAR_1', ')', '{', 'while', '(', 'VAR_1.', 'METHOD_2', '(', ')', ')', '{', 'TYPE_3', 'VAR_2', '=', 'METHOD_3', '(', 'VAR_1', ')', ';', 'if', '(', 'VAR_2', '==', 'null', ')', '{', 'break', ';', '}', 'if', '(', 'TYPE_4.', 'METHOD_4', '(', 'VAR_2.', 'METHOD_5', '(', ')', ')', ')', '{', 'METHOD_6', '(', 'parameters,', 'METHOD_7', '(', 'VAR_2', ')', ')', ';', '}', 'VAR_1', '=', '(', '(', 'TYPE_2', ')', '(', 'VAR_2.', 'METHOD_8', '(', ')', ')', ')', ';', '}', '}']]\n","0.17\n","61.45\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IGGJYnLmxV7E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624464281813,"user_tz":-360,"elapsed":3807,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"647a87ea-6783-4c93-aa76-bf5a73740eea"},"source":["accuracy = Accuracy(total_actual_str,total_actual_str)\n","sommth_bleu_score = round(_bleu(total_actual_str, total_actual_str),2)\n","\n","print(accuracy)\n","print(sommth_bleu_score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[['public', 'java.lang.String', 'METHOD_1', '(', ')', '{', 'if', '(', '(', 'METHOD_2', '(', ')', ')', '&&', '(', 'METHOD_3', '(', 'VAR_1', '.', 'METHOD_4', '(', ')', ')', ')', ')', '{', 'return', 'VAR_1', '.', 'METHOD_4', '(', ')', ';', '}', 'else', 'if', '(', 'METHOD_3', '(', 'VAR_3', '.', 'METHOD_5', '(', ')', '.', 'METHOD_6', '(', ')', ')', ')', '{', 'return', 'VAR_3', '.', 'METHOD_5', '(', ')', '.', 'METHOD_6', '(', ')', ';', '}', 'else', '{', 'return', 'VAR_4', '.', 'METHOD_4', '(', ')', ';', '}', '}'], ['private', 'void', 'METHOD_1', '(', 'TYPE_1', 'index', ',', 'java.util.Collection', '<', 'TYPE_2', '>', 'VAR_1', ')', '{', 'TYPE_1', 'VAR_2', '=', 'index', '.', 'METHOD_2', '(', 'VAR_3', ')', ';', 'for', '(', 'TYPE_3', '<', 'TYPE_2', '>', 'VAR_4', ':', 'this', '.', 'VAR_1', '.', 'values', '(', ')', ')', '{', 'VAR_4', '.', 'METHOD_3', '(', 'VAR_2', ',', 'null', ')', ';', '}', 'METHOD_4', '(', 'index', ',', 'VAR_1', ')', ';', '}'], ['public', 'void', 'remove', '(', 'int', 'id', ')', '{', 'try', '{', 'java.lang.String', 'query', '=', 'STRING_1', ';', 'TYPE_1', 'VAR_1', '=', 'METHOD_1', '(', ')', ';', 'TYPE_2', 'VAR_2', '=', 'VAR_1', '.', 'METHOD_2', '(', 'query', ')', ';', 'VAR_2', '.', 'METHOD_3', '(', '1', ',', 'id', ')', ';', 'VAR_2', '.', 'METHOD_4', '(', ')', ';', '}', 'catch', '(', 'TYPE_3', 'VAR_3', ')', '{', 'java.lang.System.out.println', '(', 'STRING_2', ')', ';', '}', '}'], ['private', 'java.util.List', '<', 'TYPE_1', '>', 'METHOD_1', '(', ')', '{', 'java.util.List', '<', 'TYPE_1', '>', 'VAR_2', '=', 'new', 'java.util.ArrayList', '<', '>', '(', ')', ';', 'for', '(', 'int', 'i', '=', '0', ';', 'i', '<', '(', 'VAR_3', '.', 'size', '(', ')', ')', ';', 'i', '++', ')', '{', 'TYPE_1', 'VAR_1', '=', 'new', 'TYPE_1', '(', ')', ';', 'VAR_1', '.', 'METHOD_2', '(', 'VAR_3', '.', 'get', '(', 'i', ')', '.', 'METHOD_3', '(', ')', ')', ';', 'VAR_2', '.', 'add', '(', 'VAR_1', ')', ';', '}', 'return', 'VAR_2', ';', '}'], ['private', 'void', 'METHOD_1', '(', 'java.util.List', '<', 'TYPE_1', '>', 'parameters', ',', 'TYPE_2', 'VAR_1', ')', '{', 'while', '(', 'VAR_1', '.', 'METHOD_2', '(', ')', ')', '{', 'TYPE_3', 'VAR_2', '=', 'METHOD_3', '(', 'VAR_1', ')', ';', 'if', '(', 'VAR_2', '==', 'null', ')', '{', 'break', ';', '}', 'if', '(', 'VAR_2', '.', 'METHOD_4', '(', ')', ')', '{', 'METHOD_6', '(', 'parameters', ',', 'METHOD_7', '(', 'VAR_2', ')', ')', ';', '}', 'VAR_1', '=', '(', '(', 'TYPE_2', ')', '(', 'VAR_2', '.', 'METHOD_8', '(', ')', ')', ')', ';', '}', '}']]\n","[['public', 'java.lang.String', 'METHOD_1', '(', ')', '{', 'if', '(', '(', 'METHOD_2', '(', ')', ')', '&&', '(', 'METHOD_3', '(', 'VAR_1', '.', 'METHOD_4', '(', ')', ')', ')', ')', '{', 'return', 'VAR_1', '.', 'METHOD_4', '(', ')', ';', '}', 'else', 'if', '(', 'METHOD_3', '(', 'VAR_3', '.', 'METHOD_5', '(', ')', '.', 'METHOD_6', '(', ')', ')', ')', '{', 'return', 'VAR_3', '.', 'METHOD_5', '(', ')', '.', 'METHOD_6', '(', ')', ';', '}', 'else', '{', 'return', 'VAR_4', '.', 'METHOD_4', '(', ')', ';', '}', '}'], ['private', 'void', 'METHOD_1', '(', 'TYPE_1', 'index', ',', 'java.util.Collection', '<', 'TYPE_2', '>', 'VAR_1', ')', '{', 'TYPE_1', 'VAR_2', '=', 'index', '.', 'METHOD_2', '(', 'VAR_3', ')', ';', 'for', '(', 'TYPE_3', '<', 'TYPE_2', '>', 'VAR_4', ':', 'this', '.', 'VAR_1', '.', 'values', '(', ')', ')', '{', 'VAR_4', '.', 'METHOD_3', '(', 'VAR_2', ',', 'null', ')', ';', '}', 'METHOD_4', '(', 'index', ',', 'VAR_1', ')', ';', '}'], ['public', 'void', 'remove', '(', 'int', 'id', ')', '{', 'try', '{', 'java.lang.String', 'query', '=', 'STRING_1', ';', 'TYPE_1', 'VAR_1', '=', 'METHOD_1', '(', ')', ';', 'TYPE_2', 'VAR_2', '=', 'VAR_1', '.', 'METHOD_2', '(', 'query', ')', ';', 'VAR_2', '.', 'METHOD_3', '(', '1', ',', 'id', ')', ';', 'VAR_2', '.', 'METHOD_4', '(', ')', ';', '}', 'catch', '(', 'TYPE_3', 'VAR_3', ')', '{', 'java.lang.System.out.println', '(', 'STRING_2', ')', ';', '}', '}'], ['private', 'java.util.List', '<', 'TYPE_1', '>', 'METHOD_1', '(', ')', '{', 'java.util.List', '<', 'TYPE_1', '>', 'VAR_2', '=', 'new', 'java.util.ArrayList', '<', '>', '(', ')', ';', 'for', '(', 'int', 'i', '=', '0', ';', 'i', '<', '(', 'VAR_3', '.', 'size', '(', ')', ')', ';', 'i', '++', ')', '{', 'TYPE_1', 'VAR_1', '=', 'new', 'TYPE_1', '(', ')', ';', 'VAR_1', '.', 'METHOD_2', '(', 'VAR_3', '.', 'get', '(', 'i', ')', '.', 'METHOD_3', '(', ')', ')', ';', 'VAR_2', '.', 'add', '(', 'VAR_1', ')', ';', '}', 'return', 'VAR_2', ';', '}'], ['private', 'void', 'METHOD_1', '(', 'java.util.List', '<', 'TYPE_1', '>', 'parameters', ',', 'TYPE_2', 'VAR_1', ')', '{', 'while', '(', 'VAR_1', '.', 'METHOD_2', '(', ')', ')', '{', 'TYPE_3', 'VAR_2', '=', 'METHOD_3', '(', 'VAR_1', ')', ';', 'if', '(', 'VAR_2', '==', 'null', ')', '{', 'break', ';', '}', 'if', '(', 'VAR_2', '.', 'METHOD_4', '(', ')', ')', '{', 'METHOD_6', '(', 'parameters', ',', 'METHOD_7', '(', 'VAR_2', ')', ')', ';', '}', 'VAR_1', '=', '(', '(', 'TYPE_2', ')', '(', 'VAR_2', '.', 'METHOD_8', '(', ')', ')', ')', ';', '}', '}']]\n","100.0\n","100.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"djtFAyfe2ncv","executionInfo":{"status":"ok","timestamp":1624032134883,"user_tz":-360,"elapsed":535,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"06154810530490924203"}},"outputId":"47eec9a3-21e7-4b9f-ba14-d44bba4ccdac"},"source":["print(ed.config.encoder.max_length)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["20\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ht2OMlcq5fF","executionInfo":{"status":"ok","timestamp":1623752484246,"user_tz":-360,"elapsed":420,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"06154810530490924203"}},"outputId":"edb45d68-7745-4517-f91b-ba8c78620aa5"},"source":["import torch\n","output_ids_padding = torch.where(train_labels[0]== -100,led_tokenizer.pad_token_id,train_labels[0])\n","print(led_tokenizer.decode(output_ids_padding))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<s>[problem_tags]greedy, math, sortings[problem_difficulty]1100[req_time]218 ms[req_memory]400 KB[code_text]#include<bits/stdc++.h>\r\r\n","using namespace std;\r\r\n","\r\r\n","int main()\r\r\n","{\r\r\n","\tint t; cin>>t; while(t-->0){\r\r\n","\t\tint n; cin>>n; int a[n]; for(int i=0;i<n;i++) cin>>a[i];\r\r\n","\t\tint p=n-1; sort(a,a+n);\r\r\n","\t\tfor(int i=0;i<p;i++){\r\r\n","\t\t\tif(a[i+1]-a[i] < a[p]){\r\r\n","\t\t\t\tp--; i--;\r\r\n","\t\t\t}\r\r\n","\t\t}\r\r\n","\t\tcout << p+1 << endl;\r\r\n","\t}\r\r\n","}</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tSp5J6ltjHP6"},"source":["import torch\n","\n","from datasets import load_dataset, load_metric\n","from transformers import LEDTokenizer, LEDForConditionalGeneration\n","\n","# load pubmed\n","pubmed_test = load_dataset(\"scientific_papers\", \"pubmed\", ignore_verifications=True, split=\"test\")\n","\n","# load tokenizer\n","tokenizer = LEDTokenizer.from_pretrained(\"patrickvonplaten/led-large-16384-pubmed\")\n","model = LEDForConditionalGeneration.from_pretrained(\"patrickvonplaten/led-large-16384-pubmed\").to(\"cuda\").half()\n","\n","\n","def generate_answer(batch):\n","  inputs_dict = tokenizer(batch[\"article\"], padding=\"max_length\", max_length=8192, return_tensors=\"pt\", truncation=True)\n","  input_ids = inputs_dict.input_ids.to(\"cuda\")\n","  attention_mask = inputs_dict.attention_mask.to(\"cuda\")\n","  global_attention_mask = torch.zeros_like(attention_mask)\n","  # put global attention on <s> token\n","  global_attention_mask[:, 0] = 1\n","\n","  predicted_abstract_ids = model.generate(input_ids, attention_mask=attention_mask, global_attention_mask=global_attention_mask)\n","  batch[\"predicted_abstract\"] = tokenizer.batch_decode(predicted_abstract_ids, skip_special_tokens=True)\n","  return batch\n","\n","\n","result = pubmed_test.map(generate_answer, batched=True, batch_size=4)\n","\n","# load rouge\n","rouge = load_metric(\"rouge\")\n","\n","print(\"Result:\", rouge.compute(predictions=result[\"predicted_abstract\"], references=result[\"abstract\"], rouge_types=[\"rouge2\"])[\"rouge2\"].mid)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UkDe4LKiJcPI"},"source":["for i in range(len(train_labels)):\n","  for x in train_labels[i]:\n","    if(x>50277 or x<0):\n","      print(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t-JsofAhQU-B"},"source":["for x in train_labels[0]:\n","  if(x!=1):\n","    #print(x)\n","    #s = led_tokenizer.convert_ids_to_tokens(torch.tensor([x]))\n","    #x = led_model.get_decoder().embed_tokens(train_labels[0])[0]\n","    #print(s)\n","    m = led_model.get_decoder()\n","    ss = m(tensorify([[x]]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zJxUK4pJb6nw","executionInfo":{"status":"ok","timestamp":1622920670945,"user_tz":-360,"elapsed":575,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"74e9e588-8025-48f7-d830-47c1e9c7a61b"},"source":["arr = torch.zeros_like(train_labels[0])\n","print(len(arr))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["4096\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XxnwUjfMe3Aa"},"source":["print(led_model.config.max_decoder_position_embeddings)\n","dec = led_model.get_decoder()\n","print(led_model.get_decoder().embed_tokens)\n","dec.set_input_embeddings(led_model.get_encoder().embed_tokens)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":340},"id":"-pFi8xqyaGAX","executionInfo":{"status":"error","timestamp":1622923729558,"user_tz":-360,"elapsed":389,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"bff6c710-6fd9-45bf-e400-01763dfbf57f"},"source":["x = edm.get_decoder()\n","ss = x(tensorify([arr[:1024]]))"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-49-2bb4de1c05e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensorify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/reformer/modeling_reformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, position_ids, attention_mask, head_mask, inputs_embeds, num_hashes, past_buckets_states, use_cache, output_hidden_states, output_attentions, return_dict, labels)\u001b[0m\n\u001b[1;32m   2236\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2237\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2238\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2239\u001b[0m         )\n\u001b[1;32m   2240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/reformer/modeling_reformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, num_hashes, past_buckets_states, use_cache, output_hidden_states, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m   2083\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2084\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2085\u001b[0;31m             \u001b[0mstart_idx_pos_encodings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_idx_pos_encodings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2086\u001b[0m         )\n\u001b[1;32m   2087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/reformer/modeling_reformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, position_ids, inputs_embeds, start_idx_pos_encodings)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m# add positional embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/reformer/modeling_reformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, position_ids)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxial_pos_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 raise ValueError(\n\u001b[0;32m--> 156\u001b[0;31m                     \u001b[0;34mf\"If training, make sure that config.axial_pos_shape factors: {self.axial_pos_shape} multiply to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                     \u001b[0;34mf\"sequence length. Got prod({self.axial_pos_shape}) != sequence_length: {sequence_length}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                     \u001b[0;34mf\"You might want to consider padding your sequence length to {reduce(mul, self.axial_pos_shape)} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: If training, make sure that config.axial_pos_shape factors: (128, 512) multiply to sequence length. Got prod((128, 512)) != sequence_length: 1024. You might want to consider padding your sequence length to 65536 or changing config.axial_pos_shape."]}]},{"cell_type":"code","metadata":{"id":"UsKew13SR3sD"},"source":["print(ss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x4u0kzyrFKx5","executionInfo":{"status":"ok","timestamp":1622911805192,"user_tz":-360,"elapsed":405,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"95c67d2e-e857-482f-b1a2-17a62573c430"},"source":["print(len(led_tokenizer))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["50265\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qOlwP_wSFO8u"},"source":["print(led_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j5vDcLYyhSbl"},"source":["model = led_model.get_decoder()\n","#x.from_pretrained(\"allenai/led-base-16384\")\n","model.max_target_positions = 2048"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8kbNwdP1m8fq"},"source":["from transformers import EncoderDecoderModel,AutoModelForCausalLM\n","\n","encoder_model = AutoModelForCausalLM.from_pretrained('allenai/longformer-base-4096')\n","#encoder_model.resize_token_embeddings(len(encoder_tokenizer))\n","\n","encoder_model.save_pretrained(project_path+'Saved_Models/Longformer_Encoder_Init_2')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KoDI4zbRpeX1"},"source":["from transformers import EncoderDecoderModel,AutoModelForSeq2SeqLM, ReformerModel,ReformerForMaskedLM\n","\n","edm = EncoderDecoderModel.from_encoder_decoder_pretrained(project_path+'Saved_Models/asd_E',project_path+'Saved_Models/asd_D')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wMMSQ3nMxWAY","executionInfo":{"status":"ok","timestamp":1623221292691,"user_tz":-360,"elapsed":8787,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"12a3852a-cc35-4926-9005-53906401f8ea"},"source":["print(edm.config.decoder.max_position_embeddings)\n","\n","edm.save_pretrained(project_path+'Saved_Models/asd_ED')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["65536\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IaiojYkjgZMV"},"source":["from transformers import ReformerModel, ReformerConfig\n","# Initializing a Reformer configuration\n","configuration = ReformerConfig.from_pretrained(\"google/reformer-enwik8\", lsh_attn_chunk_length=16386, local_attn_chunk_length=16386)\n","# Initializing a Reformer model\n","enc_model = ReformerModel(configuration)\n","\n","enc_model.save_pretrained(project_path+'Saved_Models/asd_E')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fHywIi9Lgps7"},"source":["from transformers import ReformerForMaskedLM, ReformerConfig\n","# Initializing a Reformer configuration\n","configuration = ReformerConfig.from_pretrained(\"google/reformer-enwik8\", lsh_attn_chunk_length=16386, local_attn_chunk_length=16386)\n","configuration.is_decoder=False\n","# Initializing a Reformer model\n","dec_model = ReformerForMaskedLM(configuration)\n","\n","dec_model.save_pretrained(project_path+'Saved_Models/asd_D')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZGHTUf4ecHdH"},"source":["red = AutoModelForSeq2SeqLM.from_pretrained(project_path+'Saved_Models/asd_ED')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L--c2w-3h6KW","executionInfo":{"status":"ok","timestamp":1623221451026,"user_tz":-360,"elapsed":340,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"55240be5-4d04-43d3-b253-28b0c90f4d3f"},"source":["print(red.config.decoder.is_decoder)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dl3iiv78lHjz","executionInfo":{"status":"ok","timestamp":1623222892873,"user_tz":-360,"elapsed":4739,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"4dc8acd5-71b5-4922-97a2-cbdeccf772a7"},"source":["cnt_1024 = 0\n","cnt_4096 = 0\n","\n","for x in train_labels:\n","  try:\n","    if(x.tolist().index(1)+1<=1023):\n","      cnt_1024=cnt_1024+1\n","    else:\n","      cnt_4096 = cnt_4096+1\n","  except:\n","    cnt_4096 = cnt_4096+1\n","\n","print(cnt_1024)\n","print(cnt_4096)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["16863\n","12389\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"81l9k2RDnro3","executionInfo":{"status":"ok","timestamp":1623222847906,"user_tz":-360,"elapsed":323,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"1655e8db-b97c-47cd-ba01-1aba646dc43e"},"source":["print(len(train_encoding['input_ids']))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["29252\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mGMhJU43lwrD","executionInfo":{"status":"ok","timestamp":1623222574131,"user_tz":-360,"elapsed":349,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"5b5ffb29-b5cc-4f40-df68-fb382ffe792c"},"source":["print(train_encoding['input_ids'][0].tolist().index(1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["626\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238,"referenced_widgets":["3fd406cb781c4531bfeae59f1b2f8460","0ed49ed0fabc433892cb6e66256b110a","9f2417e77b5c40529814b17863ed7abc","0c34082f5e4440f8a83b57148659ef8e","057582f7457a420d8756a3ba6d057634","dd767d8c985a4576a49fac5b8d9be619","08929d7f50684c7c8ada1dfd288038e9","38ec365837fa4ff0a2be6c8cba2ab4d2","7d0bb7a8222c4cdd93ebe7343c255476","7270e156c2ff4542bd03b3a45226bb57","27d0397128774943a646b8e58302a4c0","8d6ab9f9e9f64ec29c325fafb95f606b","5019419281ac4713bb661ff4d40a7517","0aaa5b3202324f09a008ba9d56dd9a25","5b6f621fe077499e8f3d16861ad6d3b8","486c7fddcdb6442f8196ee95d637ab75"]},"id":"kssh2MlxlRC1","executionInfo":{"status":"ok","timestamp":1623827507768,"user_tz":-360,"elapsed":19049,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"06154810530490924203"}},"outputId":"51559d13-ea70-4448-d004-da2dd8c46b9d"},"source":["#python_code = \"def convert(x): return x\"\n","PHP_CODE = \"\"\"\n","public static <mask> set(string $key, $value) {\n","    if (!in_array($key, self::$allowedKeys)) {\n","        throw new \\InvalidArgumentException('Invalid key given');\n","    }\n","    self::$storedValues[$key] = $value;\n","}\n","\"\"\".lstrip()\n","\n","from transformers import pipeline, EncoderDecoderModel\n","\n","#summarizer = pipeline(\"summarization\")\n","\n","ed_model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"microsoft/codebert-base-mlm\",\"microsoft/codebert-base\")\n","'''\n","fill_mask = pipeline(\n","    \"summarization\",\n","    model=model,\n","    tokenizer=\"microsoft/codebert-base-mlm\"\n",")\n","\n","print(fill_mask(PHP_CODE))\n","'''\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at microsoft/codebert-base-mlm were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3fd406cb781c4531bfeae59f1b2f8460","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=498.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d0bb7a8222c4cdd93ebe7343c255476","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=498627950.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of RobertaForCausalLM were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.value.bias', 'lm_head.layer_norm.bias', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'lm_head.bias', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.8.crossattention.self.value.bias', 'lm_head.decoder.weight', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.query.weight', 'lm_head.dense.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'lm_head.dense.weight', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.value.bias', 'lm_head.layer_norm.weight', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nfill_mask = pipeline(\\n    \"summarization\",\\n    model=model,\\n    tokenizer=\"microsoft/codebert-base-mlm\"\\n)\\n\\nprint(fill_mask(PHP_CODE))\\n'"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":553,"referenced_widgets":["7e43d9250d9c4fe98cf2194b98c78718","1a94aa7269f04ec0a6225998be67fe19","ee9becdbc1304049894383e58d3494af","b74e72c12b5b4616a8442c4cb6c43d66","4eac87fde4cd41069b79a176f4f0ef2c","05b4472fa511434d976e4fdfe07f0b0e","6d57a22c25154c0bbe08e30c14b14058","257914342d4d46b18d18ce634df1491e","a68e0782e4a5468db873a756625b19de","de2be8b05cce43bfaa77683c05d88601","a5d2b9fc93804566a996519a9effd1b4","da2b4c1886aa436bb65d7bf84ec83591","5dcbe6b0e6ff4a809bbe5169c26ccc66","0c8efdfc214a4555b45553902871ca21","70a386e1270d4cec81a6f8094949f78a","97e7fd5fe96240029d5c945237f2698f","9203100138a345008a2f9a8fbf0d2b64","e1fd4543d8954cf9a39a44e87ff88d51","0619c1520fef496cbe7c7ff7849f5a3e","cf4a578094e34e49b2aa06645c967a45","efc714bbf70346978fc96984d874c14e","4043d03dae6340f69a78ca3de9769269","4f16ea15084949d9ba31135f95e46883","63fccdf13da943d5b6465aac5de450c9","5363e51c14074513a213eee6a32be738","cc3f26fa8f3f408da359dd9fb8951240","42d306f457d342cd9145fa9ac8849bb3","593bba70198e43ff84d417e394fa37ec","4ee0adef37534792857a6d87798d17cb","8eddc5a2839c4b359b7415194dfa7f0f","221f4aaf860c4a6fbafd774a348bb227","d10fc488334e4677842ef6c6230a8d5a"]},"id":"mOUktUDZpWTS","executionInfo":{"status":"error","timestamp":1623830636311,"user_tz":-360,"elapsed":18035,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"06154810530490924203"}},"outputId":"3c42d94d-2c19-4b6a-f721-9856c404adce"},"source":["summarizer = pipeline(\"text-generation\", model=\"microsoft/codebert-base\", tokenizer=\"microsoft/codebert-base\", framework=\"tf\")\n","summarizer(\"def convert_int_to_str(x):\", min_length=5, max_length=50)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e43d9250d9c4fe98cf2194b98c78718","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898822.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a68e0782e4a5468db873a756625b19de","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9203100138a345008a2f9a8fbf0d2b64","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=150.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5363e51c14074513a213eee6a32be738","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=25.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"error","ename":"PipelineException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mPipelineException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-65f1399abde7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummarizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text-generation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"microsoft/codebert-base\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"microsoft/codebert-base\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msummarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"def convert_int_to_str(x):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"feature_extractor\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtask_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, return_full_text, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_model_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALLOWED_MODELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_full_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_full_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mcheck_model_type\u001b[0;34m(self, supported_models)\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m                 \u001b[0;34mf\"The model '{self.model.__class__.__name__}' is not supported for {self.task}. Supported models are {supported_models}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m             )\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mPipelineException\u001b[0m: The model 'RobertaModel' is not supported for text-generation. Supported models are ['XLNetLMHeadModel', 'TransfoXLLMHeadModel', 'ReformerModelWithLMHead', 'GPT2LMHeadModel', 'GPTNeoForCausalLM', 'OpenAIGPTLMHeadModel', 'CTRLLMHeadModel', 'TFXLNetLMHeadModel', 'TFTransfoXLLMHeadModel', 'TFGPT2LMHeadModel', 'TFOpenAIGPTLMHeadModel', 'TFCTRLLMHeadModel']"]}]}]}