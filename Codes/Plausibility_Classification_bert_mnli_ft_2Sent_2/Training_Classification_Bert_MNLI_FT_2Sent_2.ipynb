{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Training_Classification_Bert_MNLI_FT_2Sent_2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"52345ff5a81444a8ad467674bd5dd735":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d4e3dc1929c34f6f920fd54816d44473","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_699cb00c6c6d424586c19bf67c2c6355","IPY_MODEL_b8beca9aa048492c8f6534bbed178f44","IPY_MODEL_55b4f686272a4d0f87370b3c74b32225"]}},"d4e3dc1929c34f6f920fd54816d44473":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"699cb00c6c6d424586c19bf67c2c6355":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_58e728d168bc4d42893245177f497435","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_abf56ecadd054bbd805aef3490810842"}},"b8beca9aa048492c8f6534bbed178f44":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e5d1503493e841818b1579c3b935cd40","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":48,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":48,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ad49dbb109124865ace47d2b56bda35f"}},"55b4f686272a4d0f87370b3c74b32225":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a60eb1350f174da2bbcd9143c915ed7c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 48.0/48.0 [00:00&lt;00:00, 1.03kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1e518dced0894f1f97e7b4d96f22c001"}},"58e728d168bc4d42893245177f497435":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"abf56ecadd054bbd805aef3490810842":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e5d1503493e841818b1579c3b935cd40":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ad49dbb109124865ace47d2b56bda35f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a60eb1350f174da2bbcd9143c915ed7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1e518dced0894f1f97e7b4d96f22c001":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"51b216fdc5b645128f6ffb749a0427c8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0ff974ebee52412fbf5d28c2e1044eb7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e56469828f8f45ae918fc794484762d6","IPY_MODEL_211fd04467aa459ebc1f455836adaebf","IPY_MODEL_ad1aede8ac074c8480f79a0af181bdfd"]}},"0ff974ebee52412fbf5d28c2e1044eb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e56469828f8f45ae918fc794484762d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5d2298ac289f4ef78ceddc7f46517388","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a861f815340c4507afc046679a7a17e0"}},"211fd04467aa459ebc1f455836adaebf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2fa5278e72224070b699a429474c3437","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":630,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":630,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3a1aa267188a46ceb512c148500557f6"}},"ad1aede8ac074c8480f79a0af181bdfd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5bb214a3a385416e915402c246b60e43","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 630/630 [00:00&lt;00:00, 17.1kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7cdf625baa304093ba45b57a928245ca"}},"5d2298ac289f4ef78ceddc7f46517388":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a861f815340c4507afc046679a7a17e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2fa5278e72224070b699a429474c3437":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3a1aa267188a46ceb512c148500557f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5bb214a3a385416e915402c246b60e43":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7cdf625baa304093ba45b57a928245ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d2055937f7b84bdf85aaa9d718b47fcd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1b6d034f1aee4331bd7def3d1e2d775c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e1a13a1dc89049f1842dc18feb9fc8cc","IPY_MODEL_ea1b1474d0424f8faf0e38c02229c86a","IPY_MODEL_533b8ca876bb491baed5667ec87c2df0"]}},"1b6d034f1aee4331bd7def3d1e2d775c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e1a13a1dc89049f1842dc18feb9fc8cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ca0c02e449ae45789d5dbe4d2aa4275b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_55a5b7144fce49789d9611ed3aff6802"}},"ea1b1474d0424f8faf0e38c02229c86a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e832f9589f454cd5a02656faa0401ed8","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8e63601a7d9c4fe9a0da0fdbb477fc41"}},"533b8ca876bb491baed5667ec87c2df0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d589eb7cc727497ba6c534a719aa3923","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 226k/226k [00:00&lt;00:00, 755kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a79c3cb3ced64de083d1671335f9fed7"}},"ca0c02e449ae45789d5dbe4d2aa4275b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"55a5b7144fce49789d9611ed3aff6802":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e832f9589f454cd5a02656faa0401ed8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8e63601a7d9c4fe9a0da0fdbb477fc41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d589eb7cc727497ba6c534a719aa3923":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a79c3cb3ced64de083d1671335f9fed7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6c99b84215dc47a09c794d6a8d687a55":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_79e6108927324614aa594efef7632988","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f0e9c9ef17e74f7f894a1824b94abe34","IPY_MODEL_ae918d8a52bb46ef996a26a54c762291","IPY_MODEL_3c45ccbb5dbb407fbf5af4fcdd8c70a3"]}},"79e6108927324614aa594efef7632988":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f0e9c9ef17e74f7f894a1824b94abe34":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_56f21ada06bc44b1b3653dcec8dbff23","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c1ea160fb83b491b8ad56605ad8a81c9"}},"ae918d8a52bb46ef996a26a54c762291":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a243d76dee3142b7bb67915219187f30","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":112,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":112,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_58ed6fa783ff45dc98bebe518073a50b"}},"3c45ccbb5dbb407fbf5af4fcdd8c70a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3cc6144297754d8491d1815d5effdbbf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 112/112 [00:00&lt;00:00, 2.92kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_74288cb8381440519283445e1dbdf661"}},"56f21ada06bc44b1b3653dcec8dbff23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c1ea160fb83b491b8ad56605ad8a81c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a243d76dee3142b7bb67915219187f30":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"58ed6fa783ff45dc98bebe518073a50b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3cc6144297754d8491d1815d5effdbbf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"74288cb8381440519283445e1dbdf661":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3a2dbfb2c1a84d3c9a17c041a7a98629":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_55cb62b359844edc90920eaca914e9d2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f424091fde0c44bf874aacd6a9bafcac","IPY_MODEL_4ee57cbc19054214a7ac42e547ee09c2","IPY_MODEL_6436144838a946a292ae759133b1f122"]}},"55cb62b359844edc90920eaca914e9d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f424091fde0c44bf874aacd6a9bafcac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ea4f744c22b6475d8b3af9c4629ed00d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aee84de5db554284a6e8f5784306cfd3"}},"4ee57cbc19054214a7ac42e547ee09c2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f9391fad7ece416abf6a4470ef83dad5","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":437988463,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":437988463,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0ec2b151dd374b03927989b830621c3d"}},"6436144838a946a292ae759133b1f122":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_efc11343e46f45a8b621b086cb07516f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 418M/418M [00:16&lt;00:00, 28.4MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a048a1032ddc4d869f604562af3a012d"}},"ea4f744c22b6475d8b3af9c4629ed00d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"aee84de5db554284a6e8f5784306cfd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f9391fad7ece416abf6a4470ef83dad5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0ec2b151dd374b03927989b830621c3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"efc11343e46f45a8b621b086cb07516f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a048a1032ddc4d869f604562af3a012d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"23bd46b99c89418999ac75c0a83acd3c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2a53d398e73245449f287c42bc15c8ce","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7e4def0603e744fb883295bd48634587","IPY_MODEL_a527afd7a9c1424a920283a8b96cfddd","IPY_MODEL_11592961c887443c9711aa11d3931b00"]}},"2a53d398e73245449f287c42bc15c8ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7e4def0603e744fb883295bd48634587":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7ea96dc7c54846749a8ad9a10d7015ea","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: ","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d185a0ff82f64f71a861b2d2ce28dec7"}},"a527afd7a9c1424a920283a8b96cfddd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0f37c8ce6ad94d25b8cae3c834716081","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1248,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1248,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_669d3bee449d498d9472d66ba6def250"}},"11592961c887443c9711aa11d3931b00":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_be65334abfa84a7d84feec15f86f93a5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2.64k/? [00:00&lt;00:00, 67.5kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0139398eaa8a45a58c05b6594fa43100"}},"7ea96dc7c54846749a8ad9a10d7015ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d185a0ff82f64f71a861b2d2ce28dec7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0f37c8ce6ad94d25b8cae3c834716081":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"669d3bee449d498d9472d66ba6def250":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"be65334abfa84a7d84feec15f86f93a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0139398eaa8a45a58c05b6594fa43100":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"19aa5ab11a654963acf13242aca9af58":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e2060577fc1748f58ebdb6a6b1efa0a2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f3f75d8af49343edbf11f7499bd747ee","IPY_MODEL_f4aefafdc0564eccbcd359ca2de5cdae","IPY_MODEL_8cea44f18f8a4d34a97530a5a495f839"]}},"e2060577fc1748f58ebdb6a6b1efa0a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f3f75d8af49343edbf11f7499bd747ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9c0cabb997144e1fa0ae9359184cfed1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Skipping the first batches: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f112ecb120d44a0889b774ba3cf3232d"}},"f4aefafdc0564eccbcd359ca2de5cdae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7d8d076ed1d64bdaa3b1cbc7140e131f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":268,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":268,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fa3e5abc67c04043a3dcd6e926594984"}},"8cea44f18f8a4d34a97530a5a495f839":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_aa9620d86a00475592ff7166d00c31f4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 268/268 [00:06&lt;00:00, 122.67it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5e8651435020488bb86a0c4717e52e8a"}},"9c0cabb997144e1fa0ae9359184cfed1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f112ecb120d44a0889b774ba3cf3232d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7d8d076ed1d64bdaa3b1cbc7140e131f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fa3e5abc67c04043a3dcd6e926594984":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aa9620d86a00475592ff7166d00c31f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5e8651435020488bb86a0c4717e52e8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ca6f1ac354cc46f0908aafe38153169e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c218d9b79e0d4c8cb2a0eed53dd7b408","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5b334d5c6fc44a17bbd028c1cf9f852f","IPY_MODEL_ff608fc8b46b4b8eb69d176f89ccec0a","IPY_MODEL_d80ee9d46d7d477599b6c730a3db8137"]}},"c218d9b79e0d4c8cb2a0eed53dd7b408":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5b334d5c6fc44a17bbd028c1cf9f852f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_35eb604a76f34c1a9f725d236b9ba111","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Skipping the first batches: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e0d2cd666716461295089890803eba32"}},"ff608fc8b46b4b8eb69d176f89ccec0a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2e7aa5664cc042be86cdb063b15e58db","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1800,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1800,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c22fb2ebd1dd4784ab0bba5aa7b5e68a"}},"d80ee9d46d7d477599b6c730a3db8137":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0fb183a2e46b40aab309c1057035c059","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1800/1800 [00:13&lt;00:00, 425.22it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5a225d06e68442fd96dc5b7ccad4d479"}},"35eb604a76f34c1a9f725d236b9ba111":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e0d2cd666716461295089890803eba32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2e7aa5664cc042be86cdb063b15e58db":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c22fb2ebd1dd4784ab0bba5aa7b5e68a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0fb183a2e46b40aab309c1057035c059":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5a225d06e68442fd96dc5b7ccad4d479":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3fd406cb781c4531bfeae59f1b2f8460":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0ed49ed0fabc433892cb6e66256b110a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9f2417e77b5c40529814b17863ed7abc","IPY_MODEL_0c34082f5e4440f8a83b57148659ef8e"]}},"0ed49ed0fabc433892cb6e66256b110a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9f2417e77b5c40529814b17863ed7abc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_057582f7457a420d8756a3ba6d057634","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":498,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":498,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dd767d8c985a4576a49fac5b8d9be619"}},"0c34082f5e4440f8a83b57148659ef8e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_08929d7f50684c7c8ada1dfd288038e9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 498/498 [00:02&lt;00:00, 240B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_38ec365837fa4ff0a2be6c8cba2ab4d2"}},"057582f7457a420d8756a3ba6d057634":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"dd767d8c985a4576a49fac5b8d9be619":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"08929d7f50684c7c8ada1dfd288038e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"38ec365837fa4ff0a2be6c8cba2ab4d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7d0bb7a8222c4cdd93ebe7343c255476":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7270e156c2ff4542bd03b3a45226bb57","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_27d0397128774943a646b8e58302a4c0","IPY_MODEL_8d6ab9f9e9f64ec29c325fafb95f606b"]}},"7270e156c2ff4542bd03b3a45226bb57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"27d0397128774943a646b8e58302a4c0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5019419281ac4713bb661ff4d40a7517","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":498627950,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":498627950,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0aaa5b3202324f09a008ba9d56dd9a25"}},"8d6ab9f9e9f64ec29c325fafb95f606b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5b6f621fe077499e8f3d16861ad6d3b8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 499M/499M [00:14&lt;00:00, 33.9MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_486c7fddcdb6442f8196ee95d637ab75"}},"5019419281ac4713bb661ff4d40a7517":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0aaa5b3202324f09a008ba9d56dd9a25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5b6f621fe077499e8f3d16861ad6d3b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"486c7fddcdb6442f8196ee95d637ab75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7e43d9250d9c4fe98cf2194b98c78718":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1a94aa7269f04ec0a6225998be67fe19","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ee9becdbc1304049894383e58d3494af","IPY_MODEL_b74e72c12b5b4616a8442c4cb6c43d66"]}},"1a94aa7269f04ec0a6225998be67fe19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ee9becdbc1304049894383e58d3494af":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4eac87fde4cd41069b79a176f4f0ef2c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":898822,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898822,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_05b4472fa511434d976e4fdfe07f0b0e"}},"b74e72c12b5b4616a8442c4cb6c43d66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6d57a22c25154c0bbe08e30c14b14058","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 899k/899k [00:01&lt;00:00, 890kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_257914342d4d46b18d18ce634df1491e"}},"4eac87fde4cd41069b79a176f4f0ef2c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"05b4472fa511434d976e4fdfe07f0b0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6d57a22c25154c0bbe08e30c14b14058":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"257914342d4d46b18d18ce634df1491e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a68e0782e4a5468db873a756625b19de":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_de2be8b05cce43bfaa77683c05d88601","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a5d2b9fc93804566a996519a9effd1b4","IPY_MODEL_da2b4c1886aa436bb65d7bf84ec83591"]}},"de2be8b05cce43bfaa77683c05d88601":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a5d2b9fc93804566a996519a9effd1b4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5dcbe6b0e6ff4a809bbe5169c26ccc66","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0c8efdfc214a4555b45553902871ca21"}},"da2b4c1886aa436bb65d7bf84ec83591":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_70a386e1270d4cec81a6f8094949f78a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:00&lt;00:00, 746kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_97e7fd5fe96240029d5c945237f2698f"}},"5dcbe6b0e6ff4a809bbe5169c26ccc66":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0c8efdfc214a4555b45553902871ca21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"70a386e1270d4cec81a6f8094949f78a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"97e7fd5fe96240029d5c945237f2698f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9203100138a345008a2f9a8fbf0d2b64":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e1fd4543d8954cf9a39a44e87ff88d51","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0619c1520fef496cbe7c7ff7849f5a3e","IPY_MODEL_cf4a578094e34e49b2aa06645c967a45"]}},"e1fd4543d8954cf9a39a44e87ff88d51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0619c1520fef496cbe7c7ff7849f5a3e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_efc714bbf70346978fc96984d874c14e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":150,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":150,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4043d03dae6340f69a78ca3de9769269"}},"cf4a578094e34e49b2aa06645c967a45":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4f16ea15084949d9ba31135f95e46883","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 150/150 [00:00&lt;00:00, 333B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_63fccdf13da943d5b6465aac5de450c9"}},"efc714bbf70346978fc96984d874c14e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4043d03dae6340f69a78ca3de9769269":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4f16ea15084949d9ba31135f95e46883":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"63fccdf13da943d5b6465aac5de450c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5363e51c14074513a213eee6a32be738":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cc3f26fa8f3f408da359dd9fb8951240","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_42d306f457d342cd9145fa9ac8849bb3","IPY_MODEL_593bba70198e43ff84d417e394fa37ec"]}},"cc3f26fa8f3f408da359dd9fb8951240":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"42d306f457d342cd9145fa9ac8849bb3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4ee0adef37534792857a6d87798d17cb","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":25,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":25,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8eddc5a2839c4b359b7415194dfa7f0f"}},"593bba70198e43ff84d417e394fa37ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_221f4aaf860c4a6fbafd774a348bb227","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 25.0/25.0 [00:00&lt;00:00, 272B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d10fc488334e4677842ef6c6230a8d5a"}},"4ee0adef37534792857a6d87798d17cb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8eddc5a2839c4b359b7415194dfa7f0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"221f4aaf860c4a6fbafd774a348bb227":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d10fc488334e4677842ef6c6230a8d5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"MpxvQ14HFYM1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637235567656,"user_tz":480,"elapsed":27385,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"0d69579d-cbd4-4fc5-f75c-3b35f7b76f88"},"source":["from google.colab import drive\n","drive._mount('/content/drive/')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","metadata":{"id":"jGuiOxBdFh3k"},"source":["#!pip install -q keras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"utYxkMR9F0wq"},"source":["!pip install -q pydrive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OIJwvszjF4AZ"},"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WxE-L4LS3v5I"},"source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y8N8IE0Z30_Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637235616569,"user_tz":480,"elapsed":25814,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"7f6f492e-cbaf-4bfe-8398-a5e9eeec667f"},"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla K80\n"]}]},{"cell_type":"code","metadata":{"id":"yAUVCCQ96jsT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636627923747,"user_tz":480,"elapsed":22593,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06154810530490924203"}},"outputId":"4346e94c-6e7b-4697-9a3b-2918252657a5"},"source":["!nvidia-smi\n","\n","from tensorflow.python.client import device_lib\n","device_lib.list_local_devices()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Nov 11 10:51:41 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   67C    P8    33W / 149W |      3MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]},{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 6643255504538126705\n"," xla_global_id: -1, name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 10868293632\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 2378385677047141038\n"," physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n"," xla_global_id: 416903419]"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"6-PaQ17P36m8","colab":{"base_uri":"https://localhost:8080/","height":922},"executionInfo":{"status":"ok","timestamp":1637235647997,"user_tz":480,"elapsed":31445,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"10e684b9-995f-44ed-913d-033c98c4c0b6"},"source":["#!pip install transformers\n","!pip install git+https://github.com/huggingface/transformers"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/huggingface/transformers\n","  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-3sy84oj7\n","  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-3sy84oj7\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n","\u001b[K     |████████████████████████████████| 59 kB 5.4 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (21.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (4.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (3.3.2)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 22.6 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 36.3 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (4.62.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (2019.12.20)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 50.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (1.19.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.13.0.dev0) (3.10.0.2)\n","Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.13.0.dev0) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.13.0.dev0) (3.6.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (1.15.0)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.13.0.dev0-py3-none-any.whl size=3133584 sha256=1e53ea576d114860ee56b47d422f020fb8448835e613c7dfdff1a913eb100269\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-oq6svxkf/wheels/35/2e/a7/d819e3310040329f0f47e57c9e3e7a7338aa5e74c49acfe522\n","Successfully built transformers\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.13.0.dev0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["yaml"]}}},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"hYNfHEVCUTJM"},"source":["project_path='/content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b7Re8ir-aRg4","executionInfo":{"status":"ok","timestamp":1623930507463,"user_tz":-360,"elapsed":407,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"06154810530490924203"}},"outputId":"5f8c4590-62d5-41ce-b064-66903de9f725"},"source":["#cd '/content/drive/My Drive/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SmZ_NAJRUc7v"},"source":["#cd $project_path"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XutRrfaDUh-p"},"source":["#ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jEvmy_hdVu99"},"source":["import numpy as np\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eak_teqZUmjI"},"source":["def tensorify(lst):\n","    \"\"\"\n","    List must be nested list of tensors (with no varying lengths within a dimension).\n","    Nested list of nested lengths [D1, D2, ... DN] -> tensor([D1, D2, ..., DN)\n","\n","    :return: nested list D\n","    \"\"\"\n","    # base case, if the current list is not nested anymore, make it into tensor\n","    if type(lst[0]) != list:\n","        if type(lst) == torch.Tensor:\n","            return lst\n","        elif type(lst[0]) == torch.Tensor:\n","            return torch.stack(lst, dim=0)\n","        else:  # if the elements of lst are floats or something like that\n","            return torch.tensor(lst)\n","    current_dimension_i = len(lst)\n","    for d_i in range(current_dimension_i):\n","        tensor = tensorify(lst[d_i])\n","        lst[d_i] = tensor\n","    # end of loop lst[d_i] = tensor([D_i, ... D_0])\n","    tensor_lst = torch.stack(lst, dim=0)\n","    return tensor_lst"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KzLahl8DjRbo"},"source":["import torch\n","\n","class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","        self.temp = None\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EZ98pV7F4ctw"},"source":["######## Shuffling Training Dataset for Plausibility Classification ######################\n","#########################################################################\n","\n","import pickle\n","\n","with open(project_path+'Pickles/Plausibility_Classification_Roberta_1/pickle_shuffled_train_clarification_single_filler_dataset_2Sent_2.pickle', 'rb') as f:\n","  shuffled_train_dataset = pickle.load(f)\n","  #pickle.dump((test_df['labels'],predictions),f)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T5gyjQ3FjUJd"},"source":["import pickle\n","\n","with open(project_path+'Pickles/Plausibility_Classification_Roberta_1/pickle_train_clarification_single_filler_dataset_2Sent_2.pickle', 'rb') as f:\n","  train_dataset = pickle.load(f)\n","  #pickle.dump((test_df['labels'],predictions),f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EeWHCErDz2kz"},"source":["import pickle\n","\n","with open(project_path+'Pickles/Plausibility_Classification_Roberta_1/pickle_valid_clarification_single_filler_dataset_2Sent_2.pickle', 'rb') as f:\n","  val_dataset = pickle.load(f)\n","  #pickle.dump((test_df['labels'],predictions),f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ja9xsfbkOUbD"},"source":["'''\n","import pickle\n","\n","with open(project_path+'Pickles/pickle_valid_puzzle_shuffled_1000_dataset_1.pickle', 'rb') as f:\n","  shuffled_val_dataset = pickle.load(f)\n","  #pickle.dump((test_df['labels'],predictions),f)\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QVXCtnSBjW5P"},"source":["import pickle\n","\n","with open(project_path+'Pickles/Plausibility_Classification_Roberta_1/pickle_valid_small_clarification_single_filler_dataset_2Sent_2.pickle', 'rb') as f:\n","  val_small_dataset = pickle.load(f)\n","  #pickle.dump((test_df['labels'],predictions),f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KEX_2Di5jZFM"},"source":["\n","import pickle\n","\n","with open(project_path+'Pickles/Plausibility_Classification_Roberta_1/pickle_test_clarification_single_filler_dataset_2Sent_2.pickle', 'rb') as f:\n","  test_dataset = pickle.load(f)\n","  #pickle.dump((test_df['labels'],predictions),f)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XTNsqVdCBlzb","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["52345ff5a81444a8ad467674bd5dd735","d4e3dc1929c34f6f920fd54816d44473","699cb00c6c6d424586c19bf67c2c6355","b8beca9aa048492c8f6534bbed178f44","55b4f686272a4d0f87370b3c74b32225","58e728d168bc4d42893245177f497435","abf56ecadd054bbd805aef3490810842","e5d1503493e841818b1579c3b935cd40","ad49dbb109124865ace47d2b56bda35f","a60eb1350f174da2bbcd9143c915ed7c","1e518dced0894f1f97e7b4d96f22c001","51b216fdc5b645128f6ffb749a0427c8","0ff974ebee52412fbf5d28c2e1044eb7","e56469828f8f45ae918fc794484762d6","211fd04467aa459ebc1f455836adaebf","ad1aede8ac074c8480f79a0af181bdfd","5d2298ac289f4ef78ceddc7f46517388","a861f815340c4507afc046679a7a17e0","2fa5278e72224070b699a429474c3437","3a1aa267188a46ceb512c148500557f6","5bb214a3a385416e915402c246b60e43","7cdf625baa304093ba45b57a928245ca","d2055937f7b84bdf85aaa9d718b47fcd","1b6d034f1aee4331bd7def3d1e2d775c","e1a13a1dc89049f1842dc18feb9fc8cc","ea1b1474d0424f8faf0e38c02229c86a","533b8ca876bb491baed5667ec87c2df0","ca0c02e449ae45789d5dbe4d2aa4275b","55a5b7144fce49789d9611ed3aff6802","e832f9589f454cd5a02656faa0401ed8","8e63601a7d9c4fe9a0da0fdbb477fc41","d589eb7cc727497ba6c534a719aa3923","a79c3cb3ced64de083d1671335f9fed7","6c99b84215dc47a09c794d6a8d687a55","79e6108927324614aa594efef7632988","f0e9c9ef17e74f7f894a1824b94abe34","ae918d8a52bb46ef996a26a54c762291","3c45ccbb5dbb407fbf5af4fcdd8c70a3","56f21ada06bc44b1b3653dcec8dbff23","c1ea160fb83b491b8ad56605ad8a81c9","a243d76dee3142b7bb67915219187f30","58ed6fa783ff45dc98bebe518073a50b","3cc6144297754d8491d1815d5effdbbf","74288cb8381440519283445e1dbdf661"]},"executionInfo":{"status":"ok","timestamp":1637235665816,"user_tz":480,"elapsed":9969,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"d380b3c6-00c3-481a-cf84-1b7b143e7834"},"source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained('textattack/bert-base-uncased-MNLI')    #('microsoft/deberta-large-mnli') #, skip_special_tokens=True)\n","\n","#special_tokens_dict = {'additional_special_tokens': ['[SEP]','[FILLER]','[\\FILLER]']}\n","#num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"52345ff5a81444a8ad467674bd5dd735","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"51b216fdc5b645128f6ffb749a0427c8","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/630 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d2055937f7b84bdf85aaa9d718b47fcd","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6c99b84215dc47a09c794d6a8d687a55","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aETyN_olnOGA","executionInfo":{"status":"ok","timestamp":1637195415041,"user_tz":480,"elapsed":160,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"4ddd779e-480f-49a6-d513-cf5c7f885446"},"source":["'''\n","decoder_tokenizer.cls_token = decoder_tokenizer.bos_token\n","decoder_tokenizer.sep_token = decoder_tokenizer.eos_token\n","decoder_tokenizer.pad_token = decoder_tokenizer.eos_token\n","encoder_tokenizer.pad_token = decoder_tokenizer.eos_token\n","'''\n","\n","print(tokenizer.cls_token,tokenizer.sep_token,tokenizer.bos_token,tokenizer.eos_token,tokenizer.pad_token,tokenizer.sep_token_id,tokenizer.pad_token_id)\n","print(tokenizer.special_tokens_map)\n","#print(decoder_tokenizer.cls_token,decoder_tokenizer.sep_token,decoder_tokenizer.bos_token,decoder_tokenizer.eos_token,decoder_tokenizer.pad_token,decoder_tokenizer.sep_token_id,decoder_tokenizer.pad_token_id)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using bos_token, but it is not set yet.\n","Using eos_token, but it is not set yet.\n"]},{"output_type":"stream","name":"stdout","text":["[CLS] [SEP] None None [PAD] 102 0\n","{'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}\n"]}]},{"cell_type":"code","metadata":{"id":"STcaFc6xJMOR","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["3a2dbfb2c1a84d3c9a17c041a7a98629","55cb62b359844edc90920eaca914e9d2","f424091fde0c44bf874aacd6a9bafcac","4ee57cbc19054214a7ac42e547ee09c2","6436144838a946a292ae759133b1f122","ea4f744c22b6475d8b3af9c4629ed00d","aee84de5db554284a6e8f5784306cfd3","f9391fad7ece416abf6a4470ef83dad5","0ec2b151dd374b03927989b830621c3d","efc11343e46f45a8b621b086cb07516f","a048a1032ddc4d869f604562af3a012d"]},"executionInfo":{"status":"ok","timestamp":1637195473617,"user_tz":480,"elapsed":26752,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"ec1b71fe-2279-44a4-f3e4-8225b0d74dce"},"source":["'''\n","from transformers import AutoModelForSequenceClassification\n","\n","roberta_new = AutoModelForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-MNLI\",num_labels=3)\n","\n","\n","#print(roberta_new.get_input_embeddings())\n","\n","#roberta_new.resize_token_embeddings(len(tokenizer))\n","\n","#print(roberta_new.get_input_embeddings())\n","\n","roberta_new.save_pretrained(project_path+'Saved_Models/PLAUSIBILITY_CLASSIFICATION_ROBERTA_3/')\n","'''\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3a2dbfb2c1a84d3c9a17c041a7a98629","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/418M [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"6HsV4dm8j9qT"},"source":["from transformers import AutoModelForSequenceClassification\n","model = AutoModelForSequenceClassification.from_pretrained(project_path+'Saved_Models/PLAUSIBILITY_CLASSIFICATION_ROBERTA_3/',num_labels=3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pMamweLLLhWz","executionInfo":{"status":"ok","timestamp":1637195476262,"user_tz":480,"elapsed":29,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"571910d2-ede4-48e6-c750-1408ab6c7efc"},"source":["#model.config.decoder.add_cross_attention=True\n","#print(model.config.decoder)\n","print(model.get_input_embeddings())\n","print(model.config.pad_token_id)\n","#model.save_pretrained(project_path+'Saved_Models/BertGPT_2_decoder_cross_attention')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Embedding(30522, 768, padding_idx=0)\n","0\n"]}]},{"cell_type":"code","metadata":{"id":"cWzHwcz6BEeo"},"source":["#led_tokenizer = AutoTokenizer.from_pretrained(\"allenai/led-base-16384\")\n","#led_model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/led-base-16384\", gradient_checkpointing=True, use_cache=False,)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":800},"id":"MmYQNbcc44J4","executionInfo":{"status":"ok","timestamp":1637235689789,"user_tz":480,"elapsed":10366,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"74afabe2-308d-4ac7-84b6-14e584688da0"},"source":["!pip install datasets==1.2.1\n","!pip install rouge_score"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets==1.2.1\n","  Downloading datasets-1.2.1-py3-none-any.whl (159 kB)\n","\u001b[?25l\r\u001b[K     |██                              | 10 kB 24.0 MB/s eta 0:00:01\r\u001b[K     |████                            | 20 kB 24.8 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 30 kB 24.1 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 40 kB 19.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 51 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 61 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 71 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 81 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 92 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 102 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 112 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 122 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 133 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 143 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 153 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 159 kB 12.4 MB/s \n","\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (0.70.12.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (1.19.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (4.8.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (1.1.5)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (2.23.0)\n","Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (3.0.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (0.3.4)\n","Collecting tqdm<4.50.0,>=4.27\n","  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n","\u001b[K     |████████████████████████████████| 69 kB 7.1 MB/s \n","\u001b[?25hCollecting xxhash\n","  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n","\u001b[K     |████████████████████████████████| 243 kB 40.3 MB/s \n","\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.2.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.2.1) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.2.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.2.1) (2.10)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==1.2.1) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==1.2.1) (3.10.0.2)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.2.1) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.2.1) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.2.1) (1.15.0)\n","Installing collected packages: xxhash, tqdm, datasets\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.62.3\n","    Uninstalling tqdm-4.62.3:\n","      Successfully uninstalled tqdm-4.62.3\n","Successfully installed datasets-1.2.1 tqdm-4.49.0 xxhash-2.0.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tqdm"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting rouge_score\n","  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.19.5)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.15.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge_score) (0.12.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge_score) (3.2.5)\n","Installing collected packages: rouge-score\n","Successfully installed rouge-score-0.0.4\n"]}]},{"cell_type":"code","metadata":{"id":"f7M0Ok_QAaHI","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["23bd46b99c89418999ac75c0a83acd3c","2a53d398e73245449f287c42bc15c8ce","7e4def0603e744fb883295bd48634587","a527afd7a9c1424a920283a8b96cfddd","11592961c887443c9711aa11d3931b00","7ea96dc7c54846749a8ad9a10d7015ea","d185a0ff82f64f71a861b2d2ce28dec7","0f37c8ce6ad94d25b8cae3c834716081","669d3bee449d498d9472d66ba6def250","be65334abfa84a7d84feec15f86f93a5","0139398eaa8a45a58c05b6594fa43100"]},"executionInfo":{"status":"ok","timestamp":1637235691202,"user_tz":480,"elapsed":1419,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"262f0283-c94d-4aa1-ca2c-e37780a69c77"},"source":["#from transformers import logging ################\n","#logging.set_verbosity_info() #####################\n","\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","\n","from datasets import load_dataset, load_metric\n","from transformers import (\n","    Trainer,\n","    TrainingArguments,\n","    AutoTokenizer,\n",")\n","\n","#tokenizer = tokenizer\n","\n","# load rouge\n","metric = load_metric(\"accuracy\")\n","\n","# compute Rouge score during validation\n","def compute_metrics(pred):\n","    logits, labels = pred\n","    predictions = np.argmax(logits, axis=-1)\n","\n","    accuracy = metric.compute(predictions=predictions, references=labels)['accuracy']\n","\n","    micro_f1 = f1_score(labels, predictions, average='micro')\n","    macro_f1 = f1_score(labels, predictions, average='macro')\n","    weighted_f1 = f1_score(labels, predictions, average='weighted')\n","\n","\n","\n","    return {\n","        \"Accuracy\": accuracy,\n","        \"micro_F1\": round(micro_f1, 4),\n","        \"macro_F1\": round(macro_f1, 4),\n","        \"weighted_F1\": round(weighted_f1, 4),\n","    }\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"23bd46b99c89418999ac75c0a83acd3c","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.25k [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":974},"id":"9RKQPr9zbjFE","executionInfo":{"status":"ok","timestamp":1637235706336,"user_tz":480,"elapsed":15144,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKWPYm_DG9HFs1oug5YfZeU-Z_e2iNrLAL0ZgdCw=s64","userId":"15048921894640499370"}},"outputId":"c20dc3a9-fc63-48fd-cf71-6a154941f166"},"source":["!pip install wandb\n","\n","import wandb\n","wandb.login()\n","\n","%env WANDB_PROJECT=Plausibility_Clarification_RoBerta_Training_2Sent_2"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wandb\n","  Downloading wandb-0.12.6-py2.py3-none-any.whl (1.7 MB)\n","\u001b[?25l\r\u001b[K     |▏                               | 10 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |▋                               | 30 kB 21.7 MB/s eta 0:00:01\r\u001b[K     |▉                               | 40 kB 17.3 MB/s eta 0:00:01\r\u001b[K     |█                               | 51 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 61 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 71 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 81 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 92 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██                              | 102 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 112 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 122 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 133 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 143 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 153 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 163 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 174 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 184 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 194 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 204 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 215 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 225 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 235 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 245 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 256 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 266 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 276 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 286 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 296 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 307 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 317 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 327 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 337 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 348 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 358 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 368 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 378 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 389 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 399 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 409 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 419 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 430 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 440 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 450 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 460 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 471 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 481 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 491 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 501 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 512 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 522 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 532 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 542 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 552 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 563 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 573 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 583 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 593 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 604 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 614 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 624 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 634 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 645 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 655 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 665 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 675 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 686 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 696 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 706 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 716 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 727 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 737 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 747 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 757 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 768 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 778 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 788 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 798 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 808 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 819 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 829 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 839 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 849 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 860 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 870 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 880 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 890 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 901 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 911 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 921 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 931 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 942 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 952 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 962 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 972 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 983 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 993 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.0 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.0 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.0 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.0 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.0 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.1 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.1 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.1 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.1 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.1 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.1 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.1 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.1 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.1 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.2 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.2 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.2 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.2 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.2 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.2 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.2 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.2 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.2 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.3 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.3 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.3 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.3 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.3 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.3 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.3 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.3 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.4 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.4 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.4 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.4 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.4 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.4 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.4 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.4 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.4 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.4 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.5 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.5 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.5 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.5 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.5 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.5 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.5 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.5 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.5 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.5 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.6 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.6 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.6 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.6 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.6 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.6 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.6 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.6 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.6 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.6 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.7 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.7 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7 MB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7 MB 11.1 MB/s \n","\u001b[?25hCollecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Collecting yaspin>=1.0.0\n","  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.5.0-py2.py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 46.7 MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Collecting configparser>=3.8.1\n","  Downloading configparser-5.1.0-py3-none-any.whl (19 kB)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n","\u001b[K     |████████████████████████████████| 180 kB 53.1 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Collecting subprocess32>=3.5.3\n","  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 6.6 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n","Building wheels for collected packages: subprocess32, pathtools\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=14250b2ae5ed4b1c3d51c1ea5630dfd892ed077f2795086c280da8d07e249ff4\n","  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=e669214df5b6900ad6447e83636258e8fb4fcaf9f1e24939b057ce32c1cc3a3c\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built subprocess32 pathtools\n","Installing collected packages: smmap, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n","Successfully installed GitPython-3.1.24 configparser-5.1.0 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.0 shortuuid-1.0.8 smmap-5.0.0 subprocess32-3.5.4 wandb-0.12.6 yaspin-2.1.0\n"]},{"output_type":"display_data","data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"stream","name":"stdout","text":["env: WANDB_PROJECT=Plausibility_Clarification_RoBerta_Training_2Sent_2\n"]}]},{"cell_type":"code","metadata":{"id":"z3u4_AvV5ysj"},"source":["batch_size = 8 ####################\n","\n","\n","\n","training_args = TrainingArguments(\n","    evaluation_strategy=\"steps\",\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    #fp16=True,\n","    #fp16_backend=\"apex\",\n","    output_dir=project_path+'Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/',\n","    logging_dir = project_path+'Saved_Logs/Training_1/Plausibility_Classification_Roberta_2Sent_2/',\n","    num_train_epochs = 20,  ##########################################################\n","    logging_steps=10, #250,\n","    eval_steps=50,  # 200, #5000,\n","    save_steps=50, #200, #500,\n","    warmup_steps=1, #1500,\n","    #save_total_limit=2,\n","    gradient_accumulation_steps=4, ############################################################\n","    load_best_model_at_end = False,\n","    #resume_from_checkpoint = project_path+'Saved_Models/Training_1/checkpoint-1500',\n","    report_to=\"wandb\",  # enable logging to W&B\n","    run_name=\"plausibility-classification-RoBerta-2Sent-2-run-1\",  # name of the W&B run (optional)\n",")\n","\n","\n","# BEST TO ME by Accuracy (project_path+'Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1050')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PgKdrbAGTVun","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["19aa5ab11a654963acf13242aca9af58","e2060577fc1748f58ebdb6a6b1efa0a2","f3f75d8af49343edbf11f7499bd747ee","f4aefafdc0564eccbcd359ca2de5cdae","8cea44f18f8a4d34a97530a5a495f839","9c0cabb997144e1fa0ae9359184cfed1","f112ecb120d44a0889b774ba3cf3232d","7d8d076ed1d64bdaa3b1cbc7140e131f","fa3e5abc67c04043a3dcd6e926594984","aa9620d86a00475592ff7166d00c31f4","5e8651435020488bb86a0c4717e52e8a"]},"outputId":"c9e2e661-3852-40dc-d892-17eba60e17ae"},"source":["# instantiate trainer BATCH SIZE = 8 ############\n","trainer = Trainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    #data_collator=data_collator,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    train_dataset= shuffled_train_dataset,  #train_dataset,  ########################################\n","    eval_dataset=test_dataset,  # val_dataset, \n",")\n","\n","# start training\n","#trainer.train()\n","trainer.train(project_path+'Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1750')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Loading model from /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1750).\n","***** Running training *****\n","  Num examples = 17960\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 4\n","  Total optimization steps = 11220\n","  Continuing training from checkpoint, will skip to saved global_step\n","  Continuing training from epoch 3\n","  Continuing training from global step 1750\n","  Will skip the first 3 epochs then the first 268 batches in the first epoch. If this takes a lot of time, you can add the `--ignore_data_skip` flag to your launch command, but you will resume the training on data already seen by your model.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"19aa5ab11a654963acf13242aca9af58","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/268 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtawkat\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_RoBerta_Training_2Sent_2/runs/2vk9ftcm\" target=\"_blank\">plausibility-classification-RoBerta-2Sent-2-run-1</a></strong> to <a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_RoBerta_Training_2Sent_2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3196' max='11220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 3196/11220 3:41:32 < 20:31:01, 0.11 it/s, Epoch 5.69/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Micro F1</th>\n","      <th>Macro F1</th>\n","      <th>Weighted F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.591400</td>\n","      <td>1.387740</td>\n","      <td>0.426000</td>\n","      <td>0.426000</td>\n","      <td>0.418400</td>\n","      <td>0.450800</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.562700</td>\n","      <td>1.426294</td>\n","      <td>0.423200</td>\n","      <td>0.423200</td>\n","      <td>0.412400</td>\n","      <td>0.449800</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.626200</td>\n","      <td>1.371451</td>\n","      <td>0.460400</td>\n","      <td>0.460400</td>\n","      <td>0.428400</td>\n","      <td>0.470800</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.697600</td>\n","      <td>1.317463</td>\n","      <td>0.473200</td>\n","      <td>0.473200</td>\n","      <td>0.437800</td>\n","      <td>0.484700</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.624800</td>\n","      <td>1.339172</td>\n","      <td>0.422000</td>\n","      <td>0.422000</td>\n","      <td>0.413700</td>\n","      <td>0.448300</td>\n","    </tr>\n","    <tr>\n","      <td>2050</td>\n","      <td>0.653900</td>\n","      <td>1.368950</td>\n","      <td>0.460400</td>\n","      <td>0.460400</td>\n","      <td>0.428400</td>\n","      <td>0.474700</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>0.665000</td>\n","      <td>1.344016</td>\n","      <td>0.439200</td>\n","      <td>0.439200</td>\n","      <td>0.415300</td>\n","      <td>0.455300</td>\n","    </tr>\n","    <tr>\n","      <td>2150</td>\n","      <td>0.697300</td>\n","      <td>1.251236</td>\n","      <td>0.471600</td>\n","      <td>0.471600</td>\n","      <td>0.442900</td>\n","      <td>0.486200</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>0.671900</td>\n","      <td>1.406070</td>\n","      <td>0.479200</td>\n","      <td>0.479200</td>\n","      <td>0.427800</td>\n","      <td>0.478900</td>\n","    </tr>\n","    <tr>\n","      <td>2250</td>\n","      <td>0.565500</td>\n","      <td>1.472640</td>\n","      <td>0.407600</td>\n","      <td>0.407600</td>\n","      <td>0.407000</td>\n","      <td>0.436900</td>\n","    </tr>\n","    <tr>\n","      <td>2300</td>\n","      <td>0.405200</td>\n","      <td>1.697509</td>\n","      <td>0.422400</td>\n","      <td>0.422400</td>\n","      <td>0.406800</td>\n","      <td>0.439200</td>\n","    </tr>\n","    <tr>\n","      <td>2350</td>\n","      <td>0.502600</td>\n","      <td>1.676445</td>\n","      <td>0.457200</td>\n","      <td>0.457200</td>\n","      <td>0.424800</td>\n","      <td>0.469100</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>0.421500</td>\n","      <td>1.746106</td>\n","      <td>0.441200</td>\n","      <td>0.441200</td>\n","      <td>0.413100</td>\n","      <td>0.454200</td>\n","    </tr>\n","    <tr>\n","      <td>2450</td>\n","      <td>0.493600</td>\n","      <td>1.741383</td>\n","      <td>0.366800</td>\n","      <td>0.366800</td>\n","      <td>0.366200</td>\n","      <td>0.387900</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.519100</td>\n","      <td>1.663265</td>\n","      <td>0.421600</td>\n","      <td>0.421600</td>\n","      <td>0.414100</td>\n","      <td>0.446200</td>\n","    </tr>\n","    <tr>\n","      <td>2550</td>\n","      <td>0.513900</td>\n","      <td>1.515123</td>\n","      <td>0.455600</td>\n","      <td>0.455600</td>\n","      <td>0.422800</td>\n","      <td>0.467200</td>\n","    </tr>\n","    <tr>\n","      <td>2600</td>\n","      <td>0.491200</td>\n","      <td>1.604340</td>\n","      <td>0.461200</td>\n","      <td>0.461200</td>\n","      <td>0.430400</td>\n","      <td>0.473400</td>\n","    </tr>\n","    <tr>\n","      <td>2650</td>\n","      <td>0.528400</td>\n","      <td>1.540530</td>\n","      <td>0.446400</td>\n","      <td>0.446400</td>\n","      <td>0.429500</td>\n","      <td>0.468500</td>\n","    </tr>\n","    <tr>\n","      <td>2700</td>\n","      <td>0.494800</td>\n","      <td>1.643579</td>\n","      <td>0.462000</td>\n","      <td>0.462000</td>\n","      <td>0.433400</td>\n","      <td>0.479200</td>\n","    </tr>\n","    <tr>\n","      <td>2750</td>\n","      <td>0.457700</td>\n","      <td>1.686218</td>\n","      <td>0.428800</td>\n","      <td>0.428800</td>\n","      <td>0.413200</td>\n","      <td>0.448500</td>\n","    </tr>\n","    <tr>\n","      <td>2800</td>\n","      <td>0.539500</td>\n","      <td>1.596700</td>\n","      <td>0.429200</td>\n","      <td>0.429200</td>\n","      <td>0.405800</td>\n","      <td>0.441400</td>\n","    </tr>\n","    <tr>\n","      <td>2850</td>\n","      <td>0.321700</td>\n","      <td>2.012587</td>\n","      <td>0.448000</td>\n","      <td>0.448000</td>\n","      <td>0.423900</td>\n","      <td>0.465300</td>\n","    </tr>\n","    <tr>\n","      <td>2900</td>\n","      <td>0.334300</td>\n","      <td>2.152343</td>\n","      <td>0.390400</td>\n","      <td>0.390400</td>\n","      <td>0.393600</td>\n","      <td>0.416900</td>\n","    </tr>\n","    <tr>\n","      <td>2950</td>\n","      <td>0.373300</td>\n","      <td>1.817939</td>\n","      <td>0.472000</td>\n","      <td>0.472000</td>\n","      <td>0.429700</td>\n","      <td>0.470900</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.341000</td>\n","      <td>1.847535</td>\n","      <td>0.473200</td>\n","      <td>0.473200</td>\n","      <td>0.429300</td>\n","      <td>0.473500</td>\n","    </tr>\n","    <tr>\n","      <td>3050</td>\n","      <td>0.379000</td>\n","      <td>1.813369</td>\n","      <td>0.442000</td>\n","      <td>0.442000</td>\n","      <td>0.429500</td>\n","      <td>0.466900</td>\n","    </tr>\n","    <tr>\n","      <td>3100</td>\n","      <td>0.367700</td>\n","      <td>1.967909</td>\n","      <td>0.438400</td>\n","      <td>0.438400</td>\n","      <td>0.419400</td>\n","      <td>0.457700</td>\n","    </tr>\n","    <tr>\n","      <td>3150</td>\n","      <td>0.363500</td>\n","      <td>1.894276</td>\n","      <td>0.466400</td>\n","      <td>0.466400</td>\n","      <td>0.434500</td>\n","      <td>0.480200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1800\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1800/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1800/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1800/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1800/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1850\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1850/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1850/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1850/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1850/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1900\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1900/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1900/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1900/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1900/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1950\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1950/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1950/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1950/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1950/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2000\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2000/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2000/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2050\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2050/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2050/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2050/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2050/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2100\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2100/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2100/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2100/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2100/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2150\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2150/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2150/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2150/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2150/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2200\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2200/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2200/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2200/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2200/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2250\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2250/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2250/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2250/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2250/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2300\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2300/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2300/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2300/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2300/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2350\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2350/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2350/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2350/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2350/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2400\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2400/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2400/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2400/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2400/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2450\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2450/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2450/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2450/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2450/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2500\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2500/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2500/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2500/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2550\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2550/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2550/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2550/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2550/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2600\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2600/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2600/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2600/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2600/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2650\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2650/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2650/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2650/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2650/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2700\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2700/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2700/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2700/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2700/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2750\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2750/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2750/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2750/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2750/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2800\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2800/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2800/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2800/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2800/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2850\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2850/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2850/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2850/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2850/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2900\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2900/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2900/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2900/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2900/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2950\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2950/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2950/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2950/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-2950/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-3000\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-3000/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-3000/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-3000/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-3000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-3050\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-3050/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-3050/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-3050/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-3050/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-3100\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-3100/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-3100/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-3100/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-3100/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-3150\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-3150/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-3150/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-3150/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-3150/special_tokens_map.json\n"]}]},{"cell_type":"code","metadata":{"id":"ZiQMXgz4YCBK","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ca6f1ac354cc46f0908aafe38153169e","c218d9b79e0d4c8cb2a0eed53dd7b408","5b334d5c6fc44a17bbd028c1cf9f852f","ff608fc8b46b4b8eb69d176f89ccec0a","d80ee9d46d7d477599b6c730a3db8137","35eb604a76f34c1a9f725d236b9ba111","e0d2cd666716461295089890803eba32","2e7aa5664cc042be86cdb063b15e58db","c22fb2ebd1dd4784ab0bba5aa7b5e68a","0fb183a2e46b40aab309c1057035c059","5a225d06e68442fd96dc5b7ccad4d479"]},"outputId":"c3d0a7ee-0d50-42c8-ebdc-759247c06019"},"source":["# instantiate trainer BATCH SIZE = 8 ############\n","trainer = Trainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    #data_collator=data_collator,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    train_dataset= shuffled_train_dataset,  #train_dataset,  ########################################\n","    eval_dataset=test_dataset,  # val_dataset, \n",")\n","\n","# start training\n","#trainer.train()\n","trainer.train(project_path+'Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-450')"],"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Loading model from /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-450).\n","***** Running training *****\n","  Num examples = 17960\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 4\n","  Total optimization steps = 11220\n","  Continuing training from checkpoint, will skip to saved global_step\n","  Continuing training from epoch 0\n","  Continuing training from global step 450\n","  Will skip the first 0 epochs then the first 1800 batches in the first epoch. If this takes a lot of time, you can add the `--ignore_data_skip` flag to your launch command, but you will resume the training on data already seen by your model.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca6f1ac354cc46f0908aafe38153169e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1800 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtawkat\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_RoBerta_Training_2Sent_2/runs/15dby4aj\" target=\"_blank\">plausibility-classification-RoBerta-2Sent-2-run-1</a></strong> to <a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_RoBerta_Training_2Sent_2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='932' max='11220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [  932/11220 1:17:10 < 27:34:01, 0.10 it/s, Epoch 1.66/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Micro F1</th>\n","      <th>Macro F1</th>\n","      <th>Weighted F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>1.040100</td>\n","      <td>1.058453</td>\n","      <td>0.496400</td>\n","      <td>0.496400</td>\n","      <td>0.390500</td>\n","      <td>0.460200</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>1.062700</td>\n","      <td>1.056384</td>\n","      <td>0.498000</td>\n","      <td>0.498000</td>\n","      <td>0.387700</td>\n","      <td>0.459000</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>1.011800</td>\n","      <td>1.185765</td>\n","      <td>0.344400</td>\n","      <td>0.344400</td>\n","      <td>0.343500</td>\n","      <td>0.365700</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.938500</td>\n","      <td>1.096451</td>\n","      <td>0.493200</td>\n","      <td>0.493200</td>\n","      <td>0.421800</td>\n","      <td>0.480000</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.950600</td>\n","      <td>1.100811</td>\n","      <td>0.436000</td>\n","      <td>0.436000</td>\n","      <td>0.421600</td>\n","      <td>0.462100</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.941700</td>\n","      <td>1.124267</td>\n","      <td>0.420000</td>\n","      <td>0.420000</td>\n","      <td>0.406700</td>\n","      <td>0.443900</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.973300</td>\n","      <td>1.101547</td>\n","      <td>0.452800</td>\n","      <td>0.452800</td>\n","      <td>0.413500</td>\n","      <td>0.457100</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.987500</td>\n","      <td>1.114000</td>\n","      <td>0.353600</td>\n","      <td>0.353600</td>\n","      <td>0.356700</td>\n","      <td>0.369600</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.944900</td>\n","      <td>1.114743</td>\n","      <td>0.440000</td>\n","      <td>0.440000</td>\n","      <td>0.409400</td>\n","      <td>0.454100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-500\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-500/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-550\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-550/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-550/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-550/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-550/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-600\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-600/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-600/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-600/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-600/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-650\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-650/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-650/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-650/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-650/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-700\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-700/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-700/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-700/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-700/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-750\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-750/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-750/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-750/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-750/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-800\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-800/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-800/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-800/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-800/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-850\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-850/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-850/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-850/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-850/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-900\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-900/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-900/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-900/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-900/special_tokens_map.json\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1756' max='11220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 1756/11220 3:34:38 < 25:57:44, 0.10 it/s, Epoch 3.13/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Micro F1</th>\n","      <th>Macro F1</th>\n","      <th>Weighted F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>1.040100</td>\n","      <td>1.058453</td>\n","      <td>0.496400</td>\n","      <td>0.496400</td>\n","      <td>0.390500</td>\n","      <td>0.460200</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>1.062700</td>\n","      <td>1.056384</td>\n","      <td>0.498000</td>\n","      <td>0.498000</td>\n","      <td>0.387700</td>\n","      <td>0.459000</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>1.011800</td>\n","      <td>1.185765</td>\n","      <td>0.344400</td>\n","      <td>0.344400</td>\n","      <td>0.343500</td>\n","      <td>0.365700</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.938500</td>\n","      <td>1.096451</td>\n","      <td>0.493200</td>\n","      <td>0.493200</td>\n","      <td>0.421800</td>\n","      <td>0.480000</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.950600</td>\n","      <td>1.100811</td>\n","      <td>0.436000</td>\n","      <td>0.436000</td>\n","      <td>0.421600</td>\n","      <td>0.462100</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.941700</td>\n","      <td>1.124267</td>\n","      <td>0.420000</td>\n","      <td>0.420000</td>\n","      <td>0.406700</td>\n","      <td>0.443900</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.973300</td>\n","      <td>1.101547</td>\n","      <td>0.452800</td>\n","      <td>0.452800</td>\n","      <td>0.413500</td>\n","      <td>0.457100</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.987500</td>\n","      <td>1.114000</td>\n","      <td>0.353600</td>\n","      <td>0.353600</td>\n","      <td>0.356700</td>\n","      <td>0.369600</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.944900</td>\n","      <td>1.114743</td>\n","      <td>0.440000</td>\n","      <td>0.440000</td>\n","      <td>0.409400</td>\n","      <td>0.454100</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>1.011400</td>\n","      <td>1.096514</td>\n","      <td>0.462800</td>\n","      <td>0.462800</td>\n","      <td>0.392400</td>\n","      <td>0.445800</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.970200</td>\n","      <td>1.131770</td>\n","      <td>0.431200</td>\n","      <td>0.431200</td>\n","      <td>0.386400</td>\n","      <td>0.428500</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>1.000100</td>\n","      <td>1.040842</td>\n","      <td>0.517600</td>\n","      <td>0.517600</td>\n","      <td>0.413800</td>\n","      <td>0.488200</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.954200</td>\n","      <td>1.140611</td>\n","      <td>0.424800</td>\n","      <td>0.424800</td>\n","      <td>0.390600</td>\n","      <td>0.430900</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.794300</td>\n","      <td>1.303227</td>\n","      <td>0.424800</td>\n","      <td>0.424800</td>\n","      <td>0.401800</td>\n","      <td>0.440400</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.799700</td>\n","      <td>1.211991</td>\n","      <td>0.431600</td>\n","      <td>0.431600</td>\n","      <td>0.416800</td>\n","      <td>0.455500</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.816100</td>\n","      <td>1.177088</td>\n","      <td>0.482800</td>\n","      <td>0.482800</td>\n","      <td>0.422600</td>\n","      <td>0.478600</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.820900</td>\n","      <td>1.197433</td>\n","      <td>0.442400</td>\n","      <td>0.442400</td>\n","      <td>0.410900</td>\n","      <td>0.450700</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.817800</td>\n","      <td>1.130154</td>\n","      <td>0.454400</td>\n","      <td>0.454400</td>\n","      <td>0.429900</td>\n","      <td>0.471900</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.839600</td>\n","      <td>1.106789</td>\n","      <td>0.511600</td>\n","      <td>0.511600</td>\n","      <td>0.443000</td>\n","      <td>0.506900</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.819900</td>\n","      <td>1.199392</td>\n","      <td>0.420800</td>\n","      <td>0.420800</td>\n","      <td>0.408300</td>\n","      <td>0.444600</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.817300</td>\n","      <td>1.120925</td>\n","      <td>0.477600</td>\n","      <td>0.477600</td>\n","      <td>0.434700</td>\n","      <td>0.484900</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.821200</td>\n","      <td>1.133324</td>\n","      <td>0.484000</td>\n","      <td>0.484000</td>\n","      <td>0.438100</td>\n","      <td>0.492700</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.850700</td>\n","      <td>1.194712</td>\n","      <td>0.441600</td>\n","      <td>0.441600</td>\n","      <td>0.411300</td>\n","      <td>0.448300</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.806600</td>\n","      <td>1.099771</td>\n","      <td>0.486400</td>\n","      <td>0.486400</td>\n","      <td>0.428700</td>\n","      <td>0.483800</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.606200</td>\n","      <td>1.267013</td>\n","      <td>0.502800</td>\n","      <td>0.502800</td>\n","      <td>0.425800</td>\n","      <td>0.488400</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.570000</td>\n","      <td>1.350038</td>\n","      <td>0.454000</td>\n","      <td>0.454000</td>\n","      <td>0.438300</td>\n","      <td>0.479700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-950\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-950/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-950/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-950/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-950/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1000\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1000/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1050\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1050/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1050/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1050/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1050/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1100\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1100/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1100/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1100/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1100/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1150\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1150/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1150/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1150/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1150/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1200\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1200/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1200/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1200/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1200/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1250\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1250/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1250/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1250/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1250/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1300\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1300/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1300/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1300/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1300/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1350\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1350/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1350/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1350/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1350/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1400\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1400/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1400/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1400/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1400/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1450\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1450/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1450/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1450/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1450/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1500\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1500/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1550\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1550/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1550/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1550/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1550/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1600\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1600/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1600/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1600/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1600/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1650\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1650/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1650/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1650/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1650/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1700\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1700/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1700/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1700/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1700/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1750\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1750/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1750/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1750/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-1750/special_tokens_map.json\n"]}]},{"cell_type":"code","metadata":{"id":"KmmTpD9BjNXM","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"d0aa15ea-f15e-4234-a85f-3a9d8a54f675"},"source":["# instantiate trainer BATCH SIZE = 8 ############\n","trainer = Trainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    #data_collator=data_collator,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    train_dataset= shuffled_train_dataset,  #train_dataset,  ########################################\n","    eval_dataset=test_dataset,  # val_dataset, \n",")\n","\n","# start training\n","trainer.train()\n","#trainer.train(project_path+'Saved_Logs/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-850')"],"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 17960\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 4\n","  Total optimization steps = 11220\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtawkat\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_RoBerta_Training_2Sent_2/runs/6xy6jamn\" target=\"_blank\">plausibility-classification-RoBerta-2Sent-2-run-1</a></strong> to <a href=\"https://wandb.ai/tawkat/Plausibility_Clarification_RoBerta_Training_2Sent_2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='373' max='11220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [  373/11220 1:01:27 < 29:57:00, 0.10 it/s, Epoch 0.66/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Micro F1</th>\n","      <th>Macro F1</th>\n","      <th>Weighted F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>1.126000</td>\n","      <td>1.125398</td>\n","      <td>0.397200</td>\n","      <td>0.397200</td>\n","      <td>0.259300</td>\n","      <td>0.287600</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.088700</td>\n","      <td>1.109450</td>\n","      <td>0.341600</td>\n","      <td>0.341600</td>\n","      <td>0.320800</td>\n","      <td>0.344800</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>1.106000</td>\n","      <td>1.098869</td>\n","      <td>0.341600</td>\n","      <td>0.341600</td>\n","      <td>0.341700</td>\n","      <td>0.359900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.085100</td>\n","      <td>1.115509</td>\n","      <td>0.259600</td>\n","      <td>0.259600</td>\n","      <td>0.245000</td>\n","      <td>0.230400</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>1.102400</td>\n","      <td>1.089324</td>\n","      <td>0.426000</td>\n","      <td>0.426000</td>\n","      <td>0.359000</td>\n","      <td>0.407600</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.096300</td>\n","      <td>1.170471</td>\n","      <td>0.320800</td>\n","      <td>0.320800</td>\n","      <td>0.267100</td>\n","      <td>0.273600</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>1.080900</td>\n","      <td>1.103912</td>\n","      <td>0.402000</td>\n","      <td>0.402000</td>\n","      <td>0.373700</td>\n","      <td>0.411900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-50\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-50/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-50/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-50/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-50/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-100\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-100/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-100/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-100/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-100/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-150\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-150/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-150/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-150/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-150/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-200\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-200/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-200/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-200/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-200/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-250\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-250/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-250/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-250/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-250/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-300\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-300/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-300/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-300/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-300/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-350\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-350/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-350/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-350/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-350/special_tokens_map.json\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='454' max='11220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [  454/11220 1:16:30 < 30:22:27, 0.10 it/s, Epoch 0.81/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Micro F1</th>\n","      <th>Macro F1</th>\n","      <th>Weighted F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>1.126000</td>\n","      <td>1.125398</td>\n","      <td>0.397200</td>\n","      <td>0.397200</td>\n","      <td>0.259300</td>\n","      <td>0.287600</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.088700</td>\n","      <td>1.109450</td>\n","      <td>0.341600</td>\n","      <td>0.341600</td>\n","      <td>0.320800</td>\n","      <td>0.344800</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>1.106000</td>\n","      <td>1.098869</td>\n","      <td>0.341600</td>\n","      <td>0.341600</td>\n","      <td>0.341700</td>\n","      <td>0.359900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.085100</td>\n","      <td>1.115509</td>\n","      <td>0.259600</td>\n","      <td>0.259600</td>\n","      <td>0.245000</td>\n","      <td>0.230400</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>1.102400</td>\n","      <td>1.089324</td>\n","      <td>0.426000</td>\n","      <td>0.426000</td>\n","      <td>0.359000</td>\n","      <td>0.407600</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.096300</td>\n","      <td>1.170471</td>\n","      <td>0.320800</td>\n","      <td>0.320800</td>\n","      <td>0.267100</td>\n","      <td>0.273600</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>1.080900</td>\n","      <td>1.103912</td>\n","      <td>0.402000</td>\n","      <td>0.402000</td>\n","      <td>0.373700</td>\n","      <td>0.411900</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.049000</td>\n","      <td>1.110391</td>\n","      <td>0.467200</td>\n","      <td>0.467200</td>\n","      <td>0.281800</td>\n","      <td>0.355100</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>1.064400</td>\n","      <td>1.126935</td>\n","      <td>0.315600</td>\n","      <td>0.315600</td>\n","      <td>0.321500</td>\n","      <td>0.331800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-400\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-400/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-400/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-400/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-400/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 2500\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-450\n","Configuration saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-450/config.json\n","Model weights saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-450/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-450/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Machine Learning/UBC/CPSC_503/SemEval22_T7/Saved_Models/Training_1/Plausibility_Classification_Roberta_2Sent_2/checkpoint-450/special_tokens_map.json\n"]}]},{"cell_type":"markdown","metadata":{"id":"FMkR5GX8qEIB"},"source":["# **Testing**"]},{"cell_type":"code","metadata":{"id":"lSJ7XnOTwP2g"},"source":["class_names = [\"IMPLAUSIBLE\", \"NEUTRAL\", \"PLAUSIBLE\"]\n","\n","LABEL_DICT = {}\n","LABEL_DICT[class_names[0]] = 0\n","LABEL_DICT[class_names[1]] = 1\n","LABEL_DICT[class_names[2]] = 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"to0VNWg5GMti","executionInfo":{"status":"ok","timestamp":1625751778126,"user_tz":-360,"elapsed":429,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"a2ccccfd-25e1-4629-c1be-44f3fcd424c2"},"source":["print(tokenizer.batch_decode(train_dataset[499:500]['input_ids']))\n","\n","labels_ids = train_dataset[499:500]['labels']#[test_dataset[499:500]['labels'] == -100] = tokenizer.pad_token_id\n","labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n","#print(labels_ids)\n","output = tokenizer.batch_decode(labels_ids, skip_special_tokens=False)\n","print(output[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[\"solve: def sat(x: List[int], a: int=-165, r: int=1, l: int=42): assert type(x) is list and all(type(a) is int for a in x), 'x must be of type List[int]' return x[0] == a and len(x) == l and all([x[i] * r == x[i + 1] for i in range(len(x) - 1)])</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\"]\n","sol(a=-165, r=1, l=42): return [a * r ** i for i in range(l)]</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AUCrq4edW5j3","executionInfo":{"status":"ok","timestamp":1625751805282,"user_tz":-360,"elapsed":452,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"a2743cbd-eb9a-4148-af60-5bbae0b62f74"},"source":["print(tokenizer.special_tokens_map)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': \"['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']\"}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BinEuSh8YNuf"},"source":["accuracy = Accuracy(actual_str,output_str)\n","sommth_bleu_score = round(_bleu(actual_str, output_str),2)\n","\n","print(accuracy)\n","print(sommth_bleu_score)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gkSfUBOkDlId"},"source":["from transformers import AutoModelForSequenceClassification\n","model = AutoModelForSequenceClassification.from_pretrained(project_path+'Saved_Models/Training_1/Plausibility_Classification_Roberta_1/checkpoint-850',num_labels=3)\n","model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mq4qCzaGCn_V"},"source":["start = 200\n","end = 210\n","model.eval()\n","outputs = model(input_ids=test_dataset[start:end]['input_ids'].to(device),attention_mask=test_dataset[start:end]['attention_mask'].to(device))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-dG9P0chEGMJ","executionInfo":{"status":"ok","timestamp":1636787048297,"user_tz":480,"elapsed":621,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12040636431562290492"}},"outputId":"e43eb3a5-481b-4fac-b44f-f708c5ccff4c"},"source":["print(np.argmax(outputs.logits.detach().cpu().numpy(),axis=1))\n","print(test_dataset[start:end]['labels'])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2 2 2 2 2 2 2 2 2 2]\n","tensor([0, 0, 1, 2, 1, 0, 1, 0, 0, 2])\n"]}]},{"cell_type":"code","metadata":{"id":"JTPCopoGZzTd"},"source":["total_output_str=[]\n","batch_size = 100\n","\n","curr = 0\n","for i in range(0,len(test_dataset),batch_size):\n","  end = min(i+batch_size,len(test_dataset))\n","  code_tokens = ed.generate(input_ids=test_dataset[i:end]['input_ids'].to(device),attention_mask=test_dataset[i:end]['attention_mask'].to(device))\n","  \n","  codes = decoder_tokenizer.batch_decode(code_tokens,skip_special_tokens=True)\n","\n","  for c in codes:\n","    total_output_str.append(c)\n","  print(i)\n","  if(end == len(test_dataset)):\n","    break\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RwXy5K__TnQ1","executionInfo":{"status":"ok","timestamp":1624463170470,"user_tz":-360,"elapsed":12,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"b288768f-b9c7-4541-8ad5-17bf675fd7cd"},"source":["print(len(total_output_str))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["6545\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XnxauUisXJ14"},"source":["class Example(object):\n","    \"\"\"A single training/test example.\"\"\"\n","    def __init__(self,\n","                 idx,\n","                 source,\n","                 target,\n","                 ):\n","        self.idx = idx\n","        self.source = source\n","        self.target = target"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r1haZjJ8Xe8E"},"source":["import pickle\n","with open(project_path+'Pickles/pickle_test_buggy_fixed_1.pickle', 'rb') as f:\n","  test_examples = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K5vm5E9gXgfR","executionInfo":{"status":"ok","timestamp":1624463170958,"user_tz":-360,"elapsed":15,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"296d3f96-a55a-463f-b3fe-41be9de8f284"},"source":["total_actual_str=[]\n","\n","for te in test_examples:\n","  total_actual_str.append(te.target)\n","\n","print(len(total_actual_str))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["6545\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bFQg6nPQnmKh"},"source":["import pickle\n","with open(project_path+'Pickles/pickle_pred_test_buggy_fixed_13000_1.pickle', 'wb') as f:\n","  pickle.dump((total_actual_str,total_output_str),f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D6m6Eu4uoEUl"},"source":["import pickle\n","with open(project_path+'Pickles/pickle_pred_test_buggy_fixed_13000_1.pickle', 'rb') as f:\n","  total_actual_str,total_output_str = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bDwUATPdX0JK","executionInfo":{"status":"ok","timestamp":1624464471028,"user_tz":-360,"elapsed":414,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"a8eca143-6574-43a2-db93-e0e02885563d"},"source":["print(total_actual_str[100])\n","print(total_output_str[100])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["public void METHOD_1 ( ) { TYPE_1 query = new TYPE_1 ( ) ; TYPE_2 VAR_1 = TYPE_3 . METHOD_2 ( VAR_2 class ) ; TYPE_3 . METHOD_3 ( VAR_1 . getId ( ) ) . METHOD_4 ( 1 ) ; TYPE_3 . METHOD_5 ( VAR_1 ) ; java.lang.Long count = VAR_3 . METHOD_6 ( VAR_1 , query ) ; TYPE_4 . assertEquals ( INT_2 , count . METHOD_7 ( ) ) ; }\n","public void METHOD_1 ( ) { TYPE_1 query = new TYPE_1 ( ) ; TYPE_2 VAR_1 = TYPE_3. METHOD_2 ( VAR_2 class ) ; TYPE_3. METHOD_3 ( VAR_1. getId ( ) ). METHOD_4 ( INT_1 ) ; TYPE_3. METHOD_5 ( VAR_1 ) ; java.lang.Long count = VAR_3. METHOD_6 ( VAR_1, query ) ; TYPE_4. assertEquals ( INT_2, count. METHOD_7 ( ) ) ; }\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KUFMXJPrxaqs","executionInfo":{"status":"ok","timestamp":1624464289031,"user_tz":-360,"elapsed":3404,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"5283b33f-8801-4c03-92a2-3489af3fa4de"},"source":["accuracy = Accuracy(total_actual_str,total_output_str)\n","sommth_bleu_score = round(_bleu(total_actual_str, total_output_str),2)\n","\n","print(accuracy)\n","print(sommth_bleu_score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[['public', 'java.lang.String', 'METHOD_1', '(', ')', '{', 'if', '(', '(', 'METHOD_2', '(', ')', ')', '&&', '(', 'METHOD_3', '(', 'VAR_1', '.', 'METHOD_4', '(', ')', ')', ')', ')', '{', 'return', 'VAR_1', '.', 'METHOD_4', '(', ')', ';', '}', 'else', 'if', '(', 'METHOD_3', '(', 'VAR_3', '.', 'METHOD_5', '(', ')', '.', 'METHOD_6', '(', ')', ')', ')', '{', 'return', 'VAR_3', '.', 'METHOD_5', '(', ')', '.', 'METHOD_6', '(', ')', ';', '}', 'else', '{', 'return', 'VAR_4', '.', 'METHOD_4', '(', ')', ';', '}', '}'], ['private', 'void', 'METHOD_1', '(', 'TYPE_1', 'index', ',', 'java.util.Collection', '<', 'TYPE_2', '>', 'VAR_1', ')', '{', 'TYPE_1', 'VAR_2', '=', 'index', '.', 'METHOD_2', '(', 'VAR_3', ')', ';', 'for', '(', 'TYPE_3', '<', 'TYPE_2', '>', 'VAR_4', ':', 'this', '.', 'VAR_1', '.', 'values', '(', ')', ')', '{', 'VAR_4', '.', 'METHOD_3', '(', 'VAR_2', ',', 'null', ')', ';', '}', 'METHOD_4', '(', 'index', ',', 'VAR_1', ')', ';', '}'], ['public', 'void', 'remove', '(', 'int', 'id', ')', '{', 'try', '{', 'java.lang.String', 'query', '=', 'STRING_1', ';', 'TYPE_1', 'VAR_1', '=', 'METHOD_1', '(', ')', ';', 'TYPE_2', 'VAR_2', '=', 'VAR_1', '.', 'METHOD_2', '(', 'query', ')', ';', 'VAR_2', '.', 'METHOD_3', '(', '1', ',', 'id', ')', ';', 'VAR_2', '.', 'METHOD_4', '(', ')', ';', '}', 'catch', '(', 'TYPE_3', 'VAR_3', ')', '{', 'java.lang.System.out.println', '(', 'STRING_2', ')', ';', '}', '}'], ['private', 'java.util.List', '<', 'TYPE_1', '>', 'METHOD_1', '(', ')', '{', 'java.util.List', '<', 'TYPE_1', '>', 'VAR_2', '=', 'new', 'java.util.ArrayList', '<', '>', '(', ')', ';', 'for', '(', 'int', 'i', '=', '0', ';', 'i', '<', '(', 'VAR_3', '.', 'size', '(', ')', ')', ';', 'i', '++', ')', '{', 'TYPE_1', 'VAR_1', '=', 'new', 'TYPE_1', '(', ')', ';', 'VAR_1', '.', 'METHOD_2', '(', 'VAR_3', '.', 'get', '(', 'i', ')', '.', 'METHOD_3', '(', ')', ')', ';', 'VAR_2', '.', 'add', '(', 'VAR_1', ')', ';', '}', 'return', 'VAR_2', ';', '}'], ['private', 'void', 'METHOD_1', '(', 'java.util.List', '<', 'TYPE_1', '>', 'parameters', ',', 'TYPE_2', 'VAR_1', ')', '{', 'while', '(', 'VAR_1', '.', 'METHOD_2', '(', ')', ')', '{', 'TYPE_3', 'VAR_2', '=', 'METHOD_3', '(', 'VAR_1', ')', ';', 'if', '(', 'VAR_2', '==', 'null', ')', '{', 'break', ';', '}', 'if', '(', 'VAR_2', '.', 'METHOD_4', '(', ')', ')', '{', 'METHOD_6', '(', 'parameters', ',', 'METHOD_7', '(', 'VAR_2', ')', ')', ';', '}', 'VAR_1', '=', '(', '(', 'TYPE_2', ')', '(', 'VAR_2', '.', 'METHOD_8', '(', ')', ')', ')', ';', '}', '}']]\n","[['public', 'java.lang.String', 'METHOD_1', '(', ')', '{', 'if', '(', '(', 'METHOD_2', '(', ')', ')', '&&', '(', 'METHOD_3', '(', 'VAR_1.', 'METHOD_4', '(', ')', ')', ')', ')', '{', 'return', 'VAR_2.', 'METHOD_4', '(', ')', ';', '}', 'else', 'if', '(', 'METHOD_3', '(', 'VAR_3.', 'METHOD_5', '(', ').', 'METHOD_6', '(', ')', ')', ')', '{', 'return', 'VAR_3.', 'METHOD_5', '(', ').', 'METHOD_6', '(', ')', ';', '}', 'else', '{', 'return', 'VAR_4.', 'METHOD_4', '(', ')', ';', '}', '}'], ['private', 'void', 'METHOD_1', '(', 'TYPE_1', 'index,', 'java.util.Collection', '<', 'TYPE_2', '>', 'VAR_1', ')', '{', 'TYPE_1', 'VAR_2', '=', 'index.', 'METHOD_2', '(', 'VAR_3', ')', ';', 'for', '(', 'TYPE_3', '<', 'TYPE_2', '>', 'VAR_4', ':', 'this.', 'VAR_1.', 'values', '(', ')', ')', '{', 'VAR_4.', 'METHOD_3', '(', 'VAR_2,', 'null', ')', ';', '}', 'METHOD_4', '(', 'VAR_2,', 'VAR_1', ')', ';', '}'], ['public', 'void', 'remove', '(', 'int', 'id', ')', '{', 'try', '{', 'java.lang.String', 'query', '=', 'STRING_1', ';', 'TYPE_1', 'VAR_1', '=', 'METHOD_1', '(', ')', ';', 'TYPE_2', 'VAR_2', '=', 'VAR_1.', 'METHOD_2', '(', 'query', ')', ';', 'VAR_2.', 'METHOD_3', '(', '1,', 'id', ')', ';', 'VAR_2.', 'METHOD_4', '(', ')', ';', '}', 'catch', '(', 'TYPE_3', 'VAR_3', ')', '{', 'VAR_3.', 'METHOD_5', '(', ')', ';', 'java.lang.System.out.println', '(', 'STRING_2', ')', ';', '}', '}'], ['private', 'java.util.List', '<', 'TYPE_1', '>', 'METHOD_1', '(', ')', '{', 'TYPE_1', 'VAR_1', '=', 'new', 'TYPE_1', '(', ')', ';', 'java.util.List', '<', 'TYPE_1', '>', 'VAR_2', '=', 'new', 'java.util.ArrayList', '<', '>', '(', ')', ';', 'for', '(', 'int', 'i', '=', '0', ';', 'i', '<', '(', 'VAR_3.', 'size', '(', ')', ')', ';', 'i', '++', ')', '{', 'VAR_1.', 'METHOD_2', '(', 'VAR_3.', 'get', '(', 'i', ').', 'METHOD_3', '(', ')', ')', ';', 'VAR_2.', 'add', '(', 'VAR_1', ')', ';', '}', 'return', 'VAR_2', ';', '}'], ['private', 'void', 'METHOD_1', '(', 'java.util.List', '<', 'TYPE_1', '>', 'parameters,', 'TYPE_2', 'VAR_1', ')', '{', 'while', '(', 'VAR_1.', 'METHOD_2', '(', ')', ')', '{', 'TYPE_3', 'VAR_2', '=', 'METHOD_3', '(', 'VAR_1', ')', ';', 'if', '(', 'VAR_2', '==', 'null', ')', '{', 'break', ';', '}', 'if', '(', 'TYPE_4.', 'METHOD_4', '(', 'VAR_2.', 'METHOD_5', '(', ')', ')', ')', '{', 'METHOD_6', '(', 'parameters,', 'METHOD_7', '(', 'VAR_2', ')', ')', ';', '}', 'VAR_1', '=', '(', '(', 'TYPE_2', ')', '(', 'VAR_2.', 'METHOD_8', '(', ')', ')', ')', ';', '}', '}']]\n","0.17\n","61.45\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IGGJYnLmxV7E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624464281813,"user_tz":-360,"elapsed":3807,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"647a87ea-6783-4c93-aa76-bf5a73740eea"},"source":["accuracy = Accuracy(total_actual_str,total_actual_str)\n","sommth_bleu_score = round(_bleu(total_actual_str, total_actual_str),2)\n","\n","print(accuracy)\n","print(sommth_bleu_score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[['public', 'java.lang.String', 'METHOD_1', '(', ')', '{', 'if', '(', '(', 'METHOD_2', '(', ')', ')', '&&', '(', 'METHOD_3', '(', 'VAR_1', '.', 'METHOD_4', '(', ')', ')', ')', ')', '{', 'return', 'VAR_1', '.', 'METHOD_4', '(', ')', ';', '}', 'else', 'if', '(', 'METHOD_3', '(', 'VAR_3', '.', 'METHOD_5', '(', ')', '.', 'METHOD_6', '(', ')', ')', ')', '{', 'return', 'VAR_3', '.', 'METHOD_5', '(', ')', '.', 'METHOD_6', '(', ')', ';', '}', 'else', '{', 'return', 'VAR_4', '.', 'METHOD_4', '(', ')', ';', '}', '}'], ['private', 'void', 'METHOD_1', '(', 'TYPE_1', 'index', ',', 'java.util.Collection', '<', 'TYPE_2', '>', 'VAR_1', ')', '{', 'TYPE_1', 'VAR_2', '=', 'index', '.', 'METHOD_2', '(', 'VAR_3', ')', ';', 'for', '(', 'TYPE_3', '<', 'TYPE_2', '>', 'VAR_4', ':', 'this', '.', 'VAR_1', '.', 'values', '(', ')', ')', '{', 'VAR_4', '.', 'METHOD_3', '(', 'VAR_2', ',', 'null', ')', ';', '}', 'METHOD_4', '(', 'index', ',', 'VAR_1', ')', ';', '}'], ['public', 'void', 'remove', '(', 'int', 'id', ')', '{', 'try', '{', 'java.lang.String', 'query', '=', 'STRING_1', ';', 'TYPE_1', 'VAR_1', '=', 'METHOD_1', '(', ')', ';', 'TYPE_2', 'VAR_2', '=', 'VAR_1', '.', 'METHOD_2', '(', 'query', ')', ';', 'VAR_2', '.', 'METHOD_3', '(', '1', ',', 'id', ')', ';', 'VAR_2', '.', 'METHOD_4', '(', ')', ';', '}', 'catch', '(', 'TYPE_3', 'VAR_3', ')', '{', 'java.lang.System.out.println', '(', 'STRING_2', ')', ';', '}', '}'], ['private', 'java.util.List', '<', 'TYPE_1', '>', 'METHOD_1', '(', ')', '{', 'java.util.List', '<', 'TYPE_1', '>', 'VAR_2', '=', 'new', 'java.util.ArrayList', '<', '>', '(', ')', ';', 'for', '(', 'int', 'i', '=', '0', ';', 'i', '<', '(', 'VAR_3', '.', 'size', '(', ')', ')', ';', 'i', '++', ')', '{', 'TYPE_1', 'VAR_1', '=', 'new', 'TYPE_1', '(', ')', ';', 'VAR_1', '.', 'METHOD_2', '(', 'VAR_3', '.', 'get', '(', 'i', ')', '.', 'METHOD_3', '(', ')', ')', ';', 'VAR_2', '.', 'add', '(', 'VAR_1', ')', ';', '}', 'return', 'VAR_2', ';', '}'], ['private', 'void', 'METHOD_1', '(', 'java.util.List', '<', 'TYPE_1', '>', 'parameters', ',', 'TYPE_2', 'VAR_1', ')', '{', 'while', '(', 'VAR_1', '.', 'METHOD_2', '(', ')', ')', '{', 'TYPE_3', 'VAR_2', '=', 'METHOD_3', '(', 'VAR_1', ')', ';', 'if', '(', 'VAR_2', '==', 'null', ')', '{', 'break', ';', '}', 'if', '(', 'VAR_2', '.', 'METHOD_4', '(', ')', ')', '{', 'METHOD_6', '(', 'parameters', ',', 'METHOD_7', '(', 'VAR_2', ')', ')', ';', '}', 'VAR_1', '=', '(', '(', 'TYPE_2', ')', '(', 'VAR_2', '.', 'METHOD_8', '(', ')', ')', ')', ';', '}', '}']]\n","[['public', 'java.lang.String', 'METHOD_1', '(', ')', '{', 'if', '(', '(', 'METHOD_2', '(', ')', ')', '&&', '(', 'METHOD_3', '(', 'VAR_1', '.', 'METHOD_4', '(', ')', ')', ')', ')', '{', 'return', 'VAR_1', '.', 'METHOD_4', '(', ')', ';', '}', 'else', 'if', '(', 'METHOD_3', '(', 'VAR_3', '.', 'METHOD_5', '(', ')', '.', 'METHOD_6', '(', ')', ')', ')', '{', 'return', 'VAR_3', '.', 'METHOD_5', '(', ')', '.', 'METHOD_6', '(', ')', ';', '}', 'else', '{', 'return', 'VAR_4', '.', 'METHOD_4', '(', ')', ';', '}', '}'], ['private', 'void', 'METHOD_1', '(', 'TYPE_1', 'index', ',', 'java.util.Collection', '<', 'TYPE_2', '>', 'VAR_1', ')', '{', 'TYPE_1', 'VAR_2', '=', 'index', '.', 'METHOD_2', '(', 'VAR_3', ')', ';', 'for', '(', 'TYPE_3', '<', 'TYPE_2', '>', 'VAR_4', ':', 'this', '.', 'VAR_1', '.', 'values', '(', ')', ')', '{', 'VAR_4', '.', 'METHOD_3', '(', 'VAR_2', ',', 'null', ')', ';', '}', 'METHOD_4', '(', 'index', ',', 'VAR_1', ')', ';', '}'], ['public', 'void', 'remove', '(', 'int', 'id', ')', '{', 'try', '{', 'java.lang.String', 'query', '=', 'STRING_1', ';', 'TYPE_1', 'VAR_1', '=', 'METHOD_1', '(', ')', ';', 'TYPE_2', 'VAR_2', '=', 'VAR_1', '.', 'METHOD_2', '(', 'query', ')', ';', 'VAR_2', '.', 'METHOD_3', '(', '1', ',', 'id', ')', ';', 'VAR_2', '.', 'METHOD_4', '(', ')', ';', '}', 'catch', '(', 'TYPE_3', 'VAR_3', ')', '{', 'java.lang.System.out.println', '(', 'STRING_2', ')', ';', '}', '}'], ['private', 'java.util.List', '<', 'TYPE_1', '>', 'METHOD_1', '(', ')', '{', 'java.util.List', '<', 'TYPE_1', '>', 'VAR_2', '=', 'new', 'java.util.ArrayList', '<', '>', '(', ')', ';', 'for', '(', 'int', 'i', '=', '0', ';', 'i', '<', '(', 'VAR_3', '.', 'size', '(', ')', ')', ';', 'i', '++', ')', '{', 'TYPE_1', 'VAR_1', '=', 'new', 'TYPE_1', '(', ')', ';', 'VAR_1', '.', 'METHOD_2', '(', 'VAR_3', '.', 'get', '(', 'i', ')', '.', 'METHOD_3', '(', ')', ')', ';', 'VAR_2', '.', 'add', '(', 'VAR_1', ')', ';', '}', 'return', 'VAR_2', ';', '}'], ['private', 'void', 'METHOD_1', '(', 'java.util.List', '<', 'TYPE_1', '>', 'parameters', ',', 'TYPE_2', 'VAR_1', ')', '{', 'while', '(', 'VAR_1', '.', 'METHOD_2', '(', ')', ')', '{', 'TYPE_3', 'VAR_2', '=', 'METHOD_3', '(', 'VAR_1', ')', ';', 'if', '(', 'VAR_2', '==', 'null', ')', '{', 'break', ';', '}', 'if', '(', 'VAR_2', '.', 'METHOD_4', '(', ')', ')', '{', 'METHOD_6', '(', 'parameters', ',', 'METHOD_7', '(', 'VAR_2', ')', ')', ';', '}', 'VAR_1', '=', '(', '(', 'TYPE_2', ')', '(', 'VAR_2', '.', 'METHOD_8', '(', ')', ')', ')', ';', '}', '}']]\n","100.0\n","100.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"djtFAyfe2ncv","executionInfo":{"status":"ok","timestamp":1624032134883,"user_tz":-360,"elapsed":535,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"06154810530490924203"}},"outputId":"47eec9a3-21e7-4b9f-ba14-d44bba4ccdac"},"source":["print(ed.config.encoder.max_length)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["20\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ht2OMlcq5fF","executionInfo":{"status":"ok","timestamp":1623752484246,"user_tz":-360,"elapsed":420,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"06154810530490924203"}},"outputId":"edb45d68-7745-4517-f91b-ba8c78620aa5"},"source":["import torch\n","output_ids_padding = torch.where(train_labels[0]== -100,led_tokenizer.pad_token_id,train_labels[0])\n","print(led_tokenizer.decode(output_ids_padding))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<s>[problem_tags]greedy, math, sortings[problem_difficulty]1100[req_time]218 ms[req_memory]400 KB[code_text]#include<bits/stdc++.h>\r\r\n","using namespace std;\r\r\n","\r\r\n","int main()\r\r\n","{\r\r\n","\tint t; cin>>t; while(t-->0){\r\r\n","\t\tint n; cin>>n; int a[n]; for(int i=0;i<n;i++) cin>>a[i];\r\r\n","\t\tint p=n-1; sort(a,a+n);\r\r\n","\t\tfor(int i=0;i<p;i++){\r\r\n","\t\t\tif(a[i+1]-a[i] < a[p]){\r\r\n","\t\t\t\tp--; i--;\r\r\n","\t\t\t}\r\r\n","\t\t}\r\r\n","\t\tcout << p+1 << endl;\r\r\n","\t}\r\r\n","}</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tSp5J6ltjHP6"},"source":["import torch\n","\n","from datasets import load_dataset, load_metric\n","from transformers import LEDTokenizer, LEDForConditionalGeneration\n","\n","# load pubmed\n","pubmed_test = load_dataset(\"scientific_papers\", \"pubmed\", ignore_verifications=True, split=\"test\")\n","\n","# load tokenizer\n","tokenizer = LEDTokenizer.from_pretrained(\"patrickvonplaten/led-large-16384-pubmed\")\n","model = LEDForConditionalGeneration.from_pretrained(\"patrickvonplaten/led-large-16384-pubmed\").to(\"cuda\").half()\n","\n","\n","def generate_answer(batch):\n","  inputs_dict = tokenizer(batch[\"article\"], padding=\"max_length\", max_length=8192, return_tensors=\"pt\", truncation=True)\n","  input_ids = inputs_dict.input_ids.to(\"cuda\")\n","  attention_mask = inputs_dict.attention_mask.to(\"cuda\")\n","  global_attention_mask = torch.zeros_like(attention_mask)\n","  # put global attention on <s> token\n","  global_attention_mask[:, 0] = 1\n","\n","  predicted_abstract_ids = model.generate(input_ids, attention_mask=attention_mask, global_attention_mask=global_attention_mask)\n","  batch[\"predicted_abstract\"] = tokenizer.batch_decode(predicted_abstract_ids, skip_special_tokens=True)\n","  return batch\n","\n","\n","result = pubmed_test.map(generate_answer, batched=True, batch_size=4)\n","\n","# load rouge\n","rouge = load_metric(\"rouge\")\n","\n","print(\"Result:\", rouge.compute(predictions=result[\"predicted_abstract\"], references=result[\"abstract\"], rouge_types=[\"rouge2\"])[\"rouge2\"].mid)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UkDe4LKiJcPI"},"source":["for i in range(len(train_labels)):\n","  for x in train_labels[i]:\n","    if(x>50277 or x<0):\n","      print(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t-JsofAhQU-B"},"source":["for x in train_labels[0]:\n","  if(x!=1):\n","    #print(x)\n","    #s = led_tokenizer.convert_ids_to_tokens(torch.tensor([x]))\n","    #x = led_model.get_decoder().embed_tokens(train_labels[0])[0]\n","    #print(s)\n","    m = led_model.get_decoder()\n","    ss = m(tensorify([[x]]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zJxUK4pJb6nw","executionInfo":{"status":"ok","timestamp":1622920670945,"user_tz":-360,"elapsed":575,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"74e9e588-8025-48f7-d830-47c1e9c7a61b"},"source":["arr = torch.zeros_like(train_labels[0])\n","print(len(arr))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["4096\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XxnwUjfMe3Aa"},"source":["print(led_model.config.max_decoder_position_embeddings)\n","dec = led_model.get_decoder()\n","print(led_model.get_decoder().embed_tokens)\n","dec.set_input_embeddings(led_model.get_encoder().embed_tokens)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":340},"id":"-pFi8xqyaGAX","executionInfo":{"status":"error","timestamp":1622923729558,"user_tz":-360,"elapsed":389,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"bff6c710-6fd9-45bf-e400-01763dfbf57f"},"source":["x = edm.get_decoder()\n","ss = x(tensorify([arr[:1024]]))"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-49-2bb4de1c05e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensorify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/reformer/modeling_reformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, position_ids, attention_mask, head_mask, inputs_embeds, num_hashes, past_buckets_states, use_cache, output_hidden_states, output_attentions, return_dict, labels)\u001b[0m\n\u001b[1;32m   2236\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2237\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2238\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2239\u001b[0m         )\n\u001b[1;32m   2240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/reformer/modeling_reformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, num_hashes, past_buckets_states, use_cache, output_hidden_states, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m   2083\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2084\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2085\u001b[0;31m             \u001b[0mstart_idx_pos_encodings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_idx_pos_encodings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2086\u001b[0m         )\n\u001b[1;32m   2087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/reformer/modeling_reformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, position_ids, inputs_embeds, start_idx_pos_encodings)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m# add positional embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/reformer/modeling_reformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, position_ids)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxial_pos_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 raise ValueError(\n\u001b[0;32m--> 156\u001b[0;31m                     \u001b[0;34mf\"If training, make sure that config.axial_pos_shape factors: {self.axial_pos_shape} multiply to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                     \u001b[0;34mf\"sequence length. Got prod({self.axial_pos_shape}) != sequence_length: {sequence_length}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                     \u001b[0;34mf\"You might want to consider padding your sequence length to {reduce(mul, self.axial_pos_shape)} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: If training, make sure that config.axial_pos_shape factors: (128, 512) multiply to sequence length. Got prod((128, 512)) != sequence_length: 1024. You might want to consider padding your sequence length to 65536 or changing config.axial_pos_shape."]}]},{"cell_type":"code","metadata":{"id":"UsKew13SR3sD"},"source":["print(ss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x4u0kzyrFKx5","executionInfo":{"status":"ok","timestamp":1622911805192,"user_tz":-360,"elapsed":405,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"95c67d2e-e857-482f-b1a2-17a62573c430"},"source":["print(len(led_tokenizer))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["50265\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qOlwP_wSFO8u"},"source":["print(led_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j5vDcLYyhSbl"},"source":["model = led_model.get_decoder()\n","#x.from_pretrained(\"allenai/led-base-16384\")\n","model.max_target_positions = 2048"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8kbNwdP1m8fq"},"source":["from transformers import EncoderDecoderModel,AutoModelForCausalLM\n","\n","encoder_model = AutoModelForCausalLM.from_pretrained('allenai/longformer-base-4096')\n","#encoder_model.resize_token_embeddings(len(encoder_tokenizer))\n","\n","encoder_model.save_pretrained(project_path+'Saved_Models/Longformer_Encoder_Init_2')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KoDI4zbRpeX1"},"source":["from transformers import EncoderDecoderModel,AutoModelForSeq2SeqLM, ReformerModel,ReformerForMaskedLM\n","\n","edm = EncoderDecoderModel.from_encoder_decoder_pretrained(project_path+'Saved_Models/asd_E',project_path+'Saved_Models/asd_D')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wMMSQ3nMxWAY","executionInfo":{"status":"ok","timestamp":1623221292691,"user_tz":-360,"elapsed":8787,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"12a3852a-cc35-4926-9005-53906401f8ea"},"source":["print(edm.config.decoder.max_position_embeddings)\n","\n","edm.save_pretrained(project_path+'Saved_Models/asd_ED')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["65536\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IaiojYkjgZMV"},"source":["from transformers import ReformerModel, ReformerConfig\n","# Initializing a Reformer configuration\n","configuration = ReformerConfig.from_pretrained(\"google/reformer-enwik8\", lsh_attn_chunk_length=16386, local_attn_chunk_length=16386)\n","# Initializing a Reformer model\n","enc_model = ReformerModel(configuration)\n","\n","enc_model.save_pretrained(project_path+'Saved_Models/asd_E')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fHywIi9Lgps7"},"source":["from transformers import ReformerForMaskedLM, ReformerConfig\n","# Initializing a Reformer configuration\n","configuration = ReformerConfig.from_pretrained(\"google/reformer-enwik8\", lsh_attn_chunk_length=16386, local_attn_chunk_length=16386)\n","configuration.is_decoder=False\n","# Initializing a Reformer model\n","dec_model = ReformerForMaskedLM(configuration)\n","\n","dec_model.save_pretrained(project_path+'Saved_Models/asd_D')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZGHTUf4ecHdH"},"source":["red = AutoModelForSeq2SeqLM.from_pretrained(project_path+'Saved_Models/asd_ED')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L--c2w-3h6KW","executionInfo":{"status":"ok","timestamp":1623221451026,"user_tz":-360,"elapsed":340,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"55240be5-4d04-43d3-b253-28b0c90f4d3f"},"source":["print(red.config.decoder.is_decoder)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dl3iiv78lHjz","executionInfo":{"status":"ok","timestamp":1623222892873,"user_tz":-360,"elapsed":4739,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"4dc8acd5-71b5-4922-97a2-cbdeccf772a7"},"source":["cnt_1024 = 0\n","cnt_4096 = 0\n","\n","for x in train_labels:\n","  try:\n","    if(x.tolist().index(1)+1<=1023):\n","      cnt_1024=cnt_1024+1\n","    else:\n","      cnt_4096 = cnt_4096+1\n","  except:\n","    cnt_4096 = cnt_4096+1\n","\n","print(cnt_1024)\n","print(cnt_4096)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["16863\n","12389\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"81l9k2RDnro3","executionInfo":{"status":"ok","timestamp":1623222847906,"user_tz":-360,"elapsed":323,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"1655e8db-b97c-47cd-ba01-1aba646dc43e"},"source":["print(len(train_encoding['input_ids']))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["29252\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mGMhJU43lwrD","executionInfo":{"status":"ok","timestamp":1623222574131,"user_tz":-360,"elapsed":349,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"5b5ffb29-b5cc-4f40-df68-fb382ffe792c"},"source":["print(train_encoding['input_ids'][0].tolist().index(1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["626\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238,"referenced_widgets":["3fd406cb781c4531bfeae59f1b2f8460","0ed49ed0fabc433892cb6e66256b110a","9f2417e77b5c40529814b17863ed7abc","0c34082f5e4440f8a83b57148659ef8e","057582f7457a420d8756a3ba6d057634","dd767d8c985a4576a49fac5b8d9be619","08929d7f50684c7c8ada1dfd288038e9","38ec365837fa4ff0a2be6c8cba2ab4d2","7d0bb7a8222c4cdd93ebe7343c255476","7270e156c2ff4542bd03b3a45226bb57","27d0397128774943a646b8e58302a4c0","8d6ab9f9e9f64ec29c325fafb95f606b","5019419281ac4713bb661ff4d40a7517","0aaa5b3202324f09a008ba9d56dd9a25","5b6f621fe077499e8f3d16861ad6d3b8","486c7fddcdb6442f8196ee95d637ab75"]},"id":"kssh2MlxlRC1","executionInfo":{"status":"ok","timestamp":1623827507768,"user_tz":-360,"elapsed":19049,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"06154810530490924203"}},"outputId":"51559d13-ea70-4448-d004-da2dd8c46b9d"},"source":["#python_code = \"def convert(x): return x\"\n","PHP_CODE = \"\"\"\n","public static <mask> set(string $key, $value) {\n","    if (!in_array($key, self::$allowedKeys)) {\n","        throw new \\InvalidArgumentException('Invalid key given');\n","    }\n","    self::$storedValues[$key] = $value;\n","}\n","\"\"\".lstrip()\n","\n","from transformers import pipeline, EncoderDecoderModel\n","\n","#summarizer = pipeline(\"summarization\")\n","\n","ed_model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"microsoft/codebert-base-mlm\",\"microsoft/codebert-base\")\n","'''\n","fill_mask = pipeline(\n","    \"summarization\",\n","    model=model,\n","    tokenizer=\"microsoft/codebert-base-mlm\"\n",")\n","\n","print(fill_mask(PHP_CODE))\n","'''\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at microsoft/codebert-base-mlm were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3fd406cb781c4531bfeae59f1b2f8460","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=498.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d0bb7a8222c4cdd93ebe7343c255476","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=498627950.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of RobertaForCausalLM were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.value.bias', 'lm_head.layer_norm.bias', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'lm_head.bias', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.8.crossattention.self.value.bias', 'lm_head.decoder.weight', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.query.weight', 'lm_head.dense.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'lm_head.dense.weight', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.value.bias', 'lm_head.layer_norm.weight', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nfill_mask = pipeline(\\n    \"summarization\",\\n    model=model,\\n    tokenizer=\"microsoft/codebert-base-mlm\"\\n)\\n\\nprint(fill_mask(PHP_CODE))\\n'"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":553,"referenced_widgets":["7e43d9250d9c4fe98cf2194b98c78718","1a94aa7269f04ec0a6225998be67fe19","ee9becdbc1304049894383e58d3494af","b74e72c12b5b4616a8442c4cb6c43d66","4eac87fde4cd41069b79a176f4f0ef2c","05b4472fa511434d976e4fdfe07f0b0e","6d57a22c25154c0bbe08e30c14b14058","257914342d4d46b18d18ce634df1491e","a68e0782e4a5468db873a756625b19de","de2be8b05cce43bfaa77683c05d88601","a5d2b9fc93804566a996519a9effd1b4","da2b4c1886aa436bb65d7bf84ec83591","5dcbe6b0e6ff4a809bbe5169c26ccc66","0c8efdfc214a4555b45553902871ca21","70a386e1270d4cec81a6f8094949f78a","97e7fd5fe96240029d5c945237f2698f","9203100138a345008a2f9a8fbf0d2b64","e1fd4543d8954cf9a39a44e87ff88d51","0619c1520fef496cbe7c7ff7849f5a3e","cf4a578094e34e49b2aa06645c967a45","efc714bbf70346978fc96984d874c14e","4043d03dae6340f69a78ca3de9769269","4f16ea15084949d9ba31135f95e46883","63fccdf13da943d5b6465aac5de450c9","5363e51c14074513a213eee6a32be738","cc3f26fa8f3f408da359dd9fb8951240","42d306f457d342cd9145fa9ac8849bb3","593bba70198e43ff84d417e394fa37ec","4ee0adef37534792857a6d87798d17cb","8eddc5a2839c4b359b7415194dfa7f0f","221f4aaf860c4a6fbafd774a348bb227","d10fc488334e4677842ef6c6230a8d5a"]},"id":"mOUktUDZpWTS","executionInfo":{"status":"error","timestamp":1623830636311,"user_tz":-360,"elapsed":18035,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"06154810530490924203"}},"outputId":"3c42d94d-2c19-4b6a-f721-9856c404adce"},"source":["summarizer = pipeline(\"text-generation\", model=\"microsoft/codebert-base\", tokenizer=\"microsoft/codebert-base\", framework=\"tf\")\n","summarizer(\"def convert_int_to_str(x):\", min_length=5, max_length=50)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e43d9250d9c4fe98cf2194b98c78718","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898822.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a68e0782e4a5468db873a756625b19de","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9203100138a345008a2f9a8fbf0d2b64","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=150.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5363e51c14074513a213eee6a32be738","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=25.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"error","ename":"PipelineException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mPipelineException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-65f1399abde7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummarizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text-generation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"microsoft/codebert-base\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"microsoft/codebert-base\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msummarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"def convert_int_to_str(x):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"feature_extractor\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtask_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, return_full_text, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_model_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALLOWED_MODELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_full_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_full_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mcheck_model_type\u001b[0;34m(self, supported_models)\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m                 \u001b[0;34mf\"The model '{self.model.__class__.__name__}' is not supported for {self.task}. Supported models are {supported_models}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m             )\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mPipelineException\u001b[0m: The model 'RobertaModel' is not supported for text-generation. Supported models are ['XLNetLMHeadModel', 'TransfoXLLMHeadModel', 'ReformerModelWithLMHead', 'GPT2LMHeadModel', 'GPTNeoForCausalLM', 'OpenAIGPTLMHeadModel', 'CTRLLMHeadModel', 'TFXLNetLMHeadModel', 'TFTransfoXLLMHeadModel', 'TFGPT2LMHeadModel', 'TFOpenAIGPTLMHeadModel', 'TFCTRLLMHeadModel']"]}]},{"cell_type":"code","metadata":{"id":"4RIIbdDLOOKO"},"source":[""],"execution_count":null,"outputs":[]}]}